[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bike_Share",
    "section": "",
    "text": "BikeShare\n\n\n\n\n\n\n\n\n\n\n\nEric Mossotti\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "bikeShare.html",
    "href": "bikeShare.html",
    "title": "BikeShare",
    "section": "",
    "text": "Bike-share research (bikeshare-research.org)\nDivvy - Wikipedia\nCycling in Chicago - Wikipedia\nHome | Divvy Bikes\nDivvy Membership & Pass Options | Divvy Bikes\n(“Data License Agreement | Divvy Bikes,” n.d.)\n\nData License Agreement | Divvy Bikes\n\n(“MOTIVATE,” n.d.)\n\nMOTIVATE (motivateco.com)\n\n(“Index of Bucket \"Divvy-Tripdata\",” n.d.)\n\nIndex of bucket “divvy-tripdata”\n\n(“Why DuckDB,” n.d.)\n\nWhy DuckDB?\n\n(“R for Data Science (2e) - 22  Arrow,” n.d.)\n\nR for Data Science: Chapter 22: Arrow\n\n(“Great-Circle Distance - Wikipedia,” n.d.)\n\nhttps://en.wikipedia.org/wiki/Great-circle_distance\n\n(“Average Bicycle Speed  How Fast Do Cyclists Ride and What Affects Their Pace - BikingulTimate.com (UPDATE 👍)” 2024)\n\nhttps://bikingultimate.com/average-bicycle-speed-how-fast-do-cyclists-ride-and-what-affects-their-pace/\n\n\n\n\nCode\ndurls &lt;-\n    sprintf(\"https://divvy-tripdata.s3.amazonaws.com/%d-divvy-tripdata.zip\",\n            202301:202312)\n\n# Need some directories to store the files. \ndir.create(\"tempZips\")\n\ntempZipPaths &lt;- sprintf(\"tempZips/%d-divvy-tripdata.zip\",\n                     202301:202312)\n\n# A simple way to download and relocate several files. \ncurl::multi_download(durls,\n                     destfiles = tempZipPaths)\n\n\n\n\nCode\n#|label: 'dir + lists for unz function'\n\n# create tempFile directory\ndir.create(\"tempFiles\")\n\n# create list of tempFile directory paths\ntempfile_paths &lt;- sprintf(\"tempFiles/%d-divvy-tripdata.csv\",\n                      202301:202312)\n\n# create CSV file relocation directory\ndir.create(\"tripdata\")\n\n# create CSV file relocation paths\nfileList &lt;- sprintf(\"tripdata/%d-divvy-tripdata.csv\",\n                       202301:202312)\n\n# create CSV list to specify for unzipping\nfileNames &lt;- sprintf(\"%d-divvy-tripdata.csv\",\n                      202301:202312)\n\n\n\n\nCode\n#|label: 'unzip and relocate function'\n\n# A custom function that makes unzipping, converting and relocating files all at once, simple. \nunz_relocate &lt;- function (x = tempfile_paths,\n                          y = tempZipPaths,\n                          z = fileNames) {\n    for (i in seq(x)) {\n        utils::unzip(y[i],\n                     z[i])\n        file.rename(z[i],\n                    x[i])\n    }\n}\n\nunz_relocate()\n\n\n\n\nCode\n#|label: 'remove zips folder from working directory'\n\n# To remove stored files\nunlink(\"tempZips\",\n       recursive = TRUE)\n\n\n\n\nCode\n#|label: 'create tibble from temp CSV'\n\ntripTibble &lt;- \n    purrr::map(tempfile_paths[1:12],\n                         arrow::read_csv_arrow) |&gt;\n    purrr::list_rbind()\n\n\n\n\nCode\n#|label: 'count raw obs, then drop NAs'\n\n# Need to save this count for later before I drop the incomplete obs\noriginal_nobs &lt;- nrow(tripTibble)\n\ntripTibble &lt;- tripTibble |&gt;\n    tidyr::drop_na()\n\n\n\n\nCode\n#|label: 'new calculated column for trip time'\n\n# To make use of supplied trip interval data\ntripTibble |&gt;\n    dplyr::mutate(\"trip_time\" = lubridate::time_length(\n        lubridate::interval(started_at,\n                            ended_at),\n        unit = \"minute\"), \n        .keep = \"all\"\n    ) |&gt;\n    arrow::write_dataset(\"tempFiles\",\n                         existing_data_behavior = \"delete\")\n\n\n\n\nCode\n#|label: 'removing large tibble from memory'\n\nrm(tripTibble)\n\n\n\n\nCode\n#|label: 'create and view list of files'\n\nfileList &lt;- list.files(path = \"tempFiles\",\n                              full.names = TRUE,\n                              recursive = TRUE)\n\n\n\n\nCode\n#|label: 'create/write a parquet file dataset'\n\ntripset &lt;- arrow::open_dataset(sources = fileList[1],\n                               format = \"parquet\")\n\ntripset |&gt; arrow::write_dataset(path = \"tripdata\",\n                                format = \"parquet\")\n\n\n\n\nCode\ntripset |&gt;\n    dplyr::collect() |&gt;\n    polars::as_polars_df()\n\n\nshape: (4_331_707, 14)\n┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n│ ride_id   ┆ rideable_ ┆ started_a ┆ ended_at  ┆ … ┆ end_lat   ┆ end_lng   ┆ member_ca ┆ trip_tim │\n│ ---       ┆ type      ┆ t         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ sual      ┆ e        │\n│ str       ┆ ---       ┆ ---       ┆ datetime[ ┆   ┆ f64       ┆ f64       ┆ ---       ┆ ---      │\n│           ┆ str       ┆ datetime[ ┆ ms]       ┆   ┆           ┆           ┆ str       ┆ f64      │\n│           ┆           ┆ ms]       ┆           ┆   ┆           ┆           ┆           ┆          │\n╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n│ F96D5A74A ┆ electric_ ┆ 2023-01-2 ┆ 2023-01-2 ┆ … ┆ 41.93     ┆ -87.64    ┆ member    ┆ 10.85    │\n│ 3E41399   ┆ bike      ┆ 1         ┆ 1         ┆   ┆           ┆           ┆           ┆          │\n│           ┆           ┆ 14:05:42  ┆ 14:16:33  ┆   ┆           ┆           ┆           ┆          │\n│ 13CB7EB69 ┆ classic_b ┆ 2023-01-1 ┆ 2023-01-1 ┆ … ┆ 41.809835 ┆ -87.59938 ┆ member    ┆ 8.483333 │\n│ 8CEDB88   ┆ ike       ┆ 0         ┆ 0         ┆   ┆           ┆ 3         ┆           ┆          │\n│           ┆           ┆ 09:37:36  ┆ 09:46:05  ┆   ┆           ┆           ┆           ┆          │\n│ BD88A2E67 ┆ electric_ ┆ 2023-01-0 ┆ 2023-01-0 ┆ … ┆ 42.039742 ┆ -87.69941 ┆ casual    ┆ 13.23333 │\n│ 0661CE5   ┆ bike      ┆ 2         ┆ 2         ┆   ┆           ┆ 3         ┆           ┆ 3        │\n│           ┆           ┆ 01:51:57  ┆ 02:05:11  ┆   ┆           ┆           ┆           ┆          │\n│ C90792D03 ┆ classic_b ┆ 2023-01-2 ┆ 2023-01-2 ┆ … ┆ 41.809835 ┆ -87.59938 ┆ member    ┆ 8.766667 │\n│ 4FED968   ┆ ike       ┆ 2         ┆ 2         ┆   ┆           ┆ 3         ┆           ┆          │\n│           ┆           ┆ 04:52:58  ┆ 05:01:44  ┆   ┆           ┆           ┆           ┆          │\n│ 339701752 ┆ classic_b ┆ 2023-01-1 ┆ 2023-01-1 ┆ … ┆ 41.809835 ┆ -87.59938 ┆ member    ┆ 15.31666 │\n│ 9188E8A   ┆ ike       ┆ 2         ┆ 2         ┆   ┆           ┆ 3         ┆           ┆ 7        │\n│           ┆           ┆ 07:58:01  ┆ 08:13:20  ┆   ┆           ┆           ┆           ┆          │\n│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n│ F74DF9549 ┆ electric_ ┆ 2023-12-0 ┆ 2023-12-0 ┆ … ┆ 41.87464  ┆ -87.65703 ┆ casual    ┆ 2.216667 │\n│ B504A6B   ┆ bike      ┆ 7         ┆ 7         ┆   ┆           ┆           ┆           ┆          │\n│           ┆           ┆ 07:15:24  ┆ 07:17:37  ┆   ┆           ┆           ┆           ┆          │\n│ BCDA66E76 ┆ classic_b ┆ 2023-12-0 ┆ 2023-12-0 ┆ … ┆ 41.87464  ┆ -87.65703 ┆ casual    ┆ 3.583333 │\n│ 1CC1029   ┆ ike       ┆ 8         ┆ 8         ┆   ┆           ┆           ┆           ┆          │\n│           ┆           ┆ 12:42:21  ┆ 12:45:56  ┆   ┆           ┆           ┆           ┆          │\n│ D2CF330F9 ┆ classic_b ┆ 2023-12-0 ┆ 2023-12-0 ┆ … ┆ 41.87464  ┆ -87.65703 ┆ member    ┆ 3.833333 │\n│ C266683   ┆ ike       ┆ 5         ┆ 5         ┆   ┆           ┆           ┆           ┆          │\n│           ┆           ┆ 08:09:11  ┆ 08:13:01  ┆   ┆           ┆           ┆           ┆          │\n│ 3829A0D1E ┆ electric_ ┆ 2023-12-0 ┆ 2023-12-0 ┆ … ┆ 41.885492 ┆ -87.65228 ┆ casual    ┆ 17.63333 │\n│ 00EE970   ┆ bike      ┆ 2         ┆ 2         ┆   ┆           ┆ 9         ┆           ┆ 3        │\n│           ┆           ┆ 15:36:07  ┆ 15:53:45  ┆   ┆           ┆           ┆           ┆          │\n│ A373F5B44 ┆ classic_b ┆ 2023-12-1 ┆ 2023-12-1 ┆ … ┆ 41.87464  ┆ -87.65703 ┆ member    ┆ 3.633333 │\n│ 7AEA508   ┆ ike       ┆ 1         ┆ 1         ┆   ┆           ┆           ┆           ┆          │\n│           ┆           ┆ 07:07:46  ┆ 07:11:24  ┆   ┆           ┆           ┆           ┆          │\n└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n\n\n\n\nCode\n#|label: 'delete CSV directory'\n\n# all files and folders\nunlink(\"tempFiles\", recursive = TRUE)\n\n\n\n\nCode\n#|label: 'open parquet file dataset'\n\ntripset &lt;- arrow::open_dataset(sources = \"tripdata\",\n                              format = \"parquet\")\n\n\n\n\nCode\n#|label: 'create/view list of parquets'\n\n# To verify the location of the extracted data.\nfileList &lt;- list.files(path = \"tripdata\",\n                              full.names = TRUE,\n                              recursive = TRUE)\n\n\n\n\nCode\n#|label: 'create dupe-table, count n distinct'\n\n# This is a separate table used to analyze the observations returned as not distinct (n &gt; 1). This adds an extra column labeled \"n\".\ndupeTable &lt;- tripset |&gt;\n    arrow::to_duckdb() |&gt;\n    dplyr::select(started_at:end_station_name) |&gt;\n    # Counts of unique rows added for column 'n'\n    dplyr::add_count(started_at,\n                     ended_at,\n                     start_station_name,\n                     end_station_name) |&gt;\n    # Only observations that have been duplicated 1 or more \n    # times are shown\n    dplyr::filter(n &gt; 1) |&gt;\n    # We want to see all rows, not just one row for each obs\n    dplyr::ungroup() |&gt;\n    dplyr::arrange(started_at) |&gt;\n    dplyr::collect()\n\nn &lt;- dupeTable |&gt; \n    dplyr::distinct(n) |&gt;\n    as.integer()\n\n\nWe started with 5,719,877 observations (obs) for dates spanning January to December, 2023, then removed 1,388,170 incomplete obs.\nOf the other columns, it seems that the start_time, end_time, start_station, and end_station could show if there are possibly hidden duplicated observations. Those 4 variables combined results in the most granular view of any one observation. Meaning, that data would naturally only have duplicates in error.\nI assumed that having the same times/dates and stations for two different ride IDs was a mistake. Although, I do not know how that error would happen. I could have assumed one person could check out multiple bikes at once. In that instance, each bike could be assigned a unique ride_id. That, however, has only happened 18 times over a year. Since it’s only one copy every time, that also raises a red flag. I did not notice any other correlations with station_id/name, member_casual, or ride_type for those particular duplicated data.\n\n\nCode\n#|label: 'output to distinct duplicates and total obs'\n\ncat(\" Distinct copy count of dupes: \", n,\n    \"\\n\\n\",\n    \"Total observations that have and are duplicates: \",\n       length(dupeTable[[1]]))\n\n\n Distinct copy count of dupes:  2 \n\n Total observations that have and are duplicates:  36\n\n\nBy applying distinct() on dupeTable, we see the only distinct value is 2. We can safely conclude that, of the duplicates, each has a minimum and maximum of 1 extra copy.\nNumber of rows in the dupeTable is 36. Because each duplicated observation has one duplicate (n = 2), expected removed nobs is 18. The issue is that we need to get rid of not all 36 rows, but just the 1 extra duplicate observation from each, resulting in the expected 18.\n\n\nCode\n#|label: 'create un-duped table, count rows'\n\n# The issue is, we need to get rid of not all of these rows, but just the extra duplicate observations. \n\n# If there were 2 rows of duplicates, we would want to end up with 1 row after removing the extras.\nundupedTable &lt;- dupeTable |&gt;\n    arrow::to_duckdb() |&gt;\n    dplyr::distinct(started_at,\n                     start_station_name,\n                     ended_at,\n                     end_station_name,\n                     .keep_all = TRUE) |&gt;\n    dplyr::collect()\n\nn &lt;- undupedTable |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::count() |&gt;\n    as.integer()\n\n\n\n\nCode\n#|label: 'output distinct obs, n'\n\ncat(\"Count of distinct observations: \", n)\n\n\nCount of distinct observations:  18\n\n\nThe count of observed distinct values for the un-duplicated table was indeed 18. So now, it is time to run a count of how rows/observations are in the dataset. There is a difference, though, concerning the correct amount.\n\n\nCode\n#|label: 'incorrect/correct distinct observations'\n\n# Run an incorrect count on how many rows or observations there are in the dataset.\nincorrectDistinct &lt;- tripset |&gt;\n    arrow::to_duckdb() |&gt;\n    dplyr::distinct(dplyr::pick(\"ride_id\")) |&gt;\n    dplyr::count(name = \"Incorrect Distinct Observations\") |&gt;\n    dplyr::collect() |&gt;\n    as.integer()\n\n# For the correct count of obs\ncorrectDistinct &lt;- tripset |&gt;\n    arrow::to_duckdb() |&gt;\n    dplyr::distinct(\n        dplyr::pick(\n            \"started_at\",\n            \"start_station_name\",\n            \"ended_at\",\n            \"end_station_name\"\n        )\n    ) |&gt;\n    dplyr::count() |&gt;\n    dplyr::collect() |&gt;\n    as.integer()\n\n\n\n\nCode\n# To visualize a summary of what we just determined regarding obs\ntibble::tibble(\n    \"Original Obs\" = original_nobs,\n    \"Uncorrected Complete Obs\" = incorrectDistinct,\n    \"Corrected Complete Obs\" = correctDistinct,\n    \"Removed Obs\" = (incorrectDistinct - correctDistinct)\n) |&gt;\n    polars::as_polars_df()\n\n\nshape: (1, 4)\n┌──────────────┬──────────────────────────┬────────────────────────┬─────────────┐\n│ Original Obs ┆ Uncorrected Complete Obs ┆ Corrected Complete Obs ┆ Removed Obs │\n│ ---          ┆ ---                      ┆ ---                    ┆ ---         │\n│ i32          ┆ i32                      ┆ i32                    ┆ i32         │\n╞══════════════╪══════════════════════════╪════════════════════════╪═════════════╡\n│ 5719877      ┆ 4331707                  ┆ 4331689                ┆ 18          │\n└──────────────┴──────────────────────────┴────────────────────────┴─────────────┘\n\n\nThe incorrect number of observations (nobs) was 4,331,707. The correct nobs after removing duplicated obs was 4,331,689. In short, 18 additional obs were removed.\n\n\nCode\n# Saving the data to a file to ensure we have a copy free from incomplete and duplicated obs.\ntripset |&gt;\n    dplyr::select(ride_id:trip_time) |&gt;\n    arrow::to_duckdb() |&gt;\n    dplyr::distinct(started_at, \n                    start_station_name, \n                    ended_at,\n                    end_station_name, \n                    .keep_all = TRUE) |&gt;\n    dplyr::arrange(started_at) |&gt;\n    dplyr::collect() |&gt;\n    arrow::write_dataset(\n        path = \"tripdata\",\n        format = \"parquet\",\n        existing_data_behavior = \"overwrite\"\n    )\n\n\nNoting that it was useful for me to retain certain rows at first to determine if there were duplicates.\n\n\nCode\ntripset &lt;- arrow::open_dataset(\"tripdata\",\n                               format = \"parquet\")\n\ndbconn &lt;- DBI::dbConnect(duckdb::duckdb())\n\n# For querying the arrow dataset with the benefits of an OLAP database. \nduckdb::duckdb_register_arrow(dbconn,\n                              \"unfltrd_tripData\",\n                              tripset)\n\ndplyr::tbl(dbconn,\n           \"unfltrd_tripData\")\n\n\n# Source:   table&lt;unfltrd_tripData&gt; [?? x 14]\n# Database: DuckDB v0.10.0 [ecmos@Windows 10 x64:R 4.3.3/:memory:]\n   ride_id          rideable_type started_at          ended_at           \n   &lt;chr&gt;            &lt;chr&gt;         &lt;dttm&gt;              &lt;dttm&gt;             \n 1 D8EEE72183269F07 classic_bike  2023-01-01 00:02:06 2023-01-01 00:29:46\n 2 E5AD797A579842F8 electric_bike 2023-01-01 00:03:26 2023-01-01 00:07:23\n 3 8FBD2AD70B0F6A6F classic_bike  2023-01-01 00:04:07 2023-01-01 00:13:56\n 4 B05BD052B9EBB767 electric_bike 2023-01-01 00:04:27 2023-01-01 00:16:52\n 5 F9EA7B9E6C243CFC classic_bike  2023-01-01 00:04:54 2023-01-01 00:31:52\n 6 27C2A67184C49D01 electric_bike 2023-01-01 00:05:43 2023-01-01 00:21:37\n 7 776F6B226016E50A classic_bike  2023-01-01 00:06:03 2023-01-01 00:29:39\n 8 31FFA227B5C5FF4F electric_bike 2023-01-01 00:07:45 2023-01-01 00:13:21\n 9 544EFA0F99CA9099 electric_bike 2023-01-01 00:09:33 2023-01-01 00:14:21\n10 4BA829307ABF42BA classic_bike  2023-01-01 00:09:53 2023-01-01 00:25:01\n# ℹ more rows\n# ℹ 10 more variables: start_station_name &lt;chr&gt;, start_station_id &lt;chr&gt;,\n#   end_station_name &lt;chr&gt;, end_station_id &lt;chr&gt;, start_lat &lt;dbl&gt;,\n#   start_lng &lt;dbl&gt;, end_lat &lt;dbl&gt;, end_lng &lt;dbl&gt;, member_casual &lt;chr&gt;,\n#   trip_time &lt;dbl&gt;\n\n\n\n\n\nTo ensure the conclusions are accurate, outliers should be filtered. Negative and very low trip times might skew trends. The underlying reason for very low trip times is somewhat of an unknown. Perhaps people often change their minds?\n\n\nCode\n#|label: 'add/filter distances and speed'\n\n# imposing sensible limits on the data we wish to include moving forward\n# might as well calculate distance traveled while at it\ndplyr::tbl(dbconn,\n           \"unfltrd_tripData\") |&gt;\n    dplyr::filter(trip_time &gt; 1,\n                  trip_time &lt; 480,\n                  rideable_type != \"docked_bike\") |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(\n        miles = geosphere::distGeo(\n            p1 = cbind(start_lng, start_lat),\n            p2 = cbind(end_lng, end_lat)\n        ) / 1000 * 0.62137119,\n        mph = (miles / (trip_time / 60))\n    ) |&gt;\n    # It's somewhat nonsensical to rent a bike for distances easily walked. \n    # Also, there could be randomly generated data.\n    dplyr::filter(miles &gt; 0.1,\n                  # Seems that pro cyclists average around 20 mph, \n                  # so I set that as the ceiling.\n                  mph &lt; 21,\n                  # To account for time spent idling, stoplights and traffic.\n                  mph &gt; 1) |&gt;\n    duckdb::dbWriteTable(conn = dbconn,\n                         name = \"fltrd_tripData\")\n\n\nWriting the Filtered Parquet File\n\n\nCode\n#|label: 'write fltrdData parquet'\n\ndir.create(\"fltrdData\")\n\ndplyr::tbl(dbconn,\n           \"fltrd_tripData\") |&gt;\n    arrow::to_arrow() |&gt;\n    arrow::write_parquet(sink = \"fltrdData/fltrd.parquet\")\n\n# Now we have a filtered data file. \nunlink('tripdata', recursive = TRUE)\n\n\n\n\nCode\nduckdb::dbDisconnect(dbconn, shutdown = TRUE)\n\ntripset &lt;- arrow::open_dataset(\"fltrdData\",\n                               format = \"parquet\")\n\ndbconn &lt;- DBI::dbConnect(duckdb::duckdb())\n\n# For querying the arrow dataset with the benefits of an OLAP database. \nduckdb::duckdb_register_arrow(dbconn,\n                              \"fltrd_data\",\n                              tripset)\n\n\n\n\nCode\n#|label: 'rider count by hour table'\n\nhours_of_Riders &lt;- dplyr::tbl(dbconn,\n                           \"fltrd_data\") |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::mutate(\"hour\" = lubridate::hour(started_at)) |&gt;\n    dplyr::group_by(hour) |&gt;\n    dplyr::summarise(\"riding\" = dplyr::count(started_at)) |&gt;\n    dplyr::arrange(hour) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(\"hour\" = hms::hms(hours = hour),\n                  \"hour\" = format(strptime(hour, format = \"%H\"), \"%r\"),\n                  \"index\" = seq(1:24))\n\n\n\n\n\nCode\nggplot2::ggplot(data = hours_of_Riders,\n                mapping = ggplot2::aes(\n                    x = reorder(hour, .data$index),\n                    y = riding,\n                    fill = riding\n                )) +\n    ggplot2::geom_col() +\n    ggplot2::coord_radial(start = 2 * pi,\n                          inner.radius = .2) +\n    ggplot2::xlab(NULL) +\n    ggplot2::ylab(NULL) +\n    ggplot2::scale_fill_distiller(palette = 'Spectral',\n                                  direction = 1) +\n    ggplot2::labs(\n        title = \"Average Riders by the Hour of Day\",\n        subtitle = \"(Jan-Dec 2023)\",\n        caption = \"Data from cyclistic database.\",\n        tag = \"Figure 1.c\"\n    ) +\n    ggplot2::theme(\n        title = ggplot2::element_text(size = 16,lineheight = 4),\n        text = ggplot2::element_text(color = \"white\"),\n        panel.background = ggplot2::element_rect(fill = \"black\"),\n        panel.grid.minor = ggplot2::element_line(color = \"black\"),\n        panel.grid.major = ggplot2::element_line(color = \"grey10\"),\n        plot.background = ggplot2::element_rect(fill = \"black\"),\n        axis.text.y = ggplot2::element_blank(),\n        axis.ticks.y = ggplot2::element_blank(),\n        axis.text.x = ggplot2::element_text(size = 10,\n                                            color = \"grey90\"),\n        legend.background = ggplot2::element_rect(fill = \"black\"),\n        legend.ticks = ggplot2::element_line(color = \"black\",\n                                             linewidth = .5),\n        legend.text = ggplot2::element_text(color = 'grey80',\n                                             size = 8),\n        legend.title = ggplot2::element_blank(),\n        legend.position = \"right\",\n        legend.justification = \"center\",\n        legend.direction = \"vertical\"\n    )\n\n\n\n\n\nThe time of day people tend to be riding.\n\n\n\n\n\n\n\n\nfor quick reference with using Tsibble syntax\n\n\nCode\n#|label: 'grouped tibb'\n\ngrouped_byDay &lt;- dplyr::tbl(dbconn,\n                            \"fltrd_data\") |&gt;\n    dplyr::select(started_at,\n                  member_casual) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(started_at = as.Date(started_at)) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual) |&gt;\n    dplyr::summarize(n = dplyr::n(),\n                     sdev = stats::sd(n))\n\n\n\n\nCode\n#|label: 'to grouped tsibb'\n\n# tsibble, time-series table/tibble seems to make time series plots more straightforward\ngrouped_tsi &lt;- grouped_byDay |&gt;\n    tsibble::as_tsibble(key = c(member_casual,\n                                n),\n                        index = started_at) |&gt;\n    dplyr::arrange(started_at)\n\n\n\n\nCode\n#|label: \"map query setup\"\n\n# chicago starting coordinates for leaflet, setView\nchicago &lt;- maps::us.cities |&gt;\n    dplyr::select(\"name\",\n                  \"long\",\n                  \"lat\") |&gt;\n    dplyr::filter(name == \"Chicago IL\")\n\n# full dataset coordinates, might need to sample\ncoordQry &lt;- dplyr::tbl(dbconn,\n                       \"fltrd_data\") |&gt;\n    dplyr::select(start_lng,\n                  start_lat) |&gt;\n    dplyr::add_count(start_lng,\n                     start_lat) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::arrange(desc(n)) |&gt;\n    dplyr::collect()\n\n\ncoordQry_small &lt;- dplyr::tbl(dbconn,\n                       \"fltrd_data\") |&gt;\n    dplyr::select(start_lng,\n                  start_lat) |&gt;\n    dplyr::add_count(start_lng,\n                     start_lat) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::arrange(desc(n)) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::slice_head(n = 50)\n\n\n\n\nCode\n#|label: \"mapview\"\n\ncoordQry_small |&gt;\n    sf::st_as_sf(coords = c(1:2),\n                crs = 4326) |&gt;\n    mapview::mapview()\n\n\n\n\n\n\n\n\nCode\nojs_define(js_tsi = grouped_tsi)\n\n\n\n\nCode\njsData = transpose(js_tsi)\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    grid: true,\n    color: {legend: true},\n    marks: [\n        Plot.dot(jsData, {x: 'started_at', y: 'n', fill: 'member_casual'})\n]\n})\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.lineY(jsData, {x: \"started_at\", y: \"n\"}).plot()\n\n\n\n\n\n\n\n\n\nCode\nInputs.table(jsData, {\nrows: 20\n})\n\n\n\n\n\n\n\n\n\nCode\n#|label: 'grouped stats tibb'\n\n# Need a useful data frame for basic aggregations\ngroupedStats_byDay &lt;- dplyr::tbl(dbconn,\n                            \"fltrd_data\") |&gt;\n    dplyr::select(started_at,\n                  member_casual,\n                  rideable_type,\n                  trip_time,\n                  miles,\n                  mph) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(started_at = as.Date(started_at)) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual,\n                    rideable_type) |&gt;\n    dplyr::summarize(n = dplyr::n(),\n                     trip_time_Mean = mean(trip_time),\n                     trip_time_stDev = stats::sd(trip_time),\n                     miles_Mean = mean(miles),\n                     miles_stDev = stats::sd(miles),\n                     mph_Mean = mean(miles),\n                     mph_stDev = stats::sd(mph))\n\n\n\n\nCode\n#|label: 'grouped stats tsibb'\n\n# Would prefer to work with a tsibble for time-series data\ngroupedStats_tsib &lt;- groupedStats_byDay |&gt;\n    tsibble::as_tsibble(key = c(member_casual:mph_stDev),\n                        index = started_at) |&gt;\n    dplyr::arrange(started_at)\n\n\n\n\nCode\n# A solution to help visualize these mutli-dimensional relationships of membership and bike type to time.\ngroupedStats_tsib |&gt;\n    ggplot2::ggplot(ggplot2::aes(x = started_at,\n                                 y = trip_time_Mean,\n                                 color = trip_time_Mean)) +\n    ggplot2::geom_count(size = 3) +\n    ggplot2::facet_wrap(~member_casual+rideable_type) +\n    ggplot2::scale_x_date(date_minor_breaks = \"days\",\n                          date_labels = \"%b\",\n                          breaks = \"months\") +\n    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45,\n                                                       hjust = 1),\n                   panel.background = ggplot2::element_rect(fill = 'grey20'),\n                   panel.grid.major.y = ggplot2::element_line(\n                       linetype = 'dashed',\n                       color = 'grey30'),\n                   panel.grid.major.x = ggplot2::element_line(\n                       linetype = 'dotted',\n                       color = 'grey30'),\n                   panel.grid.minor = ggplot2::element_blank(),\n                   strip.background.x = ggplot2::element_rect(\n                       fill = 'yellowgreen')) +\n    ggplot2::scale_color_distiller(palette = 'Spectral')\n\n\n\n\n\n\n\n\n\n\n\nCode\n#|label: \"dygraph\"\n\nsumDF &lt;- groupedStats_byDay |&gt;\n    dplyr::select(started_at,\n                  n) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual) |&gt;\n    dplyr::summarise(\"count\" = sum(n)) |&gt;\n    tidyr::pivot_wider(names_from = member_casual,\n                       values_from = count)\n\ndygraphs::dygraph(sumDF, main = \"ever\",\n                  ylab = \"what\") |&gt;\n    dygraphs::dyGroup(name = c(\"member\", \"casual\"),\n                       color = c(\"green\", \"red\"))\n\n\n\n\n\n\nThese maps track bike-sharing activity going on worldwide and in Chicago.\nBike Share Map (“Bike Share Map: Chicago (Divvy),” n.d.)\nCityBikes: bike sharing networks around the world (“CityBikes: Bike Sharing Networks Around the World,” n.d.)\n\n\nCode\n#|label: 'drops duckDB tables'\n\n# a chunk for easily dropping either all (default) or specific tables from the ddb. Also made it so you can see the current tables and then the tables after running the chunk.\n\npaths &lt;- duckdb::dbListTables(dbconn)\n\npaths[]\n\ndrops_tables &lt;- function(path) {\n    \n    duckdb::dbRemoveTable(dbconn, \n                          path)\n}\n\npaths[] |&gt; purrr::walk(drops_tables)\n\npaths &lt;- duckdb::dbListTables(dbconn)\n\npaths[]\n\n\n\n\nCode\n#|label: 'duckDB Shutdown'\n\nduckdb::dbDisconnect(dbconn, shutdown = TRUE)\n\n\n\n\nCode\nunlink(\"fltrdData\", recursive = TRUE)"
  },
  {
    "objectID": "bikeShare.html#filtering-data-smartly",
    "href": "bikeShare.html#filtering-data-smartly",
    "title": "BikeShare",
    "section": "",
    "text": "To ensure the conclusions are accurate, outliers should be filtered. Negative and very low trip times might skew trends. The underlying reason for very low trip times is somewhat of an unknown. Perhaps people often change their minds?\n\n\nCode\n#|label: 'add/filter distances and speed'\n\n# imposing sensible limits on the data we wish to include moving forward\n# might as well calculate distance traveled while at it\ndplyr::tbl(dbconn,\n           \"unfltrd_tripData\") |&gt;\n    dplyr::filter(trip_time &gt; 1,\n                  trip_time &lt; 480,\n                  rideable_type != \"docked_bike\") |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(\n        miles = geosphere::distGeo(\n            p1 = cbind(start_lng, start_lat),\n            p2 = cbind(end_lng, end_lat)\n        ) / 1000 * 0.62137119,\n        mph = (miles / (trip_time / 60))\n    ) |&gt;\n    # It's somewhat nonsensical to rent a bike for distances easily walked. \n    # Also, there could be randomly generated data.\n    dplyr::filter(miles &gt; 0.1,\n                  # Seems that pro cyclists average around 20 mph, \n                  # so I set that as the ceiling.\n                  mph &lt; 21,\n                  # To account for time spent idling, stoplights and traffic.\n                  mph &gt; 1) |&gt;\n    duckdb::dbWriteTable(conn = dbconn,\n                         name = \"fltrd_tripData\")\n\n\nWriting the Filtered Parquet File\n\n\nCode\n#|label: 'write fltrdData parquet'\n\ndir.create(\"fltrdData\")\n\ndplyr::tbl(dbconn,\n           \"fltrd_tripData\") |&gt;\n    arrow::to_arrow() |&gt;\n    arrow::write_parquet(sink = \"fltrdData/fltrd.parquet\")\n\n# Now we have a filtered data file. \nunlink('tripdata', recursive = TRUE)\n\n\n\n\nCode\nduckdb::dbDisconnect(dbconn, shutdown = TRUE)\n\ntripset &lt;- arrow::open_dataset(\"fltrdData\",\n                               format = \"parquet\")\n\ndbconn &lt;- DBI::dbConnect(duckdb::duckdb())\n\n# For querying the arrow dataset with the benefits of an OLAP database. \nduckdb::duckdb_register_arrow(dbconn,\n                              \"fltrd_data\",\n                              tripset)\n\n\n\n\nCode\n#|label: 'rider count by hour table'\n\nhours_of_Riders &lt;- dplyr::tbl(dbconn,\n                           \"fltrd_data\") |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::mutate(\"hour\" = lubridate::hour(started_at)) |&gt;\n    dplyr::group_by(hour) |&gt;\n    dplyr::summarise(\"riding\" = dplyr::count(started_at)) |&gt;\n    dplyr::arrange(hour) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(\"hour\" = hms::hms(hours = hour),\n                  \"hour\" = format(strptime(hour, format = \"%H\"), \"%r\"),\n                  \"index\" = seq(1:24))\n\n\n\n\n\nCode\nggplot2::ggplot(data = hours_of_Riders,\n                mapping = ggplot2::aes(\n                    x = reorder(hour, .data$index),\n                    y = riding,\n                    fill = riding\n                )) +\n    ggplot2::geom_col() +\n    ggplot2::coord_radial(start = 2 * pi,\n                          inner.radius = .2) +\n    ggplot2::xlab(NULL) +\n    ggplot2::ylab(NULL) +\n    ggplot2::scale_fill_distiller(palette = 'Spectral',\n                                  direction = 1) +\n    ggplot2::labs(\n        title = \"Average Riders by the Hour of Day\",\n        subtitle = \"(Jan-Dec 2023)\",\n        caption = \"Data from cyclistic database.\",\n        tag = \"Figure 1.c\"\n    ) +\n    ggplot2::theme(\n        title = ggplot2::element_text(size = 16,lineheight = 4),\n        text = ggplot2::element_text(color = \"white\"),\n        panel.background = ggplot2::element_rect(fill = \"black\"),\n        panel.grid.minor = ggplot2::element_line(color = \"black\"),\n        panel.grid.major = ggplot2::element_line(color = \"grey10\"),\n        plot.background = ggplot2::element_rect(fill = \"black\"),\n        axis.text.y = ggplot2::element_blank(),\n        axis.ticks.y = ggplot2::element_blank(),\n        axis.text.x = ggplot2::element_text(size = 10,\n                                            color = \"grey90\"),\n        legend.background = ggplot2::element_rect(fill = \"black\"),\n        legend.ticks = ggplot2::element_line(color = \"black\",\n                                             linewidth = .5),\n        legend.text = ggplot2::element_text(color = 'grey80',\n                                             size = 8),\n        legend.title = ggplot2::element_blank(),\n        legend.position = \"right\",\n        legend.justification = \"center\",\n        legend.direction = \"vertical\"\n    )\n\n\n\n\n\nThe time of day people tend to be riding."
  },
  {
    "objectID": "bikeShare.html#visualizations",
    "href": "bikeShare.html#visualizations",
    "title": "BikeShare",
    "section": "",
    "text": "for quick reference with using Tsibble syntax\n\n\nCode\n#|label: 'grouped tibb'\n\ngrouped_byDay &lt;- dplyr::tbl(dbconn,\n                            \"fltrd_data\") |&gt;\n    dplyr::select(started_at,\n                  member_casual) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(started_at = as.Date(started_at)) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual) |&gt;\n    dplyr::summarize(n = dplyr::n(),\n                     sdev = stats::sd(n))\n\n\n\n\nCode\n#|label: 'to grouped tsibb'\n\n# tsibble, time-series table/tibble seems to make time series plots more straightforward\ngrouped_tsi &lt;- grouped_byDay |&gt;\n    tsibble::as_tsibble(key = c(member_casual,\n                                n),\n                        index = started_at) |&gt;\n    dplyr::arrange(started_at)\n\n\n\n\nCode\n#|label: \"map query setup\"\n\n# chicago starting coordinates for leaflet, setView\nchicago &lt;- maps::us.cities |&gt;\n    dplyr::select(\"name\",\n                  \"long\",\n                  \"lat\") |&gt;\n    dplyr::filter(name == \"Chicago IL\")\n\n# full dataset coordinates, might need to sample\ncoordQry &lt;- dplyr::tbl(dbconn,\n                       \"fltrd_data\") |&gt;\n    dplyr::select(start_lng,\n                  start_lat) |&gt;\n    dplyr::add_count(start_lng,\n                     start_lat) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::arrange(desc(n)) |&gt;\n    dplyr::collect()\n\n\ncoordQry_small &lt;- dplyr::tbl(dbconn,\n                       \"fltrd_data\") |&gt;\n    dplyr::select(start_lng,\n                  start_lat) |&gt;\n    dplyr::add_count(start_lng,\n                     start_lat) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::arrange(desc(n)) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::slice_head(n = 50)\n\n\n\n\nCode\n#|label: \"mapview\"\n\ncoordQry_small |&gt;\n    sf::st_as_sf(coords = c(1:2),\n                crs = 4326) |&gt;\n    mapview::mapview()\n\n\n\n\n\n\n\n\nCode\nojs_define(js_tsi = grouped_tsi)\n\n\n\n\nCode\njsData = transpose(js_tsi)\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.plot({\n    grid: true,\n    color: {legend: true},\n    marks: [\n        Plot.dot(jsData, {x: 'started_at', y: 'n', fill: 'member_casual'})\n]\n})\n\n\n\n\n\n\n\n\n\n\nCode\nPlot.lineY(jsData, {x: \"started_at\", y: \"n\"}).plot()\n\n\n\n\n\n\n\n\n\nCode\nInputs.table(jsData, {\nrows: 20\n})\n\n\n\n\n\n\n\n\n\nCode\n#|label: 'grouped stats tibb'\n\n# Need a useful data frame for basic aggregations\ngroupedStats_byDay &lt;- dplyr::tbl(dbconn,\n                            \"fltrd_data\") |&gt;\n    dplyr::select(started_at,\n                  member_casual,\n                  rideable_type,\n                  trip_time,\n                  miles,\n                  mph) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::mutate(started_at = as.Date(started_at)) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual,\n                    rideable_type) |&gt;\n    dplyr::summarize(n = dplyr::n(),\n                     trip_time_Mean = mean(trip_time),\n                     trip_time_stDev = stats::sd(trip_time),\n                     miles_Mean = mean(miles),\n                     miles_stDev = stats::sd(miles),\n                     mph_Mean = mean(miles),\n                     mph_stDev = stats::sd(mph))\n\n\n\n\nCode\n#|label: 'grouped stats tsibb'\n\n# Would prefer to work with a tsibble for time-series data\ngroupedStats_tsib &lt;- groupedStats_byDay |&gt;\n    tsibble::as_tsibble(key = c(member_casual:mph_stDev),\n                        index = started_at) |&gt;\n    dplyr::arrange(started_at)\n\n\n\n\nCode\n# A solution to help visualize these mutli-dimensional relationships of membership and bike type to time.\ngroupedStats_tsib |&gt;\n    ggplot2::ggplot(ggplot2::aes(x = started_at,\n                                 y = trip_time_Mean,\n                                 color = trip_time_Mean)) +\n    ggplot2::geom_count(size = 3) +\n    ggplot2::facet_wrap(~member_casual+rideable_type) +\n    ggplot2::scale_x_date(date_minor_breaks = \"days\",\n                          date_labels = \"%b\",\n                          breaks = \"months\") +\n    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45,\n                                                       hjust = 1),\n                   panel.background = ggplot2::element_rect(fill = 'grey20'),\n                   panel.grid.major.y = ggplot2::element_line(\n                       linetype = 'dashed',\n                       color = 'grey30'),\n                   panel.grid.major.x = ggplot2::element_line(\n                       linetype = 'dotted',\n                       color = 'grey30'),\n                   panel.grid.minor = ggplot2::element_blank(),\n                   strip.background.x = ggplot2::element_rect(\n                       fill = 'yellowgreen')) +\n    ggplot2::scale_color_distiller(palette = 'Spectral')\n\n\n\n\n\n\n\n\n\n\n\nCode\n#|label: \"dygraph\"\n\nsumDF &lt;- groupedStats_byDay |&gt;\n    dplyr::select(started_at,\n                  n) |&gt;\n    dplyr::group_by(started_at,\n                    member_casual) |&gt;\n    dplyr::summarise(\"count\" = sum(n)) |&gt;\n    tidyr::pivot_wider(names_from = member_casual,\n                       values_from = count)\n\ndygraphs::dygraph(sumDF, main = \"ever\",\n                  ylab = \"what\") |&gt;\n    dygraphs::dyGroup(name = c(\"member\", \"casual\"),\n                       color = c(\"green\", \"red\"))\n\n\n\n\n\n\nThese maps track bike-sharing activity going on worldwide and in Chicago.\nBike Share Map (“Bike Share Map: Chicago (Divvy),” n.d.)\nCityBikes: bike sharing networks around the world (“CityBikes: Bike Sharing Networks Around the World,” n.d.)\n\n\nCode\n#|label: 'drops duckDB tables'\n\n# a chunk for easily dropping either all (default) or specific tables from the ddb. Also made it so you can see the current tables and then the tables after running the chunk.\n\npaths &lt;- duckdb::dbListTables(dbconn)\n\npaths[]\n\ndrops_tables &lt;- function(path) {\n    \n    duckdb::dbRemoveTable(dbconn, \n                          path)\n}\n\npaths[] |&gt; purrr::walk(drops_tables)\n\npaths &lt;- duckdb::dbListTables(dbconn)\n\npaths[]\n\n\n\n\nCode\n#|label: 'duckDB Shutdown'\n\nduckdb::dbDisconnect(dbconn, shutdown = TRUE)\n\n\n\n\nCode\nunlink(\"fltrdData\", recursive = TRUE)"
  }
]