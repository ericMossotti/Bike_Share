[
  {
    "objectID": "index.html#stakeholders",
    "href": "index.html#stakeholders",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n1.1 Stakeholders",
    "text": "1.1 Stakeholders\nThe primary stakeholders in this analysis are Divvy, Lyft (the parent company of Divvy), and the City of Chicago Department of Transportation. The analysis aims to provide these stakeholders with data-driven insights to enhance the Divvy bike-sharing service, better serving the residents of Chicago and its users. The initial rationale behind Divvy’s implementation included improving air quality, promoting economic recovery, and reducing traffic congestion within the city. (About Divvy)\n\nAbout divvy: Company & history | divvy bikes. https://divvybikes-marketing-staging.lyft.net/about"
  },
  {
    "objectID": "index.html#source",
    "href": "index.html#source",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n1.2 Source",
    "text": "1.2 Source\n\nThe raw 2023 dataset was imported from Divvy Data. (Divvy Data)\n\nDivvy data. https://divvybikes.com/system-data\n\n\n\n\nCode# List of column labels to feed tabler() and add_multiple_footnotes()\nlocation_list &lt;- dplyr::tbl(dbconn, original_path) |&gt;\n    dplyr::collect() |&gt;\n    colnames() |&gt;\n    as.list()\n\n# A simple list of footnotes to feed tabler() and add_multiple_footnotes().\nnote_list &lt;- list(\"Anonymized trip identifier.\", \"The bicycle type.\", \"Starting date-time (to the second).\",\n    \"Ending date-time (to the second).\", \"Station name of where the trip started.\",\n    \"Station ID of where the trip started.\", \"Station name of where the trip ended.\",\n    \"Station ID of where the trip ended.\", \"Latitude associated with the starting location.\",\n    \"Longitude associated with the starting location.\", \"Latitude associated with the ending location.\",\n    \"Longitude associated with the ending location.\", \"If someone is an annual subscriber or not.\")\n\ndplyr::tbl(dbconn, original_path) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::slice_head(n = 10) |&gt;\n    tabler(title = \"The Original Data\", source_note = gt::md(\"**Source**: Divvy Data\"),\n        note_list = note_list, location_list = location_list, noteColumns = TRUE) |&gt;\n    gt::tab_options(table.font.size = gt::pct(75), footnotes.multiline = FALSE)\n\n\nTable 1: Raw data\n\n\n\n\n\n\n\nThe Original Data\n    \n\nride_id1\n\n      rideable_type2\n\n      started_at3\n\n      ended_at4\n\n      start_station_name5\n\n      start_station_id6\n\n      end_station_name7\n\n      end_station_id8\n\n      start_lat9\n\n      start_lng10\n\n      end_lat11\n\n      end_lng12\n\n      member_casual13\n\n    \n\n\n\nF96D5A74A3E41399\nelectric_bike\n2023-01-21 20:05:42\n2023-01-21 20:16:33\nLincoln Ave & Fullerton Ave\nTA1309000058\nHampden Ct & Diversey Ave\n202480.0\n42\n−88\n42\n−88\nmember\n\n\n13CB7EB698CEDB88\nclassic_bike\n2023-01-10 15:37:36\n2023-01-10 15:46:05\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\nBD88A2E670661CE5\nelectric_bike\n2023-01-02 07:51:57\n2023-01-02 08:05:11\nWestern Ave & Lunt Ave\nRP-005\nValli Produce - Evanston Plaza\n599\n42\n−88\n42\n−88\ncasual\n\n\nC90792D034FED968\nclassic_bike\n2023-01-22 10:52:58\n2023-01-22 11:01:44\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\n3397017529188E8A\nclassic_bike\n2023-01-12 13:58:01\n2023-01-12 14:13:20\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\n58E68156DAE3E311\nelectric_bike\n2023-01-31 07:18:03\n2023-01-31 07:21:16\nLakeview Ave & Fullerton Pkwy\nTA1309000019\nHampden Ct & Diversey Ave\n202480.0\n42\n−88\n42\n−88\nmember\n\n\n2F7194B6012A98D4\nelectric_bike\n2023-01-15 21:18:36\n2023-01-15 21:32:36\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\nDB1CF84154D6A049\nclassic_bike\n2023-01-25 10:49:01\n2023-01-25 10:58:22\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\n34EAB943F88C4C5D\nelectric_bike\n2023-01-25 20:49:47\n2023-01-25 21:02:14\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\nBC8AB1AA51DA9115\nclassic_bike\n2023-01-06 16:37:19\n2023-01-06 16:49:52\nKimbark Ave & 53rd St\nTA1309000037\nGreenwood Ave & 47th St\nTA1308000002\n42\n−88\n42\n−88\nmember\n\n\n\n\nSource: Divvy Data\n    \n\n\n        \n1 Anonymized trip identifier. 2 The bicycle type. 3 Starting date-time (to the second). 4 Ending date-time (to the second). 5 Station name of where the trip started. 6 Station ID of where the trip started. 7 Station name of where the trip ended. 8 Station ID of where the trip ended. 9 Latitude associated with the starting location. 10 Longitude associated with the starting location. 11 Latitude associated with the ending location. 12 Longitude associated with the ending location. 13 If someone is an annual subscriber or not.\n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nGlimpse\n\n\n\n\n\n\n\n\nA ‘glimpse’ function output of the raw data with data type information.dplyr::tbl(dbconn, original_path) |&gt;\n    dplyr::collect() |&gt;\n    tibble::glimpse()\n\nRows: 5,719,877\nColumns: 13\n$ ride_id            &lt;chr&gt; \"F96D5A74A3E41399\", \"13CB7EB698CEDB88\", \"BD88A2E670…\n$ rideable_type      &lt;chr&gt; \"electric_bike\", \"classic_bike\", \"electric_bike\", \"…\n$ started_at         &lt;dttm&gt; 2023-01-21 20:05:42, 2023-01-10 15:37:36, 2023-01-…\n$ ended_at           &lt;dttm&gt; 2023-01-21 20:16:33, 2023-01-10 15:46:05, 2023-01-…\n$ start_station_name &lt;chr&gt; \"Lincoln Ave & Fullerton Ave\", \"Kimbark Ave & 53rd …\n$ start_station_id   &lt;chr&gt; \"TA1309000058\", \"TA1309000037\", \"RP-005\", \"TA130900…\n$ end_station_name   &lt;chr&gt; \"Hampden Ct & Diversey Ave\", \"Greenwood Ave & 47th …\n$ end_station_id     &lt;chr&gt; \"202480.0\", \"TA1308000002\", \"599\", \"TA1308000002\", …\n$ start_lat          &lt;dbl&gt; 41.92407, 41.79957, 42.00857, 41.79957, 41.79957, 4…\n$ start_lng          &lt;dbl&gt; -87.64628, -87.59475, -87.69048, -87.59475, -87.594…\n$ end_lat            &lt;dbl&gt; 41.93000, 41.80983, 42.03974, 41.80983, 41.80983, 4…\n$ end_lng            &lt;dbl&gt; -87.64000, -87.59938, -87.69941, -87.59938, -87.599…\n$ member_casual      &lt;chr&gt; \"member\", \"member\", \"casual\", \"member\", \"member\", \"…\n\n\n\n\n\n\n\nR console output of the raw data"
  },
  {
    "objectID": "index.html#design",
    "href": "index.html#design",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n1.3 Design",
    "text": "1.3 Design\nAnother worthy objective of this analysis is to achieve reproducibility and efficiency. To facilitate future research and enable subsequent analyst teams to build upon this work, the project aimed to provide adequate code documentation and adhere to best practices regarding clean and modular code.\nFor instance, certain design decisions were incorporated to eliminate the need for re-downloading and re-processing data. For analysts conducting analysis over an extended period, such as days or months, on this dataset, it is now possible to simply reconnect to the single database file containing all the original data, including tables generated throughout the analysis process, following the initial download and subsequent processing.\nThe underlying code incorporates an if-else decision, which includes a source code script responsible for handling the initial data processing and establishing the database filesystem. Opting for a persistent DuckDB filesystem (as opposed to a purely in-memory solution) appeared optimal in terms of simplicity, cost-effectiveness of SQL database queries, and retaining progress made over extended periods. (Why DuckDB)\n\nWhy DuckDB. https://duckdb.org/why_duckdb.html\nTo streamline the process, reduce code duplication, and maintain consistent formatting throughout the project, reusable functions were developed for generating most of the tables and figures. These functions are located in the “Scripts” folder within the working directory. Their modular design not only simplifies the implementation of formatting changes but also facilitates the integration of additional code snippets when necessary. For instance, certain plots might require limiting the range of the axes, which can be achieved by combining these functions with appropriate code addendum. By leveraging these functions, the project benefits from reduced redundancy, improved efficiency, and cohesive formatting across all visualizations and data representations."
  },
  {
    "objectID": "index.html#initial-database-table-list",
    "href": "index.html#initial-database-table-list",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n1.4 Initial Database Table List",
    "text": "1.4 Initial Database Table List\n\nThese are the starting tables contained in the data/data.db file. Noting this as we will be adding many more tables in the later stages.dbList &lt;- duckdb::dbListTables(dbconn) |&gt;\n    as.data.frame() |&gt;\n    tabler(title = \"Database Tables\", note_list = list(gt::md(\"Tables in `db/data.db` at this stage\")),\n        location_list = list(\"duckdb::dbListTables(dbconn)\"), noteColumns = TRUE,\n        source_note = gt::md(\"**Source**: `db/data.db`\")) |&gt;\n    gt::cols_label(`duckdb::dbListTables(dbconn)` = \"Table Paths\") |&gt;\n    gt::cols_align(align = \"left\")\n\ndbList\n\n\nTable 2: Initial DB Table List\n\n\n\n\n\n\n\nDatabase Tables\n    \n\nTable Paths1\n\n    \n\n\ndb/complete_data.db\ndb/original_data.db\n\n\n\nSource: db/data.db\n\n    \n\n\n1 Tables in db/data.db at this stage\n    \n\n\n\n\n\n\n\n\n\n\nA view of the filesystem directory. Notice there are not separate files for tables. Technically, data.db, in this view, does not represent a table name, but the name of the database."
  },
  {
    "objectID": "index.html#duplicates",
    "href": "index.html#duplicates",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n2.1 Duplicates",
    "text": "2.1 Duplicates\n\n\n\nCode to Remove Duplicates\n\n\n\n\n\n\n\n\nFirst, record original observations from the raw data.# Need to save this count for the summary table later\noriginal_nobs &lt;- dplyr::tbl(dbconn, original_path) |&gt;\n    dplyr::collect() |&gt;\n    nrow()\n\n\n\nCreate a table containing the duplicated observations.# This is a separate table used to analyze the observations returned as not\n# distinct (n &gt; 1). This adds an extra column, labeled 'n'.\ndupeTable &lt;- dplyr::tbl(dbconn, complete_path) |&gt;\n    dplyr::select(started_at:end_station_name) |&gt;\n    # Counts of unique rows added for column 'n'\ndplyr::add_count(started_at, ended_at, start_station_name, end_station_name) |&gt;\n    # Only observations that have been duplicated 1 or more times are shown.\ndplyr::filter(n &gt; 1) |&gt;\n    # To see all rows, not just one row for each obs.\ndplyr::ungroup() |&gt;\n    dplyr::arrange(started_at) |&gt;\n    dplyr::collect()\n\n\n\nRecord a count of distinct duplicates and total observations.distinctCopiesCount &lt;- dupeTable |&gt;\n    dplyr::distinct(n) |&gt;\n    as.integer()\n\nduplicateObs &lt;- length(dupeTable[[1]])\n\n\n\nCreate a table of the now unduplicated observations seen earlier.# The issue is, we need to get rid of not all of these rows, but just the extra\n# duplicate observations.\n\n# If there were 2 rows of duplicates, one would want to end up with 1 row after\n# removing the extras.\nundupedTable &lt;- dupeTable |&gt;\n    dplyr::distinct(started_at, start_station_name, ended_at, end_station_name)\n\n\n\nRecord a count of the incorrect observations.# Run an incorrect count on how many rows or observations there are in the\n# dataset.\ncount_incorrectDists &lt;- dplyr::tbl(dbconn, complete_path) |&gt;\n    dplyr::distinct(dplyr::pick(\"ride_id\")) |&gt;\n    dplyr::count(name = \"Incorrect Distinct Observations\") |&gt;\n    dplyr::collect() |&gt;\n    as.integer()\n\n\n\nRecord a count of the correct observations.# For the correct count of obs\ncount_correctDists &lt;- dplyr::tbl(dbconn, complete_path) |&gt;\n    dplyr::distinct(dplyr::pick(\"started_at\", \"start_station_name\", \"ended_at\", \"end_station_name\")) |&gt;\n    dplyr::count() |&gt;\n    dplyr::collect() |&gt;\n    as.integer()\n\n\n\nLastly, write the unduplicated data to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/data_unduped.db\"))) {\n    dplyr::tbl(dbconn, complete_path) |&gt;\n        dplyr::distinct(started_at, start_station_name, ended_at, end_station_name,\n            .keep_all = TRUE) |&gt;\n        dplyr::arrange(started_at) |&gt;\n        dplyr::collect() |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/data_unduped.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\nA crucial question arises: How can one identify and handle duplicate data? This section covers the process of checking for duplicates and selectively removing them while exercising caution. It is essential to recognize that the presence of unique values in a single column does not necessarily guarantee the uniqueness of each observation or row.\nWhile all values in the ride_id column were found to be unique, not all observations were truly distinct. To verify the uniqueness of each observation, additional columns such as start_time, end_time, start_station, and end_station were utilized. These columns provide more granular information, including the precise starting and ending times down to the second, as well as the starting and ending locations. It was assumed that observations with identical starting and ending date-times and stations, despite having different rider IDs, were potentially erroneous duplicates.\n\n\n\nCodegtDupes &lt;- dupeTable |&gt;\ndplyr::group_by(started_at) |&gt;\ngt::gt(\nrowname_col = \"row\",\ngroupname_col = \"started_at\",\nrow_group_as_column = TRUE\n) |&gt;\ngt::tab_style(\nstyle = list(\ngt::cell_text(weight = \"bold\", align = \"center\"),\ngt::cell_borders(sides = c(\"bottom\"))\n),\nlocations = gt::cells_column_labels(gt::everything())\n) |&gt;\ngt::tab_style(\nstyle = list(\ngt::cell_borders(sides = c(\"left\", \"right\"), color = \"transparent\"),\ngt::cell_text(align = \"center\", v_align = \"middle\")\n),\nlocations = gt::cells_body(gt::everything())\n) |&gt;\ngt::data_color(\ncolumns = start_station_name,\ntarget_columns = gt::everything(),\nmethod = \"auto\",\npalette = \"basetheme::brutal\"\n) |&gt;\ngt::tab_header(title = \"A view of duplicated observations\", subtitle = \"Grouping follows the starting date-time value\") |&gt;\ngt::tab_options(\nheading.title.font.weight = \"bolder\",\nheading.subtitle.font.weight = \"lighter\",\nheading.align = \"center\",\ntable.background.color = \"transparent\",\ntable.font.color = \"SeaShell\",\ntable.font.size = gt::pct(75),\n) |&gt;\ngt::tab_source_note(source_note = gt::md(\"**Source**: `db/data_complete.db`\"))\n\n\ngtDupes\n\n\nTable 3: Duplicates Table\n\n\n\n\n\n\n\nA view of duplicated observations\n\n\nGrouping follows the starting date-time value\n\n\n\nended_at\nstart_station_name\nstart_station_id\nend_station_name\nn\n\n\n\n\n2023-02-19 12:10:52\n2023-02-19 12:24:04\nOrleans St & Merchandise Mart Plaza\nTA1305000022\nGreen St & Randolph St*\n2\n\n\n2023-02-19 12:24:04\nOrleans St & Merchandise Mart Plaza\nTA1305000022\nGreen St & Randolph St*\n2\n\n\n2023-04-15 15:56:18\n2023-04-15 16:01:54\nKedzie Ave & 45th St\n342\nFairfield Ave & 44th St\n2\n\n\n2023-04-15 16:01:54\nKedzie Ave & 45th St\n342\nFairfield Ave & 44th St\n2\n\n\n2023-04-21 09:45:26\n2023-04-21 10:01:23\nMichigan Ave & 8th St\n623\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-04-21 10:01:23\nMichigan Ave & 8th St\n623\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-07-08 18:22:07\n2023-07-08 18:37:31\nMilwaukee Ave & Grand Ave\n13033\nBissell St & Armitage Ave*\n2\n\n\n2023-07-08 18:37:31\nMilwaukee Ave & Grand Ave\n13033\nBissell St & Armitage Ave*\n2\n\n\n2023-07-08 18:58:14\n2023-07-08 19:08:47\nClark St & Schiller St\nTA1309000024\nBissell St & Armitage Ave*\n2\n\n\n2023-07-08 19:08:47\nClark St & Schiller St\nTA1309000024\nBissell St & Armitage Ave*\n2\n\n\n2023-07-09 18:00:17\n2023-07-09 18:40:49\nWells St & Hubbard St\nTA1307000151\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-07-09 18:40:49\nWells St & Hubbard St\nTA1307000151\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-07-10 20:10:41\n2023-07-10 20:19:59\nClark St & Newport St\n632\nLincoln Ave & Roscoe St*\n2\n\n\n2023-07-10 20:19:59\nClark St & Newport St\n632\nLincoln Ave & Roscoe St*\n2\n\n\n2023-07-15 10:48:09\n2023-07-15 10:58:22\nRacine Ave & Wrightwood Ave\nTA1309000059\nBissell St & Armitage Ave*\n2\n\n\n2023-07-15 10:58:22\nRacine Ave & Wrightwood Ave\nTA1309000059\nBissell St & Armitage Ave*\n2\n\n\n2023-07-15 19:38:51\n2023-07-15 19:55:04\nAvondale Ave & Irving Park Rd\n15624\nPublic Rack - Hamlin Ave & Fullerton Ave\n2\n\n\n2023-07-15 19:55:04\nAvondale Ave & Irving Park Rd\n15624\nPublic Rack - Hamlin Ave & Fullerton Ave\n2\n\n\n2023-07-23 11:41:36\n2023-07-23 12:07:13\nBurnham Harbor\n15545\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-07-23 12:07:13\nBurnham Harbor\n15545\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-07-25 18:08:47\n2023-07-25 18:21:45\nWabash Ave & Roosevelt Rd\nTA1305000002\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-07-25 18:21:45\nWabash Ave & Roosevelt Rd\nTA1305000002\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-07-26 21:10:55\n2023-07-26 21:28:44\nBurnham Harbor\n15545\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-07-26 21:28:44\nBurnham Harbor\n15545\nFort Dearborn Dr & 31st St*\n2\n\n\n2023-08-05 19:40:37\n2023-08-05 20:08:35\nMorgan St & Lake St*\nchargingstx4\nMorgan St & Lake St*\n2\n\n\n2023-08-05 20:08:35\nMorgan St & Lake St*\nchargingstx4\nMorgan St & Lake St*\n2\n\n\n2023-08-12 17:46:53\n2023-08-12 17:57:40\nCalumet Ave & 18th St\n13102\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-08-12 17:57:40\nCalumet Ave & 18th St\n13102\nWentworth Ave & Cermak Rd*\n2\n\n\n2023-08-17 12:23:50\n2023-08-17 12:37:45\nDuSable Lake Shore Dr & Monroe St\n13300\nStreeter Dr & Grand Ave\n2\n\n\n2023-08-17 12:37:45\nDuSable Lake Shore Dr & Monroe St\n13300\nStreeter Dr & Grand Ave\n2\n\n\n2023-09-03 14:55:59\n2023-09-03 15:58:21\nBissell St & Armitage Ave*\nchargingstx1\nBissell St & Armitage Ave*\n2\n\n\n2023-09-03 15:58:21\nBissell St & Armitage Ave*\nchargingstx1\nBissell St & Armitage Ave*\n2\n\n\n2023-09-25 17:38:05\n2023-09-25 17:52:29\nFairbanks Ct & Grand Ave\nTA1305000003\nDuSable Lake Shore Dr & North Blvd\n2\n\n\n2023-09-25 17:52:29\nFairbanks Ct & Grand Ave\nTA1305000003\nDuSable Lake Shore Dr & North Blvd\n2\n\n\n2023-10-10 13:22:51\n2023-10-10 13:29:37\nLoomis St & Lexington St\n13332\nMorgan St & Polk St\n2\n\n\n2023-10-10 13:29:37\nLoomis St & Lexington St\n13332\nMorgan St & Polk St\n2\n\n\n\n\nSource: db/data_complete.db\n\n\n\n\n\n\n\n\n\n\n\nAlthough the cause of such duplication errors is unknown, it could be assumed that one person checked out multiple bikes simultaneously. In that scenario, each bike would be assigned a unique ride_id. However, this occurrence was relatively rare, happening only 18 times over the course of a year. Since there is only one duplicate for each instance, it raises concerns and warrants further investigation. It is possible that trips could be grouped where one person pays for another rider’s fare. However, if that were the case, it raises the question of why there is always precisely one duplicate.\nIn Table 3, duplicate observations are listed and grouped by color for visual clarity. In contrast, Table 4 presents the data after removing the extra copy of each duplicate observation while preserving the unique observations. Of the duplicates identified, each had one extra copy. It was noted that the number of rows in the duplicates table is 36. Each duplicated observation has one duplicate, where n (the count) is always 2. Therefore, the expected number of observations to be removed was 18. A complication arose in determining how to remove not all observations but only the extra duplicate observation from each group.\n\n\n\nCodegt_undupes &lt;- undupedTable |&gt;\ndplyr::collect() |&gt;\ndplyr::group_by(started_at) |&gt;\ngt::gt(\nrowname_col = \"row\",\ngroupname_col = \"started_at\",\nrow_group_as_column = TRUE\n) |&gt;\ngt::fmt_number(decimals = 0) |&gt;\ngt::tab_style(\nstyle = list(\ngt::cell_text(weight = \"bold\", align = \"center\"),\ngt::cell_borders(sides = c(\"bottom\"))\n),\nlocations = gt::cells_column_labels(gt::everything())\n) |&gt;\ngt::tab_style(\nstyle = list(\ngt::cell_borders(sides = c(\"left\", \"right\")),\ngt::cell_text(align = \"center\", v_align = \"middle\")\n),\nlocations = gt::cells_body(gt::everything())\n) |&gt;\ngt::data_color(\ncolumns = start_station_name,\ntarget_columns = gt::everything(),\nmethod = \"auto\",\npalette = \"basetheme::brutal\"\n) |&gt;\ngt::tab_header(title = \"After duplicates were removed\", subtitle = \"Same grouping\") |&gt;\ngt::tab_options(\nheading.title.font.weight = \"bolder\",\nheading.subtitle.font.weight = \"lighter\",\nheading.align = \"center\",\ntable.background.color = \"transparent\",\ntable.font.color = \"SeaShell\",\ntable.font.size = gt::pct(75)\n) |&gt;\ngt::tab_source_note(source_note = gt::md(\"**Source**: `db/data_complete.db`\"))\n\ngt_undupes\n\n\nTable 4: Un-duplicated Table\n\n\n\n\n\n\n\nAfter duplicates were removed\n\n\nSame grouping\n\n\n\nstart_station_name\nended_at\nend_station_name\n\n\n\n\n2023-02-19 12:10:52\nOrleans St & Merchandise Mart Plaza\n2023-02-19 12:24:04\nGreen St & Randolph St*\n\n\n2023-04-15 15:56:18\nKedzie Ave & 45th St\n2023-04-15 16:01:54\nFairfield Ave & 44th St\n\n\n2023-04-21 09:45:26\nMichigan Ave & 8th St\n2023-04-21 10:01:23\nWentworth Ave & Cermak Rd*\n\n\n2023-07-08 18:22:07\nMilwaukee Ave & Grand Ave\n2023-07-08 18:37:31\nBissell St & Armitage Ave*\n\n\n2023-07-08 18:58:14\nClark St & Schiller St\n2023-07-08 19:08:47\nBissell St & Armitage Ave*\n\n\n2023-07-09 18:00:17\nWells St & Hubbard St\n2023-07-09 18:40:49\nFort Dearborn Dr & 31st St*\n\n\n2023-07-10 20:10:41\nClark St & Newport St\n2023-07-10 20:19:59\nLincoln Ave & Roscoe St*\n\n\n2023-07-15 10:48:09\nRacine Ave & Wrightwood Ave\n2023-07-15 10:58:22\nBissell St & Armitage Ave*\n\n\n2023-07-15 19:38:51\nAvondale Ave & Irving Park Rd\n2023-07-15 19:55:04\nPublic Rack - Hamlin Ave & Fullerton Ave\n\n\n2023-07-23 11:41:36\nBurnham Harbor\n2023-07-23 12:07:13\nFort Dearborn Dr & 31st St*\n\n\n2023-07-25 18:08:47\nWabash Ave & Roosevelt Rd\n2023-07-25 18:21:45\nWentworth Ave & Cermak Rd*\n\n\n2023-07-26 21:10:55\nBurnham Harbor\n2023-07-26 21:28:44\nFort Dearborn Dr & 31st St*\n\n\n2023-08-05 19:40:37\nMorgan St & Lake St*\n2023-08-05 20:08:35\nMorgan St & Lake St*\n\n\n2023-08-12 17:46:53\nCalumet Ave & 18th St\n2023-08-12 17:57:40\nWentworth Ave & Cermak Rd*\n\n\n2023-08-17 12:23:50\nDuSable Lake Shore Dr & Monroe St\n2023-08-17 12:37:45\nStreeter Dr & Grand Ave\n\n\n2023-09-03 14:55:59\nBissell St & Armitage Ave*\n2023-09-03 15:58:21\nBissell St & Armitage Ave*\n\n\n2023-09-25 17:38:05\nFairbanks Ct & Grand Ave\n2023-09-25 17:52:29\nDuSable Lake Shore Dr & North Blvd\n\n\n2023-10-10 13:22:51\nLoomis St & Lexington St\n2023-10-10 13:29:37\nMorgan St & Polk St\n\n\n\n\nSource: db/data_complete.db\n\n\n\n\n\n\n\n\n\n\n\nTo ensure the accurate removal of duplicates, the count of distinct n-values (representing the number of occurrences) for the un-duplicated table was computed, confirming the expected 18 unique instances. Subsequently, the total number of observations in the dataset was recorded, initially standing at 4,331,707. After removing the identified duplicate observations, the correct count of observations was 4,331,689. In summary, 18 additional observations were successfully removed, aligning with the expected number of duplicates identified earlier. These steps are documented in Table 5 for reference.\nBy carefully analyzing the count of distinct n-values and the total observation count before and after reduplication, it was ensured that only the precise number of duplicate observations was removed, preserving the integrity of the unique data while eliminating the identified duplicates. This meticulous approach to data cleaning is crucial for maintaining data quality and reliability throughout the analysis process.\n\n\n\nCode used for handling duplicates in this section"
  },
  {
    "objectID": "index.html#outliers",
    "href": "index.html#outliers",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n2.2 Outliers",
    "text": "2.2 Outliers\n\n\n\nTransform and Filter the Database\n\n\n\n\n\n\n\n\nIf you happen to be re-using this code - this is so you do not have to re-download or re-filter after making further adjustments.filtered_path &lt;- \"db/filtered_data.db\"\n\n# Do we still need to filter the database?\nif (duckdb::dbExistsTable(dbconn, filtered_path) == FALSE) {\n    source(\"Scripts/transFilter.R\")\n    transFilter(conxn = dbconn, oldPath = \"db/data_unduped.db\", newPath = filtered_path)\n}\n\n\n\n\n\nThis would execute if the if-else conditions were met to filter the db/data.db database table# ----\n# Author: Eric Mossotti\n# CC-BY SA\n# ----\n# Performs data transformations and filters to enforce consistency across\n# all of the analyses. It also will simplify query syntax in extended analyses.\n# Filtering can be based on flexible, but sensible criteria.\n# ----\ntransFilter &lt;- function(conxn, oldPath, newPath) {\n    dplyr::tbl(conxn, oldPath) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(\n            \"trip_time\" = lubridate::time_length(lubridate::interval(started_at, ended_at), \n                                                 unit = \"minute\"),\n            miles = geosphere::distGeo(\n                p1 = cbind(start_lng, start_lat),\n                p2 = cbind(end_lng, end_lat)\n            ) / 1000 * 0.62137119,\n            mph = (miles / (trip_time / 60)),\n            .keep = \"all\",\n        ) |&gt; \n        # Floor rationale -  less than 0.1 miles are distances easily walked\n        # Speed ceiling rationale - pro cyclists average around 20 mph\n        # Speed floor rationale - accounts for trips possibly spent idling\n        # rideable_type rationale - docked_bike stopped being recorded as a distinct\n        # category within the time being analyzed (2023)\n        # docked_bike was phased out and not much info about what it means\n        dplyr::filter(\n            trip_time &gt; 1,\n            trip_time &lt; 480,\n            rideable_type != \"docked_bike\",\n            miles &gt;= 0.1,\n            mph &lt;= 20,\n            mph &gt;= 1\n        ) |&gt;\n        duckdb::dbWriteTable(conn = conxn,\n                             name = newPath,\n                             overwrite = TRUE)\n}\n\n\n\n\n\nObservations deemed erroneous or irrelevant for identifying usage trends among members and casual users were filtered out. Keeping track of these errors is a good practice, as they might provide insights into the differences in how members and casuals utilize the service.\nTrips with negative duration were flagged as errors and removed. Additionally, trips lasting less than a minute but greater than zero were noted and removed, as they could potentially skew the derived statistics. These extremely short trips might be attributed to users briefly trying out the service before committing or quickly realizing their dissatisfaction with it. While some observations seemed nonsensical, most of the data was retained.\nConsistent with the previous approach, an if-else decision was employed to facilitate testing. An external database filtering script was utilized to streamline the code within the main Quarto document. The resulting filtered data served as the foundation for subsequent analysis and table generation.\n\n\nTo get a count of the new total observations after filtering.count_filtered &lt;- dplyr::tbl(dbconn, filtered_path) |&gt;\n    dplyr::select(ride_id) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::count() |&gt;\n    dplyr::collect() |&gt;\n    as.integer()\n\n\n\n\n\nCode# To see the history of obs in our dataset.\nsummaryProcessTable &lt;- tidyr::tribble(\n~ \"Observations\",\n~ \"Counts\",\n\"Original   \",\noriginal_nobs,\n\"Complete Observations   \",\ncount_incorrectDists,\n\"Duplicates   \",\n(count_incorrectDists - count_correctDists),\n\"Filtered     \",\n(count_correctDists - count_filtered),\n\"Total Corrected   \",\ncount_filtered\n) |&gt;\ngt::gt(rownames_to_stub = FALSE) |&gt;\ngt::tab_header(title = \"Tallying Observations\") |&gt;\ngt::tab_footnote(\nfootnote = gt::md(\"Row counts throughout the cleaning steps.\"),\nlocations = gt::cells_column_labels(columns = Counts)\n) |&gt;\ngt::tab_style(\nstyle = list(\ngt::cell_borders(sides = \"bottom\"),\ngt::cell_text(\nalign = \"left\",\nstretch = \"semi-expanded\",\nwhitespace = \"break-spaces\"\n)\n),\nlocations = gt::cells_body(gt::everything())\n) |&gt;\ngt::tab_style(\ngt::cell_text(\nalign = \"center\",\nstretch = \"semi-expanded\",\nwhitespace = \"break-spaces\"\n),\nlocations = list(\ngt::cells_title(groups = c(\"title\", \"subtitle\")),\ngt::cells_column_labels(gt::everything())\n)\n) |&gt;\ngt::fmt_number(decimals = 0) |&gt;\ngt::tab_options(\ncolumn_labels.font.weight = \"bold\",\ntable.background.color = \"transparent\",\ntable.font.color = \"SeaShell\",\nrow.striping.background_color = \"gray10\",\nrow.striping.include_table_body = TRUE\n) |&gt;\ngt::tab_source_note(source_note = gt::md(\"**Sources**: `db/data_original.db`, `db/data_complete.db`, `db/data_unduped.db`, `db/data_filtered.db`\"))\n\nsummaryProcessTable\n\n\nTable 5: Observation Processing History\n\n\n\n\n\n\n\nTallying Observations\n    \n\nObservations\n      Counts1\n\n    \n\n\n\nOriginal   \n5,719,877\n\n\nComplete Observations   \n4,331,707\n\n\nDuplicates   \n18\n\n\nFiltered     \n434,291\n\n\nTotal Corrected   \n3,897,398\n\n\n\n\nSources: db/data_original.db, db/data_complete.db, db/data_unduped.db, db/data_filtered.db\n\n    \n\n\n1 Row counts throughout the cleaning steps.\n    \n\n\n\n\n\n\n\n\n\n\nOutlier and additional transformations"
  },
  {
    "objectID": "index.html#sec-membership",
    "href": "index.html#sec-membership",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.1 Membership",
    "text": "3.1 Membership\n\n\n\n\n\n\n\n\n\n\nTable 7 and Figure 1 gives an idea of the membership distribution.\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDatabase Code\n\n\n\n\n\n\n\n\nWrite … to db/… .dbif (isFALSE(duckdb::dbExistsTable(dbconn, \"db/membership.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(member_casual) |&gt;\n        dplyr::arrange(member_casual) |&gt;\n        dplyr::collect() |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/membership.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/membership.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 6: Kable output\n\n\n\n\nmember_casual\n\n\n\ncasual\n\n\ncasual\n\n\ncasual\n\n\ncasual\n\n\ncasual\n\n\ncasual\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/membership.db\", select_cols = \"member_casual\",\n    group_cols = \"member_casual\", doWeights = TRUE) |&gt;\n    plotter(x_col = member_casual, y_col = n, geomType = \"column\", title = \"Membership Types\",\n        x_label = \"Rider Types\", y_label = \"n\")\n\ngplot\n\n\n\n\n\n\nFigure 1: Total Member Frequency\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/membership.db\", select_cols = \"member_casual\",\n    group_cols = \"member_casual\", doWeights = TRUE) |&gt;\n    tabler(title = \"Membership\", note_list = list(\"membership status\", \"observation count\"),\n        location_list = c(\"member_casual\", \"n\"), source_note = gt::md(\"**Source**: `db/membership.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 7: Total Member Frequency\n\n\n\n\n\n\n\nMembership\n    \n\nMembership1\n\n      n2\n\n    \n\n\n\ncasual\n1,260,621\n\n\nmember\n2,636,777\n\n\n\n\nSource: db/membership.db\n\n    \n\n\n\n1 membership status\n    \n\n\n2 observation count"
  },
  {
    "objectID": "index.html#sec-btypes",
    "href": "index.html#sec-btypes",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.2 Cycle Types",
    "text": "3.2 Cycle Types\n\n\n\n\n\n\n\n\n\nTable 10 and Figure 2 gives an idea of the rideable_type parameter’s distribution.\nTable 11 and Figure 3 summarizes the bicycle type frequencies by membership status.\n\nTable 12 presents a Chi-Square analysis of bicycle type usage among casual users and members. There is a statistically significant association between bicycle type and membership status (p &lt; 0.001).\n\nMembers show a higher preference for classic bikes (65%) compared to casual users (59%). Casual users have a higher proportion of electric bike usage (41%) compared to members (35%).\nBoth casual users and members prefer classic bikes over electric bikes.\nThe very low p-value (&lt; 0.001) indicates strong evidence against the null hypothesis of no association between bicycle type and membership status. This suggests that the choice of bicycle type is not independent of membership status.\nThe large χ² value (14762.37) with just 1 degree of freedom (calculated as [rows - 1] * [columns - 1]) results in the very small p-value (&lt; 0.001). This combination strongly suggests that the difference in bike type preference between casual users and members is not due to random chance. However, with such a large sample size (nearly 4 million total users), even small differences can produce statistically significant results.\n\n\n\nTable 13 presents the results of a binary logistic regression analyzing the relationship between bicycle type and membership status. The analysis compares two types of bicycles: classic bikes and electric bikes, with classic bikes serving as the reference category.\n\nThe odds of membership for users of electric bikes were 0.76 times the odds for users of classic bikes. Statistical Significance: The difference in membership likelihood between electric and classic bike users is highly statistically significant (p &lt; 0.001).\n\n\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite bType.db to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/bType.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(rideable_type, member_casual) |&gt;\n        dplyr::arrange(rideable_type, member_casual) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(rideable_type = forcats::as_factor(rideable_type)) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/bType.db\", overwrite = TRUE)\n}\n\n\n\n\n\nTransform and write as a weighted binary table for modeling.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/bType_wb.db\"))) {\n    transformData(conn = dbconn, path = \"db/bType.db\", select_cols = c(\"rideable_type\",\n        \"member_casual\"), group_cols = c(\"rideable_type\", \"member_casual\"), binary_col = \"member_casual\",\n        zero_val = \"casual\", one_val = \"member\", doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/bType_wb.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/bType.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/bType_wb.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 8: Kable output\n\n\n\n\nrideable_type\nmember_casual\n\n\n\nclassic_bike\ncasual\n\n\nclassic_bike\ncasual\n\n\nclassic_bike\ncasual\n\n\nclassic_bike\ncasual\n\n\nclassic_bike\ncasual\n\n\nclassic_bike\ncasual\n\n\n\n\n\n\n\n\n\n\n\nTable 9: Kable output\n\n\n\n\nrideable_type\nmember_casual\nn\n\n\n\nclassic_bike\ncasual\n739475\n\n\nclassic_bike\nmember\n1714250\n\n\nelectric_bike\ncasual\n521146\n\n\nelectric_bike\nmember\n922527\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/bType.db\", select_cols = \"rideable_type\",\n    group_cols = \"rideable_type\", doWeights = TRUE) |&gt;\n    plotter(x_col = rideable_type, y_col = n, geomType = \"column\", title = \"Bicycle Type\",\n        x_label = \"Type\", y_label = \"n\")\n\ngplot\n\n\n\n\n\n\nFigure 2: Bicycle type frequencies\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/bType.db\", select_cols = \"rideable_type\",\n    group_cols = \"rideable_type\", doWeights = TRUE) |&gt;\n    tabler(title = \"Bicycle Types\", note_list = list(\"bicycle type\", \"observation count\"),\n        location_list = list(\"rideable_type\", \"n\"), source_note = gt::md(\"**Source**: `db/bType.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(rideable_type = \"Type\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = rideable_type, align = \"left\")\n\n\nTable 10: Cycle Type Total Frequency\n\n\n\n\n\n\n\nBicycle Types\n    \n\nType1\n\n      n2\n\n    \n\n\n\nclassic_bike\n2,453,725\n\n\nelectric_bike\n1,443,673\n\n\n\n\nSource: db/bType.db\n\n    \n\n\n\n1 bicycle type\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nChi-Squared\nBinary Logistic Regression\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/bType.db\", select_cols = c(\"rideable_type\",\n    \"member_casual\"), group_cols = c(\"rideable_type\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Bicycle Groups\", x_label = \"Type\", y_label = \"n\", x_col = rideable_type,\n        y_col = n, group_col = member_casual, geomType = \"column\", is_colGroup = TRUE,\n        color_col = \"black\", colPosition = \"dodge\", colGroup_palette = \"Paired\")\n\ngplot\n\n\n\n\n\n\nFigure 3: Bicycle type membership frequencies\n\n\n\n\n\n\n\n\nCodelocation_list &lt;- list(\"member_casual\", \"n\")\n\nnote_list &lt;- list(\"membership status\", \"observation count\")\n\ntransformData(conn = dbconn, path = \"db/bType.db\", select_cols = c(\"rideable_type\",\n    \"member_casual\"), group_cols = c(\"rideable_type\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Bicycle Type - Membership\", groupName = \"rideable_type\", location = n,\n        label_n = \"n\", note_list = note_list, location_list = location_list, source_note = gt::md(\"**Source**: `db/bType.db`\"),\n        noteColumns = TRUE, isStub = TRUE, stub_label = \"Type\", stub_note = \"bicycle type\") |&gt;\n    gt::cols_label(member_casual = \"Membership\", rideable_type = \"Bicycle Type\") |&gt;\n    gt::cols_label(rideable_type = \"Type\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 11: Bicycle type membership frequencies\n\n\n\n\n\n\n\nBicycle Type - Membership\n    \n\nType1\n\n      Membership2\n\n      n3\n\n    \n\n\n\nclassic_bike\ncasual\n739,475\n\n\nmember\n1,714,250\n\n\nelectric_bike\ncasual\n521,146\n\n\nmember\n922,527\n\n\n\n\nSource: db/bType.db\n\n    \n\n\n\n1 bicycle type\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\nThe script I used to process the Chi-Squared test result. This code is reposted with all the chi-square tables in this report.# ----\n# Author: Eric Mossotti\n# CC BY-SA\n# ----\n# The code for returning chi-square test results as a tibble for use in tables.\n# ----\nchisqTest &lt;- function(data, variable, by) {\n    test_result &lt;- chisq.test(x = data[[variable]], y = data[[by]]) |&gt;\n        broom::tidy() |&gt;\n        dplyr::select(statistic, parameter, p.value)\n    \n    return(test_result)\n}\n\n\n\nSave the chi-square statistic and degrees of freedom values in a tibble format to add to the gtsummary table.data_tibble &lt;- dplyr::tbl(dbconn, \"db/bType.db\") |&gt;\n    dplyr::select(rideable_type, member_casual) |&gt;\n    dplyr::collect()\n\nchiResult &lt;- chisqTest(data = data_tibble, variable = \"rideable_type\", by = \"member_casual\")\n\n\n\nCodechi_table &lt;- tabler(title = \"Chi-Squared: Bicycle Type\", source_note = gt::md(\"**Source**: `db/bType.db`\"),\n    label = list(rideable_type = \"Bicycle Type\"), by = member_casual, isSummary = TRUE,\n    chiVar = \"rideable_type\", chiBy = \"member_casual\", tbl_name = data_tibble, chi_result = chiResult)\n\nchi_table\n\n\nTable 12: Bicycle type membership distributions\n\n\n\n\n\n\n\nChi-Squared: Bicycle Type\n    \n\nCharacteristic\n      \ncasual, N = 1,260,6211\n\n      \nmember, N = 2,636,7771\n\n      \np-value2\n\n    \n\n\n\nBicycle Type\n\n\n&lt;0.001\n\n\n    classic_bike\n739,475 (59%)\n1,714,250 (65%)\n\n\n\n    electric_bike\n521,146 (41%)\n922,527 (35%)\n\n\n\n\n\nSource: db/bType.db\n\n    \n\n\n\n1 n (%);   χ²  = 14762.37;   df = 1\n    \n\n\n2 Pearson’s Chi-squared test\n    \n\n\n\n\n\n\n\n\n\n\n\nPredicting the log-odds of being a member versus being a casual user based on …model &lt;- dplyr::tbl(dbconn, \"db/bType_wb.db\") |&gt;\n    glm(formula = member_casual ~ rideable_type, weights = n, family = binomial)\n\n\n\nCoderegression_tbl &lt;- model |&gt;\n    gtsummary::tbl_regression(label = list(rideable_type = \"Cycle Type\"), conf.int = FALSE,\n        exponentiate = TRUE)\n\nregression_tbl |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Bicycle Type\"), source_note = gt::md(\"**Source**: `db/bType_wb.db`\"),\n        isBinary = TRUE)\n\n\nTable 13\n\n\n\n\n\n\n\nBinary Logistic Regression:  Bicycle Type\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nCycle Type\n\n\n\n\n    classic_bike\n—\n\n\n\n    electric_bike\n0.76\n&lt;0.001\n\n\n\n\nSource: db/bType_wb.db\n\n    \n\n\n1 OR = Odds Ratio"
  },
  {
    "objectID": "index.html#sec-duration",
    "href": "index.html#sec-duration",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.3 Duration",
    "text": "3.3 Duration\n\n\n\n\n\n\n\n\n\nTable 16 and Figure 4 give an idea of the duration distribution.\nTable 17 and Figure 5 summarize the duration distribution by membership.\nTable 18 gives the reader some idea of the variability, range, and quartile information about the duration data.\n\nFigure 6 shows a density plot comparing the duration of trips for two groups: “casual” users and “members”. The x-axis represents time in minutes, ranging from 0 to 100, while the y-axis shows the density (a measure of relative frequency).\n\nBoth groups exhibit right-skewed distributions, with a peak near the left side and a long tail extending to the right. This suggests that for both groups, shorter durations are more common, while longer durations occur less frequently but can extend quite far.\nThe “member” group (darker blue) has a higher and narrower peak compared to the “casual” group (lighter blue). This indicates that members tend to have a more concentrated distribution of session durations around their most common length.\nThe “casual” group appears to have a slightly fatter tail, extending further to the right than the “member” group. This suggests that casual users might occasionally have longer sessions than members, even if it’s less common.\nBoth groups seem to have their peak density around 5-10 minutes, with members peaking slightly earlier than casual users.\nThe total area under each curve represents the entire population for that group. The curves appear to have similar total areas, suggesting the sample sizes might be comparable.\nThere’s significant overlap between the two distributions, indicating that while there are differences, there’s also considerable similarity in duration patterns between casual users and members.\n\n\n\nTable 19 presents the results of a binary logistic regression analyzing the relationship between ride duration and membership status. The analysis divides ride durations into four quartiles, with Q1 (1.02 - 5.73 minutes) serving as the reference category.\n\nCompared to Q1, the odds of being a member versus a casual rider varied significantly across the other duration quartiles (p &lt; 0.001 for all comparisons).\nIn Q2 (5.73 - 9.55 minutes), the odds of membership were 0.38 times as high as in Q1. This indicates a substantial decrease (62%) in the likelihood of membership for slightly longer rides.\nIn Q3 (9.55 - 16.13 minutes), the odds of membership were 0.08 times as high as in Q1. This shows a dramatic decrease (92%) in membership likelihood for medium-length rides.\nIn Q4 (16.13 - 475.22 minutes), the odds of membership were 0.06 times as high as in Q1. This represents an even more pronounced decrease (94%) in membership likelihood for the longest rides.\n\n\nTo visualize the full duration dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 7 (the solid yellow line represents the mean).\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite … to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/duration.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(trip_time, member_casual) |&gt;\n        dplyr::arrange(trip_time, member_casual) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(trip_time = round(trip_time, digits = 2), mins = round(trip_time,\n            digits = 0), mins = forcats::as_factor(mins)) |&gt;\n        dplyr::arrange(trip_time, member_casual) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/duration.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery … .db, transform and write weighted quartile data to … _wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/duration_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/duration.db\", select_cols = c(\"trip_time\",\n        \"member_casual\"), group_cols = c(\"trip_time\", \"member_casual\"), binary_col = \"member_casual\",\n        pred_col = \"trip_time\", ntile_col = \"quartile\", zero_val = \"casual\", one_val = \"member\",\n        qtile_levels = c(\"Q1 (1.02 - 5.73]\", \"Q2 (5.73 - 9.55]\", \"Q3 (9.55 - 16.13]\",\n            \"Q4 (16.13 - 475.22]\"), doQuantile = TRUE, doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/duration_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/duration.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/duration_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 14: Kable output\n\n\n\n\ntrip_time\nmember_casual\nmins\n\n\n\n1.02\ncasual\n1\n\n\n1.02\ncasual\n1\n\n\n1.02\ncasual\n1\n\n\n1.02\ncasual\n1\n\n\n1.02\nmember\n1\n\n\n1.02\nmember\n1\n\n\n\n\n\n\n\n\n\n\n\nTable 15: Kable output\n\n\n\n\ntrip_time\nmember_casual\nn\nquartile\n\n\n\n1.02\ncasual\n4\nQ1 (1.02 - 5.73]\n\n\n1.02\nmember\n153\nQ1 (1.02 - 5.73]\n\n\n1.03\ncasual\n7\nQ1 (1.02 - 5.73]\n\n\n1.03\nmember\n149\nQ1 (1.02 - 5.73]\n\n\n1.05\ncasual\n8\nQ1 (1.02 - 5.73]\n\n\n1.05\nmember\n182\nQ1 (1.02 - 5.73]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/duration.db\", select_cols = \"mins\",\n    group_cols = \"mins\", doWeights = TRUE) |&gt;\n    plotter(x_col = as.integer(mins), y_col = n, geomType = \"column\", title = \"Duration\",\n        x_label = \"Minutes\", y_label = \"Overall Trips\", color_col = \"black\") + ggplot2::scale_x_continuous(limits = c(0,\n    100), breaks = seq(0, 100, by = 5), guide = ggplot2::guide_axis(n.dodge = 1,\n    angle = 45))\n\ngplot\n\n\n\n\n\n\nFigure 4: Trip Duration Totals\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/duration.db\", select_cols = \"mins\", group_cols = \"mins\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Duration\", note_list = list(\"trip duration\", \"observation count\"),\n        location_list = list(\"mins\", \"n\"), source_note = gt::md(\"**Source**: `db/duration.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(mins = \"Minutes\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = mins, align = \"center\")\n\n\nTable 16: Trip-Time Totals\n\n\n\n\n\n\n\nDuration\n    \n\nMinutes1\n\n      n2\n\n    \n\n\n\n1\n11,712\n\n\n2\n109,700\n\n\n3\n212,213\n\n\n4\n282,122\n\n\n5\n288,960\n\n\n6\n291,295\n\n\n7\n264,824\n\n\n8\n252,680\n\n\n9\n221,983\n\n\n10\n206,307\n\n\n11\n176,905\n\n\n12\n162,289\n\n\n13\n139,963\n\n\n14\n128,094\n\n\n15\n109,254\n\n\n16\n100,585\n\n\n17\n85,815\n\n\n18\n79,498\n\n\n19\n69,038\n\n\n20\n63,928\n\n\n21\n55,184\n\n\n22\n51,877\n\n\n23\n45,435\n\n\n24\n42,596\n\n\n25\n37,041\n\n\n26\n34,652\n\n\n27\n30,606\n\n\n28\n28,605\n\n\n29\n25,154\n\n\n30\n23,712\n\n\n31\n21,143\n\n\n32\n19,696\n\n\n33\n17,808\n\n\n34\n16,396\n\n\n35\n14,606\n\n\n36\n13,646\n\n\n37\n12,219\n\n\n38\n11,851\n\n\n39\n10,433\n\n\n40\n9,795\n\n\n41\n8,683\n\n\n42\n8,167\n\n\n43\n7,069\n\n\n44\n6,685\n\n\n45\n5,842\n\n\n46\n5,360\n\n\n47\n4,589\n\n\n48\n4,425\n\n\n49\n3,936\n\n\n50\n3,726\n\n\n51\n3,274\n\n\n52\n3,090\n\n\n53\n2,859\n\n\n54\n2,790\n\n\n55\n2,458\n\n\n56\n2,351\n\n\n57\n2,136\n\n\n58\n2,068\n\n\n59\n1,897\n\n\n60\n1,876\n\n\n61\n1,626\n\n\n62\n1,578\n\n\n63\n1,417\n\n\n64\n1,455\n\n\n65\n1,256\n\n\n66\n1,236\n\n\n67\n1,115\n\n\n68\n1,167\n\n\n69\n984\n\n\n70\n961\n\n\n71\n908\n\n\n72\n872\n\n\n73\n829\n\n\n74\n835\n\n\n75\n755\n\n\n76\n745\n\n\n77\n657\n\n\n78\n689\n\n\n79\n622\n\n\n80\n632\n\n\n81\n585\n\n\n82\n566\n\n\n83\n500\n\n\n84\n479\n\n\n85\n443\n\n\n86\n478\n\n\n87\n432\n\n\n88\n382\n\n\n89\n416\n\n\n90\n388\n\n\n91\n337\n\n\n92\n354\n\n\n93\n301\n\n\n94\n309\n\n\n95\n260\n\n\n96\n273\n\n\n97\n238\n\n\n98\n266\n\n\n99\n229\n\n\n100\n217\n\n\n101\n241\n\n\n102\n245\n\n\n103\n203\n\n\n104\n215\n\n\n105\n190\n\n\n106\n190\n\n\n107\n169\n\n\n108\n167\n\n\n109\n154\n\n\n110\n148\n\n\n111\n161\n\n\n112\n161\n\n\n113\n160\n\n\n114\n129\n\n\n115\n125\n\n\n116\n147\n\n\n117\n153\n\n\n118\n120\n\n\n119\n106\n\n\n120\n96\n\n\n121\n116\n\n\n122\n85\n\n\n123\n104\n\n\n124\n86\n\n\n125\n99\n\n\n126\n119\n\n\n127\n87\n\n\n128\n84\n\n\n129\n94\n\n\n130\n74\n\n\n131\n62\n\n\n132\n90\n\n\n133\n77\n\n\n134\n64\n\n\n135\n66\n\n\n136\n67\n\n\n137\n84\n\n\n138\n72\n\n\n139\n62\n\n\n140\n60\n\n\n141\n53\n\n\n142\n36\n\n\n143\n46\n\n\n144\n37\n\n\n145\n55\n\n\n146\n44\n\n\n147\n65\n\n\n148\n44\n\n\n149\n54\n\n\n150\n39\n\n\n151\n47\n\n\n152\n43\n\n\n153\n45\n\n\n154\n37\n\n\n155\n36\n\n\n156\n42\n\n\n157\n29\n\n\n158\n33\n\n\n159\n32\n\n\n160\n33\n\n\n161\n27\n\n\n162\n37\n\n\n163\n28\n\n\n164\n26\n\n\n165\n35\n\n\n166\n31\n\n\n167\n30\n\n\n168\n38\n\n\n169\n12\n\n\n170\n26\n\n\n171\n19\n\n\n172\n25\n\n\n173\n20\n\n\n174\n20\n\n\n175\n30\n\n\n176\n21\n\n\n177\n11\n\n\n178\n18\n\n\n179\n13\n\n\n180\n19\n\n\n181\n17\n\n\n182\n13\n\n\n183\n12\n\n\n184\n11\n\n\n185\n17\n\n\n186\n9\n\n\n187\n9\n\n\n188\n10\n\n\n189\n13\n\n\n190\n13\n\n\n191\n5\n\n\n192\n14\n\n\n193\n9\n\n\n194\n11\n\n\n195\n7\n\n\n196\n5\n\n\n197\n3\n\n\n198\n8\n\n\n199\n6\n\n\n200\n8\n\n\n201\n3\n\n\n202\n7\n\n\n203\n8\n\n\n204\n5\n\n\n205\n3\n\n\n206\n4\n\n\n207\n7\n\n\n208\n9\n\n\n209\n4\n\n\n210\n1\n\n\n211\n4\n\n\n212\n5\n\n\n213\n3\n\n\n214\n3\n\n\n215\n1\n\n\n216\n5\n\n\n217\n4\n\n\n218\n1\n\n\n219\n7\n\n\n220\n2\n\n\n221\n1\n\n\n222\n3\n\n\n223\n1\n\n\n224\n2\n\n\n225\n5\n\n\n226\n3\n\n\n227\n6\n\n\n228\n2\n\n\n229\n2\n\n\n230\n2\n\n\n231\n1\n\n\n232\n2\n\n\n233\n2\n\n\n234\n3\n\n\n235\n2\n\n\n236\n3\n\n\n238\n3\n\n\n239\n4\n\n\n240\n1\n\n\n241\n1\n\n\n242\n1\n\n\n243\n2\n\n\n244\n1\n\n\n246\n1\n\n\n247\n1\n\n\n248\n4\n\n\n249\n3\n\n\n250\n3\n\n\n252\n3\n\n\n254\n1\n\n\n256\n4\n\n\n257\n1\n\n\n259\n1\n\n\n260\n2\n\n\n261\n1\n\n\n262\n1\n\n\n263\n1\n\n\n264\n1\n\n\n265\n3\n\n\n266\n7\n\n\n267\n3\n\n\n268\n1\n\n\n269\n3\n\n\n270\n1\n\n\n271\n1\n\n\n272\n1\n\n\n273\n2\n\n\n274\n3\n\n\n275\n1\n\n\n279\n2\n\n\n281\n2\n\n\n284\n1\n\n\n286\n1\n\n\n287\n1\n\n\n292\n1\n\n\n293\n1\n\n\n294\n1\n\n\n295\n1\n\n\n299\n1\n\n\n301\n1\n\n\n303\n1\n\n\n305\n1\n\n\n312\n1\n\n\n313\n1\n\n\n316\n1\n\n\n320\n2\n\n\n321\n1\n\n\n322\n1\n\n\n325\n1\n\n\n326\n1\n\n\n327\n1\n\n\n333\n1\n\n\n334\n1\n\n\n335\n1\n\n\n336\n1\n\n\n340\n4\n\n\n341\n1\n\n\n346\n1\n\n\n349\n1\n\n\n368\n1\n\n\n369\n1\n\n\n377\n1\n\n\n398\n1\n\n\n406\n1\n\n\n424\n1\n\n\n471\n1\n\n\n475\n1\n\n\n\n\nSource: db/duration.db\n\n    \n\n\n\n1 trip duration\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nSummary Stats\nDensity\nBinary Logistic Regression\nHistogram Plot\n\n\n\n\n\nCodegplot &lt;- dplyr::tbl(dbconn, \"db/duration.db\") |&gt;\n    dplyr::select(mins, member_casual) |&gt;\n    dplyr::filter(as.integer(mins) &lt;= 100) |&gt;\n    dplyr::collect() |&gt;\n    transformData(conn = NULL, path = NULL, select_cols = c(\"mins\", \"member_casual\"),\n        group_cols = c(\"mins\", \"member_casual\"), doWeights = TRUE, isDF = TRUE) |&gt;\n    plotter(title = \"Duration Groups\", x_label = \"Minutes\", y_label = \"n\", x_col = mins,\n        y_col = n, group_col = member_casual, geomType = \"column\", is_colGroup = TRUE,\n        colPosition = ggplot2::position_stack(reverse = TRUE), color_col = \"black\") +\n    ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45),\n        breaks = forcats::as_factor(seq(0, 100, by = 5)))\n\ngplot\n\n\n\n\n\n\nFigure 5: Trip-Time Group Frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/duration.db\", select_cols = c(\"mins\", \"member_casual\"),\n    group_cols = c(\"mins\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Duration - Membership\", groupName = \"mins\", location = n, label_n = \"n\",\n        note_list = list(\"membership status\", \"observation count\"), location_list = list(\"member_casual\",\n            \"n\"), source_note = gt::md(\"**Source**: `db/duration.db`\"), noteColumns = TRUE,\n        isStub = TRUE, stub_label = \"Trip Time\", stub_note = \"trip duration (minutes)\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\") |&gt;\n    gt::cols_align(columns = \"mins\", align = \"center\")\n\n\nTable 17: Trip Time Comparison\n\n\n\n\n\n\n\nDuration - Membership\n    \n\nTrip Time1\n\n      Membership2\n\n      n3\n\n    \n\n\n\n1\ncasual\n880\n\n\nmember\n10,832\n\n\n2\ncasual\n14,808\n\n\nmember\n94,892\n\n\n3\ncasual\n39,423\n\n\nmember\n172,790\n\n\n4\ncasual\n62,621\n\n\nmember\n219,501\n\n\n5\ncasual\n71,625\n\n\nmember\n217,335\n\n\n6\ncasual\n78,289\n\n\nmember\n213,006\n\n\n7\ncasual\n76,446\n\n\nmember\n188,378\n\n\n8\ncasual\n76,284\n\n\nmember\n176,396\n\n\n9\ncasual\n69,783\n\n\nmember\n152,200\n\n\n10\ncasual\n66,354\n\n\nmember\n139,953\n\n\n11\ncasual\n58,888\n\n\nmember\n118,017\n\n\n12\ncasual\n55,308\n\n\nmember\n106,981\n\n\n13\ncasual\n48,937\n\n\nmember\n91,026\n\n\n14\ncasual\n45,360\n\n\nmember\n82,734\n\n\n15\ncasual\n39,607\n\n\nmember\n69,647\n\n\n16\ncasual\n36,901\n\n\nmember\n63,684\n\n\n17\ncasual\n32,199\n\n\nmember\n53,616\n\n\n18\ncasual\n30,249\n\n\nmember\n49,249\n\n\n19\ncasual\n27,066\n\n\nmember\n41,972\n\n\n20\ncasual\n25,171\n\n\nmember\n38,757\n\n\n21\ncasual\n22,183\n\n\nmember\n33,001\n\n\n22\ncasual\n21,114\n\n\nmember\n30,763\n\n\n23\ncasual\n18,764\n\n\nmember\n26,671\n\n\n24\ncasual\n17,793\n\n\nmember\n24,803\n\n\n25\ncasual\n15,523\n\n\nmember\n21,518\n\n\n26\ncasual\n14,652\n\n\nmember\n20,000\n\n\n27\ncasual\n13,050\n\n\nmember\n17,556\n\n\n28\ncasual\n12,451\n\n\nmember\n16,154\n\n\n29\ncasual\n10,983\n\n\nmember\n14,171\n\n\n30\ncasual\n10,291\n\n\nmember\n13,421\n\n\n31\ncasual\n9,203\n\n\nmember\n11,940\n\n\n32\ncasual\n8,770\n\n\nmember\n10,926\n\n\n33\ncasual\n8,081\n\n\nmember\n9,727\n\n\n34\ncasual\n7,357\n\n\nmember\n9,039\n\n\n35\ncasual\n6,715\n\n\nmember\n7,891\n\n\n36\ncasual\n6,414\n\n\nmember\n7,232\n\n\n37\ncasual\n5,827\n\n\nmember\n6,392\n\n\n38\ncasual\n5,600\n\n\nmember\n6,251\n\n\n39\ncasual\n5,002\n\n\nmember\n5,431\n\n\n40\ncasual\n4,787\n\n\nmember\n5,008\n\n\n41\ncasual\n4,331\n\n\nmember\n4,352\n\n\n42\ncasual\n4,117\n\n\nmember\n4,050\n\n\n43\ncasual\n3,691\n\n\nmember\n3,378\n\n\n44\ncasual\n3,628\n\n\nmember\n3,057\n\n\n45\ncasual\n3,229\n\n\nmember\n2,613\n\n\n46\ncasual\n3,166\n\n\nmember\n2,194\n\n\n47\ncasual\n2,833\n\n\nmember\n1,756\n\n\n48\ncasual\n2,795\n\n\nmember\n1,630\n\n\n49\ncasual\n2,554\n\n\nmember\n1,382\n\n\n50\ncasual\n2,470\n\n\nmember\n1,256\n\n\n51\ncasual\n2,299\n\n\nmember\n975\n\n\n52\ncasual\n2,170\n\n\nmember\n920\n\n\n53\ncasual\n1,971\n\n\nmember\n888\n\n\n54\ncasual\n2,040\n\n\nmember\n750\n\n\n55\ncasual\n1,764\n\n\nmember\n694\n\n\n56\ncasual\n1,742\n\n\nmember\n609\n\n\n57\ncasual\n1,561\n\n\nmember\n575\n\n\n58\ncasual\n1,556\n\n\nmember\n512\n\n\n59\ncasual\n1,492\n\n\nmember\n405\n\n\n60\ncasual\n1,468\n\n\nmember\n408\n\n\n61\ncasual\n1,285\n\n\nmember\n341\n\n\n62\ncasual\n1,263\n\n\nmember\n315\n\n\n63\ncasual\n1,115\n\n\nmember\n302\n\n\n64\ncasual\n1,115\n\n\nmember\n340\n\n\n65\ncasual\n983\n\n\nmember\n273\n\n\n66\ncasual\n1,022\n\n\nmember\n214\n\n\n67\ncasual\n907\n\n\nmember\n208\n\n\n68\ncasual\n954\n\n\nmember\n213\n\n\n69\ncasual\n815\n\n\nmember\n169\n\n\n70\ncasual\n789\n\n\nmember\n172\n\n\n71\ncasual\n758\n\n\nmember\n150\n\n\n72\ncasual\n730\n\n\nmember\n142\n\n\n73\ncasual\n692\n\n\nmember\n137\n\n\n74\ncasual\n692\n\n\nmember\n143\n\n\n75\ncasual\n636\n\n\nmember\n119\n\n\n76\ncasual\n635\n\n\nmember\n110\n\n\n77\ncasual\n556\n\n\nmember\n101\n\n\n78\ncasual\n586\n\n\nmember\n103\n\n\n79\ncasual\n538\n\n\nmember\n84\n\n\n80\ncasual\n531\n\n\nmember\n101\n\n\n81\ncasual\n484\n\n\nmember\n101\n\n\n82\ncasual\n480\n\n\nmember\n86\n\n\n83\ncasual\n431\n\n\nmember\n69\n\n\n84\ncasual\n413\n\n\nmember\n66\n\n\n85\ncasual\n377\n\n\nmember\n66\n\n\n86\ncasual\n407\n\n\nmember\n71\n\n\n87\ncasual\n380\n\n\nmember\n52\n\n\n88\ncasual\n324\n\n\nmember\n58\n\n\n89\ncasual\n361\n\n\nmember\n55\n\n\n90\ncasual\n331\n\n\nmember\n57\n\n\n91\ncasual\n301\n\n\nmember\n36\n\n\n92\ncasual\n302\n\n\nmember\n52\n\n\n93\ncasual\n268\n\n\nmember\n33\n\n\n94\ncasual\n268\n\n\nmember\n41\n\n\n95\ncasual\n232\n\n\nmember\n28\n\n\n96\ncasual\n237\n\n\nmember\n36\n\n\n97\ncasual\n212\n\n\nmember\n26\n\n\n98\ncasual\n238\n\n\nmember\n28\n\n\n99\ncasual\n204\n\n\nmember\n25\n\n\n100\ncasual\n189\n\n\nmember\n28\n\n\n101\ncasual\n213\n\n\nmember\n28\n\n\n102\ncasual\n212\n\n\nmember\n33\n\n\n103\ncasual\n175\n\n\nmember\n28\n\n\n104\ncasual\n195\n\n\nmember\n20\n\n\n105\ncasual\n164\n\n\nmember\n26\n\n\n106\ncasual\n170\n\n\nmember\n20\n\n\n107\ncasual\n150\n\n\nmember\n19\n\n\n108\ncasual\n140\n\n\nmember\n27\n\n\n109\ncasual\n132\n\n\nmember\n22\n\n\n110\ncasual\n129\n\n\nmember\n19\n\n\n111\ncasual\n145\n\n\nmember\n16\n\n\n112\ncasual\n143\n\n\nmember\n18\n\n\n113\ncasual\n143\n\n\nmember\n17\n\n\n114\ncasual\n113\n\n\nmember\n16\n\n\n115\ncasual\n118\n\n\nmember\n7\n\n\n116\ncasual\n132\n\n\nmember\n15\n\n\n117\ncasual\n137\n\n\nmember\n16\n\n\n118\ncasual\n110\n\n\nmember\n10\n\n\n119\ncasual\n92\n\n\nmember\n14\n\n\n120\ncasual\n88\n\n\nmember\n8\n\n\n121\ncasual\n102\n\n\nmember\n14\n\n\n122\ncasual\n76\n\n\nmember\n9\n\n\n123\ncasual\n95\n\n\nmember\n9\n\n\n124\ncasual\n79\n\n\nmember\n7\n\n\n125\ncasual\n86\n\n\nmember\n13\n\n\n126\ncasual\n108\n\n\nmember\n11\n\n\n127\ncasual\n76\n\n\nmember\n11\n\n\n128\ncasual\n78\n\n\nmember\n6\n\n\n129\ncasual\n84\n\n\nmember\n10\n\n\n130\ncasual\n68\n\n\nmember\n6\n\n\n131\ncasual\n54\n\n\nmember\n8\n\n\n132\ncasual\n85\n\n\nmember\n5\n\n\n133\ncasual\n64\n\n\nmember\n13\n\n\n134\ncasual\n56\n\n\nmember\n8\n\n\n135\ncasual\n61\n\n\nmember\n5\n\n\n136\ncasual\n57\n\n\nmember\n10\n\n\n137\ncasual\n74\n\n\nmember\n10\n\n\n138\ncasual\n68\n\n\nmember\n4\n\n\n139\ncasual\n56\n\n\nmember\n6\n\n\n140\ncasual\n56\n\n\nmember\n4\n\n\n141\ncasual\n48\n\n\nmember\n5\n\n\n142\ncasual\n33\n\n\nmember\n3\n\n\n143\ncasual\n42\n\n\nmember\n4\n\n\n144\ncasual\n35\n\n\nmember\n2\n\n\n145\ncasual\n45\n\n\nmember\n10\n\n\n146\ncasual\n41\n\n\nmember\n3\n\n\n147\ncasual\n62\n\n\nmember\n3\n\n\n148\ncasual\n39\n\n\nmember\n5\n\n\n149\ncasual\n52\n\n\nmember\n2\n\n\n150\ncasual\n37\n\n\nmember\n2\n\n\n151\ncasual\n45\n\n\nmember\n2\n\n\n152\ncasual\n41\n\n\nmember\n2\n\n\n153\ncasual\n41\n\n\nmember\n4\n\n\n154\ncasual\n34\n\n\nmember\n3\n\n\n155\ncasual\n34\n\n\nmember\n2\n\n\n156\ncasual\n35\n\n\nmember\n7\n\n\n157\ncasual\n24\n\n\nmember\n5\n\n\n158\ncasual\n27\n\n\nmember\n6\n\n\n159\ncasual\n28\n\n\nmember\n4\n\n\n160\ncasual\n29\n\n\nmember\n4\n\n\n161\ncasual\n22\n\n\nmember\n5\n\n\n162\ncasual\n28\n\n\nmember\n9\n\n\n163\ncasual\n26\n\n\nmember\n2\n\n\n164\ncasual\n23\n\n\nmember\n3\n\n\n165\ncasual\n29\n\n\nmember\n6\n\n\n166\ncasual\n28\n\n\nmember\n3\n\n\n167\ncasual\n25\n\n\nmember\n5\n\n\n168\ncasual\n33\n\n\nmember\n5\n\n\n169\ncasual\n11\n\n\nmember\n1\n\n\n170\ncasual\n25\n\n\nmember\n1\n\n\n171\ncasual\n16\n\n\nmember\n3\n\n\n172\ncasual\n22\n\n\nmember\n3\n\n\n173\ncasual\n19\n\n\nmember\n1\n\n\n174\ncasual\n17\n\n\nmember\n3\n\n\n175\ncasual\n28\n\n\nmember\n2\n\n\n176\ncasual\n19\n\n\nmember\n2\n\n\n177\ncasual\n10\n\n\nmember\n1\n\n\n178\ncasual\n16\n\n\nmember\n2\n\n\n179\ncasual\n13\n\n\n180\ncasual\n16\n\n\nmember\n3\n\n\n181\ncasual\n13\n\n\nmember\n4\n\n\n182\ncasual\n11\n\n\nmember\n2\n\n\n183\ncasual\n10\n\n\nmember\n2\n\n\n184\ncasual\n8\n\n\nmember\n3\n\n\n185\ncasual\n13\n\n\nmember\n4\n\n\n186\ncasual\n8\n\n\nmember\n1\n\n\n187\ncasual\n7\n\n\nmember\n2\n\n\n188\ncasual\n9\n\n\nmember\n1\n\n\n189\ncasual\n10\n\n\nmember\n3\n\n\n190\ncasual\n10\n\n\nmember\n3\n\n\n191\ncasual\n5\n\n\n192\ncasual\n13\n\n\nmember\n1\n\n\n193\ncasual\n8\n\n\nmember\n1\n\n\n194\ncasual\n9\n\n\nmember\n2\n\n\n195\ncasual\n6\n\n\nmember\n1\n\n\n196\ncasual\n5\n\n\n197\ncasual\n3\n\n\n198\ncasual\n7\n\n\nmember\n1\n\n\n199\ncasual\n5\n\n\nmember\n1\n\n\n200\ncasual\n8\n\n\n201\ncasual\n3\n\n\n202\ncasual\n6\n\n\nmember\n1\n\n\n203\ncasual\n8\n\n\n204\ncasual\n4\n\n\nmember\n1\n\n\n205\ncasual\n3\n\n\n206\ncasual\n4\n\n\n207\ncasual\n6\n\n\nmember\n1\n\n\n208\ncasual\n8\n\n\nmember\n1\n\n\n209\ncasual\n4\n\n\n210\ncasual\n1\n\n\n211\ncasual\n3\n\n\nmember\n1\n\n\n212\ncasual\n4\n\n\nmember\n1\n\n\n213\ncasual\n3\n\n\n214\ncasual\n2\n\n\nmember\n1\n\n\n215\ncasual\n1\n\n\n216\ncasual\n5\n\n\n217\ncasual\n2\n\n\nmember\n2\n\n\n218\ncasual\n1\n\n\n219\ncasual\n7\n\n\n220\ncasual\n2\n\n\n221\ncasual\n1\n\n\n222\ncasual\n3\n\n\n223\ncasual\n1\n\n\n224\ncasual\n2\n\n\n225\ncasual\n5\n\n\n226\ncasual\n3\n\n\n227\ncasual\n6\n\n\n228\ncasual\n2\n\n\n229\ncasual\n1\n\n\nmember\n1\n\n\n230\ncasual\n2\n\n\n231\ncasual\n1\n\n\n232\ncasual\n2\n\n\n233\ncasual\n2\n\n\n234\ncasual\n2\n\n\nmember\n1\n\n\n235\ncasual\n1\n\n\nmember\n1\n\n\n236\ncasual\n2\n\n\nmember\n1\n\n\n238\ncasual\n1\n\n\nmember\n2\n\n\n239\ncasual\n2\n\n\nmember\n2\n\n\n240\ncasual\n1\n\n\n241\ncasual\n1\n\n\n242\ncasual\n1\n\n\n243\ncasual\n2\n\n\n244\ncasual\n1\n\n\n246\nmember\n1\n\n\n247\ncasual\n1\n\n\n248\ncasual\n3\n\n\nmember\n1\n\n\n249\ncasual\n3\n\n\n250\ncasual\n3\n\n\n252\ncasual\n3\n\n\n254\ncasual\n1\n\n\n256\ncasual\n3\n\n\nmember\n1\n\n\n257\nmember\n1\n\n\n259\ncasual\n1\n\n\n260\ncasual\n2\n\n\n261\ncasual\n1\n\n\n262\nmember\n1\n\n\n263\ncasual\n1\n\n\n264\ncasual\n1\n\n\n265\ncasual\n3\n\n\n266\ncasual\n5\n\n\nmember\n2\n\n\n267\ncasual\n2\n\n\nmember\n1\n\n\n268\nmember\n1\n\n\n269\ncasual\n3\n\n\n270\ncasual\n1\n\n\n271\nmember\n1\n\n\n272\ncasual\n1\n\n\n273\ncasual\n2\n\n\n274\ncasual\n3\n\n\n275\ncasual\n1\n\n\n279\ncasual\n1\n\n\nmember\n1\n\n\n281\ncasual\n2\n\n\n284\ncasual\n1\n\n\n286\nmember\n1\n\n\n287\ncasual\n1\n\n\n292\ncasual\n1\n\n\n293\nmember\n1\n\n\n294\ncasual\n1\n\n\n295\ncasual\n1\n\n\n299\ncasual\n1\n\n\n301\ncasual\n1\n\n\n303\ncasual\n1\n\n\n305\ncasual\n1\n\n\n312\ncasual\n1\n\n\n313\ncasual\n1\n\n\n316\ncasual\n1\n\n\n320\ncasual\n1\n\n\nmember\n1\n\n\n321\ncasual\n1\n\n\n322\nmember\n1\n\n\n325\nmember\n1\n\n\n326\ncasual\n1\n\n\n327\nmember\n1\n\n\n333\nmember\n1\n\n\n334\ncasual\n1\n\n\n335\ncasual\n1\n\n\n336\nmember\n1\n\n\n340\ncasual\n1\n\n\nmember\n3\n\n\n341\nmember\n1\n\n\n346\ncasual\n1\n\n\n349\ncasual\n1\n\n\n368\ncasual\n1\n\n\n369\ncasual\n1\n\n\n377\nmember\n1\n\n\n398\ncasual\n1\n\n\n406\nmember\n1\n\n\n424\nmember\n1\n\n\n471\ncasual\n1\n\n\n475\ncasual\n1\n\n\n\n\nSource: db/duration.db\n\n    \n\n\n\n1 trip duration (minutes)\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\nCodegtTable &lt;- dplyr::tbl(dbconn, \"db/duration.db\") |&gt;\ndplyr::select(mins, member_casual) |&gt;\ndplyr::mutate(\nmins = as.numeric(mins)\n) |&gt;\ndplyr::collect() |&gt;\ngtsummary::tbl_summary(\nby = member_casual,\ntype = mins ~ \"continuous2\",\nlabel = list(mins ~ \"Duration (mins)\"),\ndigits = list(\nmins ~ c(1, 1)),\nstatistic = \ngtsummary::all_continuous() ~ c(\n\"{median} ({p25}, {p75})\", \n\"{mean} ({sd})\", \n\"{min}, {max}\")\n) |&gt;\ngtsummary::italicize_levels() |&gt;\ntabler(\ntitle = gt::md(\"Summary Statistics:&lt;br&gt;Duration - Membership\"),\nsource_note = gt::md(\"**Source**: `db/duration.db`\"),\nisBinary = TRUE\n)\n\ngtTable\n\n\nTable 18: Useful summary statistics.\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nDuration - Membership\n\n\nCharacteristic\n\ncasual, N = 1,260,621\n\nmember, N = 2,636,777\n\n\n\n\nDuration (mins)\n\n\n\n\n    Median (IQR)\n12.0 (7.0, 20.0)\n9.0 (5.0, 14.0)\n\n\n    Mean (SD)\n16.5 (15.8)\n11.3 (9.2)\n\n\n    Range\n1.0, 475.0\n1.0, 424.0\n\n\n\n\nSource: db/duration.db\n\n\n\n\n\n\n\n\n\n\n\n\n\nDensity plot for duration by membership.gplot &lt;- transformData(conn = dbconn, path = \"db/duration.db\", select_cols = c(\"trip_time\",\n    \"member_casual\")) |&gt;\n    plotter(title = \"Duration Group Density\", x_label = paste0(\"Minutes\"), x_col = trip_time,\n        group_col = member_casual, geomType = \"column\", angle = 45, color_col = \"black\",\n        density_alpha = 0.75, isDensity = TRUE, is_colGroup = TRUE, breaks = seq(0,\n            100, by = 5), limits = c(0, 100))\n\ngplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery …_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/duration_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Duration Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Duration & Membership\"),\n        source_note = gt::md(\"**Source**: `db/duration_wq.db`\"), isBinary = TRUE)\n\n\nTable 19\n\n\n\n\n\n\n\nBinary Logistic Regression:  Duration & Membership\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nDuration Ranges\n\n\n\n\n    Q1 (1.02 - 5.73]\n—\n\n\n\n    Q2 (5.73 - 9.55]\n0.38\n&lt;0.001\n\n\n    Q3 (9.55 - 16.13]\n0.08\n&lt;0.001\n\n\n    Q4 (16.13 - 475.22]\n0.06\n&lt;0.001\n\n\n\n\nSource: db/duration_wq.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\nCreate a data frame, then extract the desired quartile info to supplement histogram visualization for … data.qdf &lt;- dplyr::tbl(dbconn, \"db/duration.db\") |&gt;\n    dplyr::select(trip_time) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(qdf$trip_time, probs = c(0.25, 0.5, 0.75))\n\n\n\n\nCodegplot &lt;- qdf |&gt;\n    plotter(title = \"Duration\", x_label = \"Duration\", y_label = \"n\", x_col = trip_time,\n        geomType = \"column\", isHistogram = TRUE, angle = 45, color_col = \"transparent\",\n        vline_color = \"lightyellow\", vline_size = 0.5, low = \"blue\", high = \"red\",\n        limits = c(0, 100), breaks = seq(0, 100, by = 5), binwidth = \\(x)\n            2 * IQR(x)/(length(x)^(1/3)), quartiles = quartiles)\n\ngplot"
  },
  {
    "objectID": "index.html#sec-moy",
    "href": "index.html#sec-moy",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.4 Month",
    "text": "3.4 Month\n\n\n\n\n\n\n\n\n\nTable 22 and Figure 8 give an aggregated distribution of the monthly ridership frequencies.\nTable 23 and Figure 9 summarize the bicycle type frequencies by membership status.\nIn Table 24 the null hypothesis is rejected. The type of bicycle and the rider’s membership status can be considered dependent variables.\nTo visualize monthly users through the lens of their respective concentrations, see Figure 10. The plot looks a little different because I am directly plotting the x-axis using the original date-time data types. I think this maintains a more accurate view of the data.\n\nTable 25 presents the results of a binary logistic regression analyzing the relationship between months of the year and membership status. The analysis divides the year into four quartiles, with Q1 (January 01 - May 20) serving as the reference category. Compared to Q1, the odds of being a member versus a casual rider varied significantly across the other time quartiles (p &lt; 0.001 for all comparisons).\n\nIn Q2 (May 20 - Jul 21), the odds of membership were 0.57 times as high as in Q1. This indicates a substantial decrease (43%) in the likelihood of membership during late spring and early summer.\nIn Q3 (Jul 21 - Sep 18), the odds of membership were 0.58 times as high as in Q1. This shows a similar decrease (42%) in membership likelihood during late summer and early fall, nearly identical to Q2.\nIn Q4 (Sep 18 - Dec 31), the odds of membership were 0.87 times as high as in Q1. While still lower than Q1, this represents a less pronounced decrease (13%) in membership likelihood during fall and early winter.\n\n\nTo visualize the full monthly dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 11 (the solid yellow line represents the mean).\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite moy.db to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/moy.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(started_at, member_casual) |&gt;\n        dplyr::arrange(started_at) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(member_casual = factor(member_casual, levels = c(\"casual\",\n            \"member\")), abbMonths = lubridate::month(started_at, label = TRUE, abbr = TRUE),\n            abbMonths = forcats::as_factor(abbMonths)) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/moy.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery …, transform, and write weighted quartile data to …_wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/moy_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/moy.db\", select_cols = c(\"started_at\",\n        \"member_casual\"), group_cols = c(\"started_at\", \"member_casual\"), binary_col = \"member_casual\",\n        pred_col = \"started_at\", ntile_col = \"quartile\", zero_val = \"casual\", one_val = \"member\",\n        qtile_levels = c(\"Q1 (Jan 01 - May 20]\", \"Q2 (May 20 - Jul 21]\", \"Q3 (Jul 21 - Sep 18]\",\n            \"Q4 (Sep 18 - Dec 31]\"), doQuantile = TRUE, doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/moy_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/moy.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/moy_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 20: Kable output for months of the year\n\n\n\n\nstarted_at\nmember_casual\nabbMonths\n\n\n\n2023-01-01 00:04:07\ncasual\nJan\n\n\n2023-01-01 00:04:54\nmember\nJan\n\n\n2023-01-01 00:05:43\nmember\nJan\n\n\n2023-01-01 00:09:33\nmember\nJan\n\n\n2023-01-01 00:09:53\nmember\nJan\n\n\n2023-01-01 00:10:45\nmember\nJan\n\n\n\n\n\n\n\n\n\n\n\nTable 21: Kable output for weighted months of the year.\n\n\n\n\nstarted_at\nmember_casual\nn\nquartile\n\n\n\n2023-01-01 00:04:07\ncasual\n1\nQ1 (Jan 01 - May 20]\n\n\n2023-01-01 00:04:54\nmember\n1\nQ1 (Jan 01 - May 20]\n\n\n2023-01-01 00:05:43\nmember\n1\nQ1 (Jan 01 - May 20]\n\n\n2023-01-01 00:09:33\nmember\n1\nQ1 (Jan 01 - May 20]\n\n\n2023-01-01 00:09:53\nmember\n1\nQ1 (Jan 01 - May 20]\n\n\n2023-01-01 00:10:45\nmember\n1\nQ1 (Jan 01 - May 20]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/moy.db\", select_cols = \"abbMonths\",\n    group_cols = \"abbMonths\", doWeights = TRUE) |&gt;\n    plotter(x_col = abbMonths, y_col = n, geomType = \"column\", title = \"Months\",\n        x_label = \"Months\", y_label = \"n\")\n\ngplot\n\n\n\n\n\n\nFigure 8: Month Total Frequency\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/moy.db\", select_cols = \"abbMonths\", group_cols = \"abbMonths\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Months\", note_list = list(\"month of year\", \"observation count\"),\n        location_list = c(\"abbMonths\", \"n\"), source_note = gt::md(\"**Source**: `db/moy.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(abbMonths = \"Month\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = abbMonths, align = \"left\")\n\n\nTable 22: Month Total Frequency\n\n\n\n\n\n\n\nMonths\n    \n\nMonth1\n\n      n2\n\n    \n\n\n\nJan\n136,886\n\n\nFeb\n136,818\n\n\nMar\n183,129\n\n\nApr\n286,343\n\n\nMay\n408,373\n\n\nJun\n474,756\n\n\nJul\n502,519\n\n\nAug\n519,423\n\n\nSep\n461,164\n\n\nOct\n374,268\n\n\nNov\n257,513\n\n\nDec\n156,206\n\n\n\n\nSource: db/moy.db\n\n    \n\n\n\n1 month of year\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nChi-Squared\nDensity\nBinary Logistic Regression\nHistogram Plot\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/moy.db\", select_cols = c(\"abbMonths\",\n    \"member_casual\"), group_cols = c(\"abbMonths\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Month Groups\", x_label = \"Months\", y_label = \"n\", x_col = abbMonths,\n        y_col = n, group_col = member_casual, geomType = \"column\", isFaceted = TRUE,\n        is_colGroup = TRUE)\n\ngplot\n\n\n\n\n\n\nFigure 9: Month Group Frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/moy.db\", select_cols = c(\"abbMonths\", \"member_casual\"),\n    group_cols = c(\"abbMonths\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Months - Membership\", groupName = \"abbMonths\", location = n,\n        label_n = \"n\", note_list = list(\"membership status\", \"observation count\"),\n        location_list = list(\"member_casual\", \"n\"), source_note = gt::md(\"**Source**: `db/moy.db`\"),\n        noteColumns = TRUE, isStub = TRUE, stub_label = \"Months\", stub_note = \"months of the year (abbreviated)\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 23: Month Group Frequency\n\n\n\n\n\n\n\nMonths - Membership\n    \n\nMonths1\n\n      Membership2\n\n      n3\n\n    \n\n\n\nJan\ncasual\n25,262\n\n\nmember\n111,624\n\n\nFeb\ncasual\n27,111\n\n\nmember\n109,707\n\n\nMar\ncasual\n39,137\n\n\nmember\n143,992\n\n\nApr\ncasual\n87,211\n\n\nmember\n199,132\n\n\nMay\ncasual\n139,998\n\n\nmember\n268,375\n\n\nJun\ncasual\n177,745\n\n\nmember\n297,011\n\n\nJul\ncasual\n194,030\n\n\nmember\n308,489\n\n\nAug\ncasual\n189,563\n\n\nmember\n329,860\n\n\nSep\ncasual\n168,881\n\n\nmember\n292,283\n\n\nOct\ncasual\n114,475\n\n\nmember\n259,793\n\n\nNov\ncasual\n64,508\n\n\nmember\n193,005\n\n\nDec\ncasual\n32,700\n\n\nmember\n123,506\n\n\n\n\nSource: db/moy.db\n\n    \n\n\n\n1 months of the year (abbreviated)\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\nThe script I used to process the Chi-Squared test result. This code is reposted with all the chi-square tables in this report.# ----\n# Author: Eric Mossotti\n# CC BY-SA\n# ----\n# The code for returning chi-square test results as a tibble for use in tables.\n# ----\nchisqTest &lt;- function(data, variable, by) {\n    test_result &lt;- chisq.test(x = data[[variable]], y = data[[by]]) |&gt;\n        broom::tidy() |&gt;\n        dplyr::select(statistic, parameter, p.value)\n    \n    return(test_result)\n}\n\n\n\nSave the chi-square statistic and degrees of freedom values in a tibble format to add to the gtsummary table.data_tibble &lt;- dplyr::tbl(dbconn, \"db/moy.db\") |&gt;\n    dplyr::select(abbMonths, member_casual) |&gt;\n    dplyr::arrange(abbMonths, member_casual) |&gt;\n    dplyr::collect()\n\nchiResult &lt;- chisqTest(data = data_tibble, variable = \"abbMonths\", by = \"member_casual\")\n\n\n\nCodechi_table &lt;- tabler(title = \"Chi-Square: Month\", source_note = gt::md(\"**Source**: `db/moy.db`\"),\n    label = list(abbMonths = \"Month\"), by = member_casual, isSummary = TRUE, tbl_name = data_tibble,\n    chi_result = chiResult)\n\nchi_table\n\n\nTable 24\n\n\n\n\n\n\n\nChi-Square: Month\n    \n\nCharacteristic\n      \ncasual, N = 1,260,6211\n\n      \nmember, N = 2,636,7771\n\n      \np-value2\n\n    \n\n\n\nMonth\n\n\n&lt;0.001\n\n\n    Jan\n25,262 (2.0%)\n111,624 (4.2%)\n\n\n\n    Feb\n27,111 (2.2%)\n109,707 (4.2%)\n\n\n\n    Mar\n39,137 (3.1%)\n143,992 (5.5%)\n\n\n\n    Apr\n87,211 (6.9%)\n199,132 (7.6%)\n\n\n\n    May\n139,998 (11%)\n268,375 (10%)\n\n\n\n    Jun\n177,745 (14%)\n297,011 (11%)\n\n\n\n    Jul\n194,030 (15%)\n308,489 (12%)\n\n\n\n    Aug\n189,563 (15%)\n329,860 (13%)\n\n\n\n    Sep\n168,881 (13%)\n292,283 (11%)\n\n\n\n    Oct\n114,475 (9.1%)\n259,793 (9.9%)\n\n\n\n    Nov\n64,508 (5.1%)\n193,005 (7.3%)\n\n\n\n    Dec\n32,700 (2.6%)\n123,506 (4.7%)\n\n\n\n\n\nSource: db/moy.db\n\n    \n\n\n\n1 n (%);   χ²  = 71802.26;   df = 11\n    \n\n\n2 Pearson’s Chi-squared test\n    \n\n\n\n\n\n\n\n\n\n\n\n\nCodegplot &lt;- dplyr::tbl(dbconn, \"db/moy.db\") |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Month Group Density\", x_label = paste0(\"Months\"), x_col = started_at,\n        group_col = member_casual, geomType = \"other\", angle = 45, color_col = \"black\",\n        density_alpha = 0.75, isTime = TRUE, date_breaks = \"1 month\", date_labels = \"%b\",\n        )\n\ngplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery …_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/moy_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Months Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Months & Membership\"),\n        source_note = gt::md(\"**Source**: `db/moy.db`\"), isBinary = TRUE)\n\n\nTable 25\n\n\n\n\n\n\n\nBinary Logistic Regression:  Months & Membership\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nMonths Ranges\n\n\n\n\n    Q1 (Jan 01 - May 20]\n—\n\n\n\n    Q2 (May 20 - Jul 21]\n0.57\n&lt;0.001\n\n\n    Q3 (Jul 21 - Sep 18]\n0.58\n&lt;0.001\n\n\n    Q4 (Sep 18 - Dec 31]\n0.87\n&lt;0.001\n\n\n\n\nSource: db/moy.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\n\nCodeqdf &lt;- dplyr::tbl(dbconn, \"db/moy.db\") |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(qdf$started_at, probs = c(0.25, 0.5, 0.75))\n\ngplot &lt;- dplyr::tbl(dbconn, \"db/moy.db\") |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Months\", x_label = \"Months\", y_label = \"n\", x_col = started_at,\n        geomType = \"column\", isHistogram = TRUE, isTimeHist = TRUE, date_breaks = \"1 month\",\n        date_labels = \"%b\", angle = 45, color_col = \"black\", vline_color = \"lightyellow\",\n        vline_size = 0.5, low = \"blue\", high = \"red\", binwidth = \\(x) 2 *\n            IQR(x)/(length(x)^(1/3)), quartiles = quartiles, qformat = \"%b-%d\")\n\ngplot"
  },
  {
    "objectID": "index.html#sec-dow",
    "href": "index.html#sec-dow",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.5 Day",
    "text": "3.5 Day\n\n\n\n\n\n\n\n\n\nTable 27 and Figure 12 give an aggregated distribution of ridership frequency by the day of the week.\nTable 28 and Figure 13 summarize the duration distribution by membership.\nIn Table 29, the null hypothesis is rejected. The type of bicycle and the rider’s membership status can be considered dependent variables.\nTo visualize weekly users through the lens of their respective concentrations, see Figure 14. The plot looks a little different because I am directly plotting the x-axis using the original date-time data types. I think this maintains a more accurate view of the data.\n\nTable 30 presents the results of a binary logistic regression analyzing the relationship between days of the week and membership status. The analysis divides the week into four quartiles, with Q1 (Sunday 12:00 am - Monday 11:40 am) serving as the reference category.\n\nCompared to Q1, the odds of being a member versus a casual rider varied significantly across the other time quartiles (p &lt; 0.001 for all comparisons).\nQ2 (Monday 11:40 am - Wednesday 05:14 am): The odds of membership were 1.52 times higher than in Q1. This suggests a substantial increase in the likelihood of members riding during the early part of the work week.\nQ3 (Wednesday 05:14 am - Friday 12:19 pm), the odds of membership were 1.36 times higher than in Q1. This indicates a continued higher likelihood of membership during the latter part of the work week, though slightly lower than Q2.\nQ4 (Friday 12:19 pm - Saturday 11:59 pm), the odds of membership were 0.80 times as high as in Q1. This represents a significant decrease in the likelihood of membership during the weekend period.\n\n\nTo visualize the full weekly dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 15 (the solid yellow line represents the mean).\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite dow.db to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/dow.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(started_at, member_casual) |&gt;\n        dplyr::arrange(started_at) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(wkdays = lubridate::wday(started_at, week_start = 7), member_casual = factor(member_casual,\n            levels = c(\"casual\", \"member\")), started_at = update(started_at, year = 2024,\n            month = 9, day = wkdays), abbDays = lubridate::wday(started_at, label = TRUE,\n            abbr = TRUE), abbDays = forcats::as_factor(abbDays)) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/dow.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery …, transform, and write weighted quartile data to …_wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/dow_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/dow.db\", select_cols = c(\"started_at\",\n        \"member_casual\"), group_cols = c(\"started_at\", \"member_casual\"), binary_col = \"member_casual\",\n        pred_col = \"started_at\", ntile_col = \"quartile\", zero_val = \"casual\", one_val = \"member\",\n        qtile_levels = c(\"Q1 (Sun 12:00 am - Mon 11:40 am]\", \"Q2 (Mon 11:40 am - Wed 05:14 am]\",\n            \"Q3 (Wed 05:14 am - Fri 12:19 pm]\", \"Q4 (Fri 12:19 pm - Sat 11:59 pm]\"),\n        doQuantile = TRUE, doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/dow_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/dow.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 26: Days of the week\n\n\n\n\nstarted_at\nmember_casual\nwkdays\nabbDays\n\n\n\n2024-09-01 00:04:07\ncasual\n1\nSun\n\n\n2024-09-01 00:04:54\nmember\n1\nSun\n\n\n2024-09-01 00:05:43\nmember\n1\nSun\n\n\n2024-09-01 00:09:33\nmember\n1\nSun\n\n\n2024-09-01 00:09:53\nmember\n1\nSun\n\n\n2024-09-01 00:10:45\nmember\n1\nSun\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCode# Values were too similar to visualize differences, see coord_cartesion()\ngplot &lt;- transformData(conn = dbconn, path = \"db/dow.db\", select_cols = \"abbDays\",\n    group_cols = \"abbDays\", doWeights = TRUE) |&gt;\n    plotter(x_col = abbDays, y_col = n, geomType = \"column\", title = \"Days for all Riders\",\n        x_label = \"Days of the Week\", y_label = \"n\") + ggplot2::coord_cartesian(ylim = c(4.5 *\n    10^5, NA))\n\ngplot\n\n\n\n\n\n\nFigure 12: Weekday Totals Frequency\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/dow.db\", select_cols = \"abbDays\", group_cols = \"abbDays\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Days of the Week\", note_list = list(\"day of the week\", \"observation count\"),\n        location_list = list(\"abbDays\", \"n\"), source_note = gt::md(\"**Source**: `db/dow.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(abbDays = \"Day\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = abbDays, align = \"left\")\n\n\nTable 27: Weekday Total Frequency\n\n\n\n\n\n\n\nDays of the Week\n    \n\nDay1\n\n      n2\n\n    \n\n\n\nSun\n486,275\n\n\nMon\n507,355\n\n\nTue\n578,095\n\n\nWed\n585,266\n\n\nThu\n597,363\n\n\nFri\n566,008\n\n\nSat\n577,036\n\n\n\n\nSource: db/dow.db\n\n    \n\n\n\n1 day of the week\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nChi-Squared\nDensity\nBinary Logistic Regression\nHistogram Plot\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/dow.db\", select_cols = c(\"abbDays\",\n    \"member_casual\"), group_cols = c(\"abbDays\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Day Groups\", x_label = \"Days\", y_label = \"n\", x_col = abbDays,\n        y_col = n, group_col = member_casual, geomType = \"column\", isFaceted = TRUE,\n        is_colGroup = TRUE)\n\ngplot\n\n\n\n\n\n\nFigure 13: Weekday Group Frequency\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/dow.db\", select_cols = c(\"abbDays\", \"member_casual\"),\n    group_cols = c(\"abbDays\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Days - Membership\", groupName = \"abbDays\", location = n, label_n = \"n\",\n        note_list = list(\"membership status\", \"observation count\"), location_list = list(\"member_casual\",\n            \"n\"), source_note = gt::md(\"**Source**: `db/dow.db`\"), noteColumns = TRUE,\n        isStub = TRUE, stub_label = \"Day\", stub_note = \"days of the week (abbreviated)\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 28: Weekday Group Frequency\n\n\n\n\n\n\n\nDays - Membership\n    \n\nDay1\n\n      Membership2\n\n      n3\n\n    \n\n\n\nSun\ncasual\n200,588\n\n\nmember\n285,687\n\n\nMon\ncasual\n142,860\n\n\nmember\n364,495\n\n\nTue\ncasual\n152,604\n\n\nmember\n425,491\n\n\nWed\ncasual\n155,978\n\n\nmember\n429,288\n\n\nThu\ncasual\n169,117\n\n\nmember\n428,246\n\n\nFri\ncasual\n189,429\n\n\nmember\n376,579\n\n\nSat\ncasual\n250,045\n\n\nmember\n326,991\n\n\n\n\nSource: db/dow.db\n\n    \n\n\n\n1 days of the week (abbreviated)\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\nThe script I used to process the Chi-Squared test result. This code is reposted with all the chi-square tables in this report.# ----\n# Author: Eric Mossotti\n# CC BY-SA\n# ----\n# The code for returning chi-square test results as a tibble for use in tables.\n# ----\nchisqTest &lt;- function(data, variable, by) {\n    test_result &lt;- chisq.test(x = data[[variable]], y = data[[by]]) |&gt;\n        broom::tidy() |&gt;\n        dplyr::select(statistic, parameter, p.value)\n    \n    return(test_result)\n}\n\n\n\nSave the chi-square statistic and degrees of freedom values in a tibble format to add to the gtsummary table.data_tibble &lt;- dplyr::tbl(dbconn, \"db/dow.db\") |&gt;\n    dplyr::select(abbDays, member_casual) |&gt;\n    dplyr::arrange(abbDays, member_casual) |&gt;\n    dplyr::collect()\n\nchiResult &lt;- chisqTest(data = data_tibble, variable = \"abbDays\", by = \"member_casual\")\n\n\n\nCodetabler(title = \"Chi-Square: Days of the Week\", source_note = gt::md(\"**Source**: `db/moy.db`\"),\n    label = list(abbDays = \"Day\"), by = member_casual, isSummary = TRUE, tbl_name = data_tibble,\n    chi_result = chiResult)\n\n\nTable 29\n\n\n\n\n\n\n\nChi-Square: Days of the Week\n    \n\nCharacteristic\n      \ncasual, N = 1,260,6211\n\n      \nmember, N = 2,636,7771\n\n      \np-value2\n\n    \n\n\n\nDay\n\n\n&lt;0.001\n\n\n    Sun\n200,588 (16%)\n285,687 (11%)\n\n\n\n    Mon\n142,860 (11%)\n364,495 (14%)\n\n\n\n    Tue\n152,604 (12%)\n425,491 (16%)\n\n\n\n    Wed\n155,978 (12%)\n429,288 (16%)\n\n\n\n    Thu\n169,117 (13%)\n428,246 (16%)\n\n\n\n    Fri\n189,429 (15%)\n376,579 (14%)\n\n\n\n    Sat\n250,045 (20%)\n326,991 (12%)\n\n\n\n\n\nSource: db/moy.db\n\n    \n\n\n\n1 n (%);   χ²  = 76305.71;   df = 6\n    \n\n\n2 Pearson’s Chi-squared test\n    \n\n\n\n\n\n\n\n\n\n\n\n\nDensity by day of the week.gplot &lt;- dplyr::tbl(dbconn, \"db/dow.db\") |&gt;\n    dplyr::select(started_at, member_casual) |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Weekday Group Density\", x_label = paste0(\"Day\"), x_col = started_at,\n        group_col = member_casual, geomType = \"other\", angle = 45, color_col = \"black\",\n        density_alpha = 0.75, isTime = TRUE, date_breaks = \"1 day\", date_labels = \"%a\")\n\ngplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuery …_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/dow_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Weekday Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Week Days\"), source_note = gt::md(\"**Source**: `db/dow_wq.db`\"),\n        isBinary = TRUE)\n\n\nTable 30\n\n\n\n\n\n\n\nBinary Logistic Regression:  Week Days\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nWeekday Ranges\n\n\n\n\n    Q1 (Sun 12:00 am - Mon 11:40 am]\n—\n\n\n\n    Q2 (Mon 11:40 am - Wed 05:14 am]\n1.52\n&lt;0.001\n\n\n    Q3 (Wed 05:14 am - Fri 12:19 pm]\n1.36\n&lt;0.001\n\n\n    Q4 (Fri 12:19 pm - Sat 11:59 pm]\n0.80\n&lt;0.001\n\n\n\n\nSource: db/dow_wq.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\n\nCodeqdf &lt;- dplyr::tbl(dbconn, \"db/dow.db\") |&gt;\n    dplyr::select(started_at) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(qdf$started_at, probs = c(0.25, 0.5, 0.75))\n\ngplot &lt;- qdf |&gt;\n    plotter(title = \"Days\", x_label = \"Days\", y_label = \"n\", x_col = started_at,\n        geomType = \"column\", isHistogram = TRUE, isTimeHist = TRUE, date_breaks = \"1 day\",\n        date_labels = \"%a\", angle = 45, color_col = \"black\", vline_color = \"lightyellow\",\n        vline_size = 0.5, low = \"blue\", high = \"red\", binwidth = \\(x) 2 *\n            IQR(x)/(length(x)^(1/3)), quartiles = quartiles, qformat = \"%a %I %p\")\n\ngplot"
  },
  {
    "objectID": "index.html#sec-hod",
    "href": "index.html#sec-hod",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.6 Hour",
    "text": "3.6 Hour\n\n\n\n\n\n\n\n\n\nTable 33 and Figure 16 give an aggregated distribution of ridership frequency by the hour of the day.\nTable 34 and Figure 17 summarize the hourly distribution by membership.\nTable 35, the null hypothesis is rejected. The type of bicycle and the rider’s membership status can be considered dependent variables.\nTo visualize monthly users through the lens of their respective concentrations, see Figure 18. The plot looks a little different because I am directly plotting the x-axis using the original date-time data types. I think this maintains a more accurate view of the data.\n\nTable 36 presents the results of a binary logistic regression analyzing the relationship between hour of the day and membership status. The analysis divides the day into four quartiles, with Q1 (12:00 am - 10:59 am) serving as the reference category.\n\nCompared to Q1, the odds of being a member versus a casual rider varied significantly across the other time quartiles (p &lt; 0.001 for all comparisons).\nSpecifically, the odds of membership were 1.44 times as high in Q2 (10:59 am - 03:24 pm), 1.04 times as high in Q3 (03:24 pm - 06:05 pm), and 0.97 times as high in Q4 (06:05 pm - 11:59 pm).\nThese results reveal a non-linear relationship between time of day and membership status. The highest likelihood of membership occurs during Q2, corresponding to midday hours.\nThere’s a slight increase in membership likelihood during Q3 (late afternoon) compared to the reference period, while evening hours (Q4) show a slight decrease in membership likelihood.\n\n\nTo visualize the full duration dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 19 (the solid yellow line represents the mean).\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite … to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/hod.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(started_at, member_casual) |&gt;\n        dplyr::arrange(started_at) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(started_at_time = update(started_at, year = 2023, month = 1,\n            day = 1), hr = stringr::str_to_lower(format(lubridate::round_date(started_at,\n            unit = \"hour\"), \"%I %p\")), hrMin = stringr::str_to_lower(format(lubridate::round_date(started_at,\n            unit = \"minute\"), \"%I:%M %p\")), hrminSec = stringr::str_to_lower(format(lubridate::round_date(started_at,\n            unit = \"second\"), \"%r\")), hr = forcats::as_factor(hr), hrMin = forcats::as_factor(hrMin)) |&gt;\n        dplyr::select(member_casual:hrminSec) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/hod.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery …, transform and write weighted quartile data to hod_wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/hod_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/hod.db\", select_cols = c(\"started_at_time\",\n        \"member_casual\"), group_cols = c(\"started_at_time\", \"member_casual\"), binary_col = \"member_casual\",\n        pred_col = \"started_at_time\", ntile_col = \"quartile\", zero_val = \"casual\",\n        one_val = \"member\", qtile_levels = c(\"Q1 (12:00 am - 10:59 am]\", \"Q2 (10:59 am - 03:24 pm]\",\n            \"Q3 (03:24 pm - 06:05 pm]\", \"Q4 (06:05 pm - 11:59 pm]\"), doQuantile = TRUE,\n        doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/hod_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/hod.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/hod_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 31: Kable output of hod.db\n\n\n\n\nmember_casual\nstarted_at_time\nhr\nhrMin\nhrminSec\n\n\n\ncasual\n2023-01-01 00:04:07\n12 am\n12:04 am\n12:04:07 am\n\n\nmember\n2023-01-01 00:04:54\n12 am\n12:05 am\n12:04:54 am\n\n\nmember\n2023-01-01 00:05:43\n12 am\n12:06 am\n12:05:43 am\n\n\nmember\n2023-01-01 00:09:33\n12 am\n12:10 am\n12:09:33 am\n\n\nmember\n2023-01-01 00:09:53\n12 am\n12:10 am\n12:09:53 am\n\n\nmember\n2023-01-01 00:10:45\n12 am\n12:11 am\n12:10:45 am\n\n\n\n\n\n\n\n\n\n\n\nTable 32: Kable output of hod_wq.db\n\n\n\n\nstarted_at_time\nmember_casual\nn\nquartile\n\n\n\n2023-01-01 00:00:00\ncasual\n6\nQ1 (12:00 am - 10:59 am]\n\n\n2023-01-01 00:00:00\nmember\n6\nQ1 (12:00 am - 10:59 am]\n\n\n2023-01-01 00:00:01\ncasual\n2\nQ1 (12:00 am - 10:59 am]\n\n\n2023-01-01 00:00:01\nmember\n10\nQ1 (12:00 am - 10:59 am]\n\n\n2023-01-01 00:00:02\ncasual\n14\nQ1 (12:00 am - 10:59 am]\n\n\n2023-01-01 00:00:02\nmember\n6\nQ1 (12:00 am - 10:59 am]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/hod.db\", select_cols = \"hr\", group_cols = \"hr\",\n    doWeights = TRUE) |&gt;\n    plotter(x_col = hr, y_col = n, geomType = \"column\", title = \"Hour of Day\", x_label = \"Hour\",\n        y_label = \"n\", ) + ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1,\n    angle = 45))\n\ngplot\n\n\n\n\n\n\nFigure 16: Total frequency by hour of day.\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/hod.db\", select_cols = \"hr\", group_cols = \"hr\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Hours\", note_list = list(\"hour of the day\", \"observation count\"),\n        location_list = list(\"hr\", \"n\"), source_note = gt::md(\"**Source**: `db/hod.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(hr = \"Hour\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = hr, align = \"left\")\n\n\nTable 33: Total freqeuncy by the hour of day\n\n\n\n\n\n\n\nHours\n    \n\nHour1\n\n      n2\n\n    \n\n\n\n12 am\n52,336\n\n\n01 am\n31,598\n\n\n02 am\n20,378\n\n\n03 am\n10,309\n\n\n04 am\n7,179\n\n\n05 am\n14,866\n\n\n06 am\n61,027\n\n\n07 am\n141,249\n\n\n08 am\n227,964\n\n\n09 am\n199,884\n\n\n10 am\n155,951\n\n\n11 am\n172,204\n\n\n12 pm\n213,544\n\n\n01 pm\n223,804\n\n\n02 pm\n224,467\n\n\n03 pm\n246,680\n\n\n04 pm\n313,374\n\n\n05 pm\n408,606\n\n\n06 pm\n371,909\n\n\n07 pm\n277,477\n\n\n08 pm\n189,106\n\n\n09 pm\n139,743\n\n\n10 pm\n112,692\n\n\n11 pm\n81,051\n\n\n\n\nSource: db/hod.db\n\n    \n\n\n\n1 hour of the day\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nChi-Squared\nDensity\nBinary Logistic Regression\nHistogram Plot\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/hod.db\", select_cols = c(\"hr\", \"member_casual\"),\n    group_cols = c(\"hr\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Hour Groups\", x_label = \"Hour of Day\", y_label = \"n\", x_col = hr,\n        y_col = n, group_col = member_casual, geomType = \"column\", isFaceted = TRUE,\n        is_colGroup = TRUE) + ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1,\n    angle = 45))\n\ngplot\n\n\n\n\n\n\nFigure 17: Grouped hour frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/hod.db\", select_cols = c(\"hr\", \"member_casual\"),\n    group_cols = c(\"hr\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Hour - Membership\", groupName = \"hr\", location = n, label_n = \"n\",\n        note_list = list(\"membership status\", \"observation count\"), location_list = list(\"member_casual\",\n            \"n\"), source_note = gt::md(\"**Source**: `db/hod.db`\"), noteColumns = TRUE,\n        isStub = TRUE, stub_label = \"Day\", stub_note = \"hour of the day (12-hour clock)\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 34: Frequencies for membership by hour.\n\n\n\n\n\n\n\nHour - Membership\n    \n\nDay1\n\n      Membership2\n\n      n3\n\n    \n\n\n\n12 am\ncasual\n24,468\n\n\nmember\n27,868\n\n\n01 am\ncasual\n15,391\n\n\nmember\n16,207\n\n\n02 am\ncasual\n10,859\n\n\nmember\n9,519\n\n\n03 am\ncasual\n5,053\n\n\nmember\n5,256\n\n\n04 am\ncasual\n3,164\n\n\nmember\n4,015\n\n\n05 am\ncasual\n3,918\n\n\nmember\n10,948\n\n\n06 am\ncasual\n12,330\n\n\nmember\n48,697\n\n\n07 am\ncasual\n27,046\n\n\nmember\n114,203\n\n\n08 am\ncasual\n43,590\n\n\nmember\n184,374\n\n\n09 am\ncasual\n45,413\n\n\nmember\n154,471\n\n\n10 am\ncasual\n47,734\n\n\nmember\n108,217\n\n\n11 am\ncasual\n59,590\n\n\nmember\n112,614\n\n\n12 pm\ncasual\n75,634\n\n\nmember\n137,910\n\n\n01 pm\ncasual\n81,646\n\n\nmember\n142,158\n\n\n02 pm\ncasual\n83,794\n\n\nmember\n140,673\n\n\n03 pm\ncasual\n90,150\n\n\nmember\n156,530\n\n\n04 pm\ncasual\n105,809\n\n\nmember\n207,565\n\n\n05 pm\ncasual\n124,466\n\n\nmember\n284,140\n\n\n06 pm\ncasual\n118,031\n\n\nmember\n253,878\n\n\n07 pm\ncasual\n91,667\n\n\nmember\n185,810\n\n\n08 pm\ncasual\n63,696\n\n\nmember\n125,410\n\n\n09 pm\ncasual\n48,455\n\n\nmember\n91,288\n\n\n10 pm\ncasual\n44,013\n\n\nmember\n68,679\n\n\n11 pm\ncasual\n34,704\n\n\nmember\n46,347\n\n\n\n\nSource: db/hod.db\n\n    \n\n\n\n1 hour of the day (12-hour clock)\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\nThe script I used to process the Chi-Squared test result. This code is reposted with all the chi-square tables in this report.# ----\n# Author: Eric Mossotti\n# CC BY-SA\n# ----\n# The code for returning chi-square test results as a tibble for use in tables.\n# ----\nchisqTest &lt;- function(data, variable, by) {\n    test_result &lt;- chisq.test(x = data[[variable]], y = data[[by]]) |&gt;\n        broom::tidy() |&gt;\n        dplyr::select(statistic, parameter, p.value)\n    \n    return(test_result)\n}\n\n\n\nSave the chi-square statistic and degrees of freedom values in a tibble format to add to the gtsummary table.data_tibble &lt;- transformData(conn = dbconn, path = \"db/hod.db\", select_cols = c(\"hr\",\n    \"member_casual\"))\n\nchiResult &lt;- chisqTest(data = data_tibble, variable = \"hr\", by = \"member_casual\")\n\n\n\nCodetabler(title = \"Chi-Square: Hour of the Day\", source_note = gt::md(\"**Source**: `db/hod.db`\"),\n    label = list(hr = \"Hour\"), by = member_casual, isSummary = TRUE, tbl_name = data_tibble,\n    chi_result = chiResult)\n\n\nTable 35: Chi-Squared for aggregated hours data to the level of rounded hours.\n\n\n\n\n\n\n\nChi-Square: Hour of the Day\n    \n\nCharacteristic\n      \ncasual, N = 1,260,6211\n\n      \nmember, N = 2,636,7771\n\n      \np-value2\n\n    \n\n\n\nHour\n\n\n&lt;0.001\n\n\n    12 am\n24,468 (1.9%)\n27,868 (1.1%)\n\n\n\n    01 am\n15,391 (1.2%)\n16,207 (0.6%)\n\n\n\n    02 am\n10,859 (0.9%)\n9,519 (0.4%)\n\n\n\n    03 am\n5,053 (0.4%)\n5,256 (0.2%)\n\n\n\n    04 am\n3,164 (0.3%)\n4,015 (0.2%)\n\n\n\n    05 am\n3,918 (0.3%)\n10,948 (0.4%)\n\n\n\n    06 am\n12,330 (1.0%)\n48,697 (1.8%)\n\n\n\n    07 am\n27,046 (2.1%)\n114,203 (4.3%)\n\n\n\n    08 am\n43,590 (3.5%)\n184,374 (7.0%)\n\n\n\n    09 am\n45,413 (3.6%)\n154,471 (5.9%)\n\n\n\n    10 am\n47,734 (3.8%)\n108,217 (4.1%)\n\n\n\n    11 am\n59,590 (4.7%)\n112,614 (4.3%)\n\n\n\n    12 pm\n75,634 (6.0%)\n137,910 (5.2%)\n\n\n\n    01 pm\n81,646 (6.5%)\n142,158 (5.4%)\n\n\n\n    02 pm\n83,794 (6.6%)\n140,673 (5.3%)\n\n\n\n    03 pm\n90,150 (7.2%)\n156,530 (5.9%)\n\n\n\n    04 pm\n105,809 (8.4%)\n207,565 (7.9%)\n\n\n\n    05 pm\n124,466 (9.9%)\n284,140 (11%)\n\n\n\n    06 pm\n118,031 (9.4%)\n253,878 (9.6%)\n\n\n\n    07 pm\n91,667 (7.3%)\n185,810 (7.0%)\n\n\n\n    08 pm\n63,696 (5.1%)\n125,410 (4.8%)\n\n\n\n    09 pm\n48,455 (3.8%)\n91,288 (3.5%)\n\n\n\n    10 pm\n44,013 (3.5%)\n68,679 (2.6%)\n\n\n\n    11 pm\n34,704 (2.8%)\n46,347 (1.8%)\n\n\n\n\n\nSource: db/hod.db\n\n    \n\n\n\n1 n (%);   χ²  = 72733.38;   df = 23\n    \n\n\n2 Pearson’s Chi-squared test\n    \n\n\n\n\n\n\n\n\n\n\n\n\nCodegplot &lt;- dplyr::tbl(dbconn, \"db/hod.db\") |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Hour Group Density\", x_label = paste0(\"Hours\", \"\\n\", \"(12-hour clock)\"),\n        x_col = started_at_time, group_col = member_casual, geomType = \"other\", angle = 45,\n        color_col = \"black\", density_alpha = 0.75, isTime = TRUE, date_breaks = \"1 hour\",\n        date_labels = \"%I %p\", )\n\ngplot\n\n\n\n\n\n\nFigure 18: Query, load, and plot the grouped densities\n\n\n\n\n\n\n\n\nQuery hod_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/hod_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Hour Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Hour\"), source_note = gt::md(\"**Source**: `db/hod_wq.db`\"),\n        isBinary = TRUE)\n\n\nTable 36\n\n\n\n\n\n\n\nBinary Logistic Regression:  Hour\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nHour Ranges\n\n\n\n\n    Q1 (12:00 am - 10:59 am]\n—\n\n\n\n    Q2 (10:59 am - 03:24 pm]\n1.44\n&lt;0.001\n\n\n    Q3 (03:24 pm - 06:05 pm]\n1.04\n&lt;0.001\n\n\n    Q4 (06:05 pm - 11:59 pm]\n0.97\n&lt;0.001\n\n\n\n\nSource: db/hod_wq.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\n\nMember histogram plot with quartile ranges.qdf &lt;- dplyr::tbl(dbconn, \"db/hod.db\") |&gt;\n    dplyr::select(started_at_time) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(qdf$started_at_time, probs = c(0.25, 0.5, 0.75))\n\ngplot &lt;- qdf |&gt;\n    plotter(title = \"Hours\", x_label = \"Hours (12-hour clock)\", y_label = \"n\", x_col = started_at_time,\n        geomType = \"column\", isHistogram = TRUE, isTimeHist = TRUE, date_breaks = \"1 hour\",\n        date_labels = \"%I %p\", angle = 45, color_col = \"black\", vline_color = \"lightyellow\",\n        vline_size = 0.5, low = \"blue\", high = \"red\", binwidth = \\(x) 2 *\n            IQR(x)/(length(x)^(1/3)), quartiles = quartiles, qformat = \"%I:%M %p\")\n\ngplot"
  },
  {
    "objectID": "index.html#sec-distance",
    "href": "index.html#sec-distance",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.7 Distance",
    "text": "3.7 Distance\n\n\n\n\n\n\n\n\n\nTable 39 and Figure 20 give an aggregated distribution of ridership frequency by the miles traveled in a trip.\nTable 40 and Figure 21 summarize the hourly distribution by membership.\nTo visualize users through the lens of their respective concentrations, see Figure 22.\n\nTable 41 presents the odds ratios for membership status across distance quartiles, with Q1 serving as the reference category.\n\nCompared to Q1, the odds of being a member versus a casual rider were significantly lower in all other quartiles (p &lt; 0.001 for all comparisons).\nSpecifically, the odds of membership were 0.63 times as high in Q2, 0.59 times as high in Q3, and 0.65 times as high in Q4.\nThese results indicate an inverse relationship between ride distance and membership status, with members generally associated with shorter ride distances.\nInterestingly, the lowest odds of membership were observed in Q3, rather than Q4, suggesting a non-linear relationship between distance and membership likelihood.\n\n\nTo visualize the full distance dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 23 (the solid yellow line represents the mean).\nTable 42 gives the reader some idea of the variability, range, and quartile information about the distance data.\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite distance.db to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/distance.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(miles, member_casual) |&gt;\n        dplyr::arrange(miles) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(milesR = miles, milesR = dplyr::case_when(milesR &gt;= 1 ~ round(milesR,\n            digits = 0), miles &lt; 1 ~ round(signif(milesR, 3), digits = 1)), milesR = forcats::as_factor(milesR)) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/distance.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery … .db, transform and write weighted quartile data to … _wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/distance_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/distance.db\", select_cols = c(\"miles\",\n        \"member_casual\"), group_cols = c(\"miles\", \"member_casual\"), binary_col = \"member_casual\",\n        pred_col = \"miles\", ntile_col = \"quartile\", zero_val = \"casual\", one_val = \"member\",\n        qtile_levels = c(\"Q1 (0.10 - 0.63]\", \"Q2 (0.63 - 1.02]\", \"Q3 (1.02 - 1.76]\",\n            \"Q4 (1.76 - 20.5]\"), doQuantile = TRUE, doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/distance_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/distance.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/distance_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 37: Distance\n\n\n\n\nmiles\nmember_casual\nmilesR\n\n\n\n0.1000100\nmember\n0.1\n\n\n0.1000367\ncasual\n0.1\n\n\n0.1000491\nmember\n0.1\n\n\n0.1003780\ncasual\n0.1\n\n\n0.1004468\nmember\n0.1\n\n\n0.1005323\nmember\n0.1\n\n\n\n\n\n\n\n\n\n\n\nTable 38: Distance, Weighted Quantiles\n\n\n\n\nmiles\nmember_casual\nn\nquartile\n\n\n\n0.1000100\nmember\n1\nQ1 (0.10 - 0.63]\n\n\n0.1000367\ncasual\n1\nQ1 (0.10 - 0.63]\n\n\n0.1000491\nmember\n1\nQ1 (0.10 - 0.63]\n\n\n0.1003780\ncasual\n1\nQ1 (0.10 - 0.63]\n\n\n0.1004468\nmember\n1\nQ1 (0.10 - 0.63]\n\n\n0.1005323\nmember\n1\nQ1 (0.10 - 0.63]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/distance.db\", select_cols = \"milesR\",\n    group_cols = \"milesR\", doWeights = TRUE) |&gt;\n    plotter(x_col = milesR, y_col = n, geomType = \"column\", title = \"Distance\", x_label = \"Miles\",\n        y_label = \"n\")\n\ngplot + ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))\n\n\n\n\n\n\nFigure 20: Miles Total Frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/distance.db\", select_cols = \"milesR\", group_cols = \"milesR\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Distance\", note_list = list(\"trip distance\", \"observation count\"),\n        location_list = list(\"milesR\", \"n\"), source_note = gt::md(\"**Source**: `db/distance.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(milesR = \"Miles\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = milesR, align = \"left\")\n\n\nTable 39: Miles Total Frequency\n\n\n\n\n\n\n\nDistance\n    \n\nMiles1\n\n      n2\n\n    \n\n\n\n0.1\n11,429\n\n\n0.2\n70,621\n\n\n0.3\n178,150\n\n\n0.4\n225,723\n\n\n0.5\n280,367\n\n\n0.6\n288,164\n\n\n0.7\n250,369\n\n\n0.8\n262,418\n\n\n0.9\n227,646\n\n\n1\n867,678\n\n\n2\n720,842\n\n\n3\n292,483\n\n\n4\n121,920\n\n\n5\n55,748\n\n\n6\n25,499\n\n\n7\n11,924\n\n\n8\n3,275\n\n\n9\n1,520\n\n\n10\n686\n\n\n11\n415\n\n\n12\n256\n\n\n13\n139\n\n\n14\n67\n\n\n15\n24\n\n\n16\n31\n\n\n17\n1\n\n\n18\n1\n\n\n19\n1\n\n\n21\n1\n\n\n\n\nSource: db/distance.db\n\n    \n\n\n\n1 trip distance\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nDensity\nBinary Logistic Regression\nHistogram Plot\nSummary Stats\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/distance.db\", select_cols = c(\"milesR\",\n    \"member_casual\"), group_cols = c(\"milesR\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Distance Groups\", x_label = \"Miles\", y_label = \"n\", x_col = milesR,\n        y_col = n, group_col = member_casual, geomType = \"column\", isFaceted = TRUE,\n        is_colGroup = TRUE)\n\ngplot + ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))\n\n\n\n\n\n\nFigure 21: Distance by membership.\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/distance.db\", select_cols = c(\"milesR\", \"member_casual\"),\n    group_cols = c(\"milesR\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Distance - Membership\", groupName = \"milesR\", location = n, label_n = \"n\",\n        note_list = list(\"membership status\", \"observation count\"), location_list = list(\"member_casual\",\n            \"n\"), source_note = gt::md(\"**Source**: `db/distance.db`\"), noteColumns = TRUE,\n        isStub = TRUE, stub_label = \"Trip distance\", stub_note = \"miles traveled per trip\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 40: Miles Group Frequency\n\n\n\n\n\n\n\nDistance - Membership\n    \n\nTrip distance1\n\n      Membership2\n\n      n3\n\n    \n\n\n\n0.1\ncasual\n1,410\n\n\nmember\n10,019\n\n\n0.2\ncasual\n11,262\n\n\nmember\n59,359\n\n\n0.3\ncasual\n34,957\n\n\nmember\n143,193\n\n\n0.4\ncasual\n54,395\n\n\nmember\n171,328\n\n\n0.5\ncasual\n75,269\n\n\nmember\n205,098\n\n\n0.6\ncasual\n83,008\n\n\nmember\n205,156\n\n\n0.7\ncasual\n76,686\n\n\nmember\n173,683\n\n\n0.8\ncasual\n91,896\n\n\nmember\n170,522\n\n\n0.9\ncasual\n77,635\n\n\nmember\n150,011\n\n\n1\ncasual\n316,382\n\n\nmember\n551,296\n\n\n2\ncasual\n261,540\n\n\nmember\n459,302\n\n\n3\ncasual\n99,452\n\n\nmember\n193,031\n\n\n4\ncasual\n39,690\n\n\nmember\n82,230\n\n\n5\ncasual\n18,589\n\n\nmember\n37,159\n\n\n6\ncasual\n9,393\n\n\nmember\n16,106\n\n\n7\ncasual\n5,492\n\n\nmember\n6,432\n\n\n8\ncasual\n1,706\n\n\nmember\n1,569\n\n\n9\ncasual\n789\n\n\nmember\n731\n\n\n10\ncasual\n433\n\n\nmember\n253\n\n\n11\ncasual\n273\n\n\nmember\n142\n\n\n12\ncasual\n170\n\n\nmember\n86\n\n\n13\ncasual\n92\n\n\nmember\n47\n\n\n14\ncasual\n49\n\n\nmember\n18\n\n\n15\ncasual\n22\n\n\nmember\n2\n\n\n16\ncasual\n27\n\n\nmember\n4\n\n\n17\ncasual\n1\n\n\n18\ncasual\n1\n\n\n19\ncasual\n1\n\n\n21\ncasual\n1\n\n\n\n\nSource: db/distance.db\n\n    \n\n\n\n1 miles traveled per trip\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\nCodegplot &lt;- dplyr::tbl(dbconn, \"db/distance.db\") |&gt;\n    dplyr::select(miles, member_casual) |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Distance Group Density\", x_label = \"Miles\", x_col = miles, group_col = member_casual,\n        geomType = \"column\", angle = 45, color_col = \"black\", density_alpha = 0.75,\n        isDensity = TRUE, is_colGroup = TRUE, breaks = seq(0, 11, by = 1), limits = c(0.1,\n            11))\n\ngplot\n\n\n\n\n\n\nFigure 22: Densities of miles to membership.\n\n\n\n\n\n\n\n\nQuery …_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/distance_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Distance Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Distance\"), source_note = gt::md(\"**Source**: `db/distance_wq.db`\"),\n        isBinary = TRUE)\n\n\nTable 41\n\n\n\n\n\n\n\nBinary Logistic Regression:  Distance\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nDistance Ranges\n\n\n\n\n    Q1 (0.10 - 0.63]\n—\n\n\n\n    Q2 (0.63 - 1.02]\n0.63\n&lt;0.001\n\n\n    Q3 (1.02 - 1.76]\n0.59\n&lt;0.001\n\n\n    Q4 (1.76 - 20.5]\n0.65\n&lt;0.001\n\n\n\n\nSource: db/distance_wq.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\n\nCodeqdf &lt;- dplyr::tbl(dbconn, \"db/distance.db\") |&gt;\n    dplyr::select(miles) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(as.numeric(qdf$miles), probs = c(0.25, 0.5, 0.75))\n\ngplot &lt;- qdf |&gt;\n    plotter(title = \"Distance\", x_label = \"Miles\", y_label = \"n\", x_col = miles,\n        geomType = \"column\", isHistogram = TRUE, angle = 45, color_col = \"transparent\",\n        vline_color = \"lightyellow\", vline_size = 0.5, low = \"blue\", high = \"red\",\n        binwidth = \\(x) 2 * IQR(x)/(length(x)^(1/3)), limits = c(0.1, 5),\n        breaks = seq(1, 5, by = 1), quartiles = quartiles)\n\ngplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodegTable &lt;- \ndplyr::tbl(dbconn, \"db/distance.db\") |&gt;\ndplyr::select(miles, member_casual) |&gt;\ndplyr::collect() |&gt;\ngtsummary::tbl_summary(\nby = member_casual,\ntype = miles ~ \"continuous2\",\nlabel = list(miles ~ \"Distance (miles)\"),\ndigits = list(\nmiles ~ c(2, 2)),\nstatistic = \ngtsummary::all_continuous() ~ c(\n\"{median} ({p25}, {p75})\", \n\"{mean} ({sd})\", \n\"{min}, {max}\")\n) |&gt;\ngtsummary::italicize_levels() |&gt;\ntabler(\ntitle = gt::md(\"Summary Statistics:&lt;br&gt;Distance - Membership\"),\nsource_note = gt::md(\"**Source**: `db/distance.db`\"),\nisBinary = TRUE\n)\n\ngTable\n\n\nTable 42: Useful summary statistics.\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nDistance - Membership\n\n\nCharacteristic\n\ncasual, N = 1,260,621\n\nmember, N = 2,636,777\n\n\n\n\nDistance (miles)\n\n\n\n\n    Median (IQR)\n1.12 (0.72, 1.83)\n0.97 (0.59, 1.71)\n\n\n    Mean (SD)\n1.48 (1.17)\n1.34 (1.11)\n\n\n    Range\n0.10, 20.54\n0.10, 16.02\n\n\n\n\nSource: db/distance.db"
  },
  {
    "objectID": "index.html#sec-speed",
    "href": "index.html#sec-speed",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.8 Speed",
    "text": "3.8 Speed\n\n\n\n\n\n\n\n\n\nTable 45 and Figure 24, give an aggregated distribution of ridership frequency by the hour of the day.\nTable 46 and Figure 25, summarize the trip speed distribution by membership.\n\nTo visualize monthly users through the lens of their respective concentrations, see Figure 26.\n\nThe plot looks a little different because I am directly plotting the x-axis using the original date-time data types. I think this maintains a more accurate view of the data.\n\n\n\nTable 47 presents the odds ratios for membership status across speed quartiles, with Q1 serving as the reference category.\n\nCompared to Q1, the odds of being a member versus a casual rider were significantly higher in all other quartiles (p &lt; 0.001 for all comparisons).\nSpecifically, the odds of membership were 2.09 times higher in Q2, 2.50 times higher in Q3, and 2.69 times higher in Q4.\nThese results suggest a strong positive association between riding speed and membership status, with the likelihood of membership increasing monotonically across speed quartiles.\n\n\nTo visualize the full speed dataset as a histogram with illustrated, colored-coded quartiles as dotted lines, see Figure 27 (the solid yellow line represents the mean).\nTable 48 gives the reader some idea of the variability, range, and quartile information about the distance data.\n\n\n\n\n\n\nDatabase Operations\n\n\nTable Preview\n\n\n\n\n\n\nDB Operations\n\n\n\n\n\n\n\n\nWrite … to the database.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/speed.db\"))) {\n    dplyr::tbl(dbconn, filtered_path) |&gt;\n        dplyr::select(mph, member_casual) |&gt;\n        dplyr::collect() |&gt;\n        dplyr::mutate(mphR = round(mph, digits = 0)) |&gt;\n        dplyr::arrange(mph, member_casual) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/speed.db\", overwrite = TRUE)\n}\n\n\n\n\n\nQuery … .db, transform and write weighted quartile data to … _wq.db.if (isFALSE(duckdb::dbExistsTable(dbconn, \"db/speed_wq.db\"))) {\n    transformData(conn = dbconn, path = \"db/speed.db\", select_cols = c(\"mph\", \"member_casual\"),\n        group_cols = c(\"mph\", \"member_casual\"), binary_col = \"member_casual\", pred_col = \"mph\",\n        ntile_col = \"quartile\", zero_val = \"casual\", one_val = \"member\", qtile_levels = c(\"Q1 (1.0 - 5.4]\",\n            \"Q2 (5.4 - 7.0]\", \"Q3 (7.0 - 8.6]\", \"Q4 (8.6 - 20]\"), doQuantile = TRUE,\n        doWeights = TRUE) |&gt;\n        duckdb::dbWriteTable(conn = dbconn, name = \"db/speed_wq.db\", overwrite = TRUE)\n}\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/speed.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\ndplyr::tbl(dbconn, \"db/speed_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    head() |&gt;\n    kableExtra::kable()\n\n\n\n\n\nTable 43: Speed\n\n\n\n\nmph\nmember_casual\nmphR\n\n\n\n1.000007\ncasual\n1\n\n\n1.000008\ncasual\n1\n\n\n1.000050\ncasual\n1\n\n\n1.000075\ncasual\n1\n\n\n1.000088\nmember\n1\n\n\n1.000098\nmember\n1\n\n\n\n\n\n\n\n\n\n\n\nTable 44: Speed with weighted quartile groups.\n\n\n\n\nmph\nmember_casual\nn\nquartile\n\n\n\n1.000007\ncasual\n1\nQ1 (1.0 - 5.4]\n\n\n1.000008\ncasual\n1\nQ1 (1.0 - 5.4]\n\n\n1.000050\ncasual\n1\nQ1 (1.0 - 5.4]\n\n\n1.000075\ncasual\n1\nQ1 (1.0 - 5.4]\n\n\n1.000088\nmember\n1\nQ1 (1.0 - 5.4]\n\n\n1.000098\nmember\n1\nQ1 (1.0 - 5.4]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Frequency Analysis\nComparative Frequency Analysis\n\n\n\n\n\nFrequency Plot\nFrequency Table\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/speed.db\", select_cols = \"mphR\",\n    group_cols = \"mphR\", doWeights = TRUE) |&gt;\n    plotter(x_col = mphR, y_col = n, geomType = \"column\", title = \"Speed\", x_label = \"Miles per Hour\",\n        y_label = \"n\")\n\ngplot\n\n\n\n\n\n\nFigure 24: Mph Total Frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/speed.db\", select_cols = \"mphR\", group_cols = \"mphR\",\n    doWeights = TRUE) |&gt;\n    tabler(title = \"Speed\", note_list = list(\"trip speed (miles per hour)\", \"observation count\"),\n        location_list = list(\"mphR\", \"n\"), source_note = gt::md(\"**Source**: `db/speed.db`\"),\n        noteColumns = TRUE) |&gt;\n    gt::cols_label(mphR = \"Mph\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = mphR, align = \"left\")\n\n\nTable 45: Mph Total Frequency\n\n\n\n\n\n\n\nSpeed\n    \n\nMph1\n\n      n2\n\n    \n\n\n\n1\n45,485\n\n\n2\n106,779\n\n\n3\n161,520\n\n\n4\n278,819\n\n\n5\n460,475\n\n\n6\n622,275\n\n\n7\n647,253\n\n\n8\n546,353\n\n\n9\n399,237\n\n\n10\n265,438\n\n\n11\n165,825\n\n\n12\n99,529\n\n\n13\n55,660\n\n\n14\n27,274\n\n\n15\n11,165\n\n\n16\n3,354\n\n\n17\n714\n\n\n18\n138\n\n\n19\n69\n\n\n20\n36\n\n\n\n\nSource: db/speed.db\n\n    \n\n\n\n1 trip speed (miles per hour)\n    \n\n\n2 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrequency Plot\nFrequency Table\nDensity\nBinary Logistic Regression\nHistogram Plot\nSummary Stats\n\n\n\n\n\nCodegplot &lt;- transformData(conn = dbconn, path = \"db/speed.db\", select_cols = c(\"mphR\",\n    \"member_casual\"), group_cols = c(\"mphR\", \"member_casual\"), doWeights = TRUE) |&gt;\n    plotter(title = \"Speed Groups (Aggregated)\", x_label = \"Miles per Hour\", y_label = \"n\",\n        x_col = mphR, y_col = n, color_col = member_casual, geomType = \"column\",\n        is_colGroup = TRUE, isFaceted = TRUE)\n\ngplot\n\n\n\n\n\n\nFigure 25: Mph Group Frequency\n\n\n\n\n\n\n\n\n\nCodetransformData(conn = dbconn, path = \"db/speed.db\", select_cols = c(\"mphR\", \"member_casual\"),\n    group_cols = c(\"mphR\", \"member_casual\"), doWeights = TRUE) |&gt;\n    tabler(title = \"Speed - Membership\", groupName = \"mphR\", location = n, label_n = \"n\",\n        note_list = list(\"membership status\", \"observation count\"), location_list = list(\"member_casual\",\n            \"n\"), source_note = gt::md(\"**Source**: `db/speed.db`\"), noteColumns = TRUE,\n        isStub = TRUE, stub_label = \"Trip Speed\", stub_note = \"estimated average speed traveled per trip (mph)\") |&gt;\n    gt::cols_label(member_casual = \"Membership\") |&gt;\n    gt::cols_align(columns = n, align = \"right\") |&gt;\n    gt::cols_align(columns = member_casual, align = \"left\")\n\n\nTable 46: Mph Group Frequency\n\n\n\n\n\n\n\nSpeed - Membership\n    \n\nTrip Speed1\n\n      Membership2\n\n      n3\n\n    \n\n\n\n1\ncasual\n28,675\n\n\nmember\n16,810\n\n\n2\ncasual\n67,464\n\n\nmember\n39,315\n\n\n3\ncasual\n93,694\n\n\nmember\n67,826\n\n\n4\ncasual\n128,134\n\n\nmember\n150,685\n\n\n5\ncasual\n166,759\n\n\nmember\n293,716\n\n\n6\ncasual\n191,146\n\n\nmember\n431,129\n\n\n7\ncasual\n179,540\n\n\nmember\n467,713\n\n\n8\ncasual\n144,296\n\n\nmember\n402,057\n\n\n9\ncasual\n102,522\n\n\nmember\n296,715\n\n\n10\ncasual\n67,961\n\n\nmember\n197,477\n\n\n11\ncasual\n42,345\n\n\nmember\n123,480\n\n\n12\ncasual\n24,981\n\n\nmember\n74,548\n\n\n13\ncasual\n13,475\n\n\nmember\n42,185\n\n\n14\ncasual\n6,305\n\n\nmember\n20,969\n\n\n15\ncasual\n2,402\n\n\nmember\n8,763\n\n\n16\ncasual\n693\n\n\nmember\n2,661\n\n\n17\ncasual\n171\n\n\nmember\n543\n\n\n18\ncasual\n38\n\n\nmember\n100\n\n\n19\ncasual\n12\n\n\nmember\n57\n\n\n20\ncasual\n8\n\n\nmember\n28\n\n\n\n\nSource: db/speed.db\n\n    \n\n\n\n1 estimated average speed traveled per trip (mph)\n    \n\n\n2 membership status\n    \n\n\n3 observation count\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\nCodegplot &lt;- dplyr::tbl(dbconn, \"db/speed.db\") |&gt;\n    dplyr::select(mph, member_casual) |&gt;\n    dplyr::collect() |&gt;\n    plotter(title = \"Speed Group Density\", x_label = \"MPH (miles per hour)\", x_col = mph,\n        group_col = member_casual, geomType = \"column\", angle = 45, color_col = \"black\",\n        density_alpha = 0.75, isDensity = TRUE, is_colGroup = TRUE, breaks = seq(1,\n            20, by = 1), limits = c(1, 20))\n\ngplot\n\n\n\n\n\n\nFigure 26: Density plot for speed by membership.\n\n\n\n\n\n\n\n\nQuery …_wq.db, process and create model R object for hour based on quartile range.model &lt;- dplyr::tbl(dbconn, \"db/speed_wq.db\") |&gt;\n    dplyr::collect() |&gt;\n    glm(formula = member_casual ~ quartile, family = binomial, weights = n)\n\n\n\nPipe model object to tbl_regression(), then further adjust output with tabler().model |&gt;\n    gtsummary::tbl_regression(label = list(quartile = \"Speed Ranges\"), conf.int = FALSE,\n        exponentiate = TRUE) |&gt;\n    tabler(title = gt::md(\"Binary Logistic Regression: &lt;br&gt; Speed & Membership\"),\n        source_note = gt::md(\"**Source**: `db/speed_wq.db`\"), isBinary = TRUE)\n\n\nTable 47\n\n\n\n\n\n\n\nBinary Logistic Regression:  Speed & Membership\n    \n\nCharacteristic\n      \nOR1\n\n      p-value\n    \n\n\n\nSpeed Ranges\n\n\n\n\n    Q1 (1.0 - 5.4]\n—\n\n\n\n    Q2 (5.4 - 7.0]\n2.09\n&lt;0.001\n\n\n    Q3 (7.0 - 8.6]\n2.50\n&lt;0.001\n\n\n    Q4 (8.6 - 20]\n2.69\n&lt;0.001\n\n\n\n\nSource: db/speed_wq.db\n\n    \n\n\n1 OR = Odds Ratio\n    \n\n\n\n\n\n\n\n\n\n\n\nCodeqdf &lt;- dplyr::tbl(dbconn, \"db/speed.db\") |&gt;\n    dplyr::select(mph) |&gt;\n    dplyr::collect()\n\nquartiles &lt;- quantile(qdf$mph, probs = c(0.25, 0.5, 0.75))\n\ngplot &lt;- qdf |&gt;\n    plotter(title = \"Estimated Average Trip Speed\", x_label = \"MPH\", y_label = \"n\",\n        x_col = mph, geomType = \"column\", isHistogram = TRUE, angle = 45, color_col = \"transparent\",\n        vline_color = \"lightyellow\", vline_size = 0.5, low = \"blue\", high = \"red\",\n        binwidth = \\(x) 2 * IQR(x)/(length(x)^(1/3)), breaks = seq(1, 20,\n            by = 1), limits = c(1, 20), quartiles = quartiles)\n\ngplot\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodedplyr::tbl(dbconn, \"db/speed.db\") |&gt;\ndplyr::select(mph, member_casual) |&gt;\ndplyr::collect() |&gt;\ngtsummary::tbl_summary(\nby = member_casual,\ntype = mph ~ \"continuous2\",\nlabel = list(mph ~ \"Speed\"),\ndigits = list(\nmph ~ c(1, 1)),\nstatistic = \ngtsummary::all_continuous() ~ c(\n\"{median} ({p25}, {p75})\", \n\"{mean} ({sd})\", \n\"{min}, {max}\")\n) |&gt;\ngtsummary::italicize_levels() |&gt;\ntabler(\ntitle = gt::md(\"Summary Statistics:&lt;br&gt;Speed - Membership\"),\nsource_note = gt::md(\"**Source**: `db/speed.db`\"),\nisBinary = TRUE\n)\n\n\nTable 48: Useful summary statistics.\n\n\n\n\n\n\n\n\n\n\n\n\nSummary Statistics:\nSpeed - Membership\n\n\nCharacteristic\n\ncasual, N = 1,260,621\n\nmember, N = 2,636,777\n\n\n\n\nSpeed\n\n\n\n\n    Median (IQR)\n6.3 (4.5, 8.1)\n7.2 (5.7, 8.8)\n\n\n    Mean (SD)\n6.4 (2.7)\n7.3 (2.4)\n\n\n    Range\n1.0, 20.0\n1.0, 20.0\n\n\n\n\nSource: db/speed.db"
  },
  {
    "objectID": "index.html#interpretation-of-eda",
    "href": "index.html#interpretation-of-eda",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.9 Interpretation of EDA",
    "text": "3.9 Interpretation of EDA\nThe EDA (exploratory data analysis) sections employ various statistical methods to uncover patterns in user behavior and preferences. A chi-square analysis reveals a significant association between bicycle type and membership status (p &lt; 0.001). Binary logistic regression further quantifies this relationship, showing that electric bike users have lower odds of being members compared to classic bike users. Section 3.2\nTrip duration analysis, also utilizing binary logistic regression, uncovers a notable trend: the odds of membership decrease substantially as trip duration increases. This model, using quartiles of trip duration, indicates that members generally take shorter, more concentrated trips, while casual users are more likely to engage in longer rides. Section 3.3\nSeasonal trends emerge when examining monthly ridership patterns through another logistic regression model. The odds of membership fluctuate throughout the year, with the highest proportion of members riding during the colder months and early spring. As the weather warms, there’s a noticeable shift towards more casual ridership, as evidenced by lower odds ratios in the summer months. Section 3.4\nWeekly and daily patterns, analyzed using similar regression techniques, provide further insights into user behavior. Weekdays, Section 3.5, particularly during typical commuting hours, Section 3.6, see higher odds of member rides. In contrast, weekends and evenings show decreased odds of membership, suggesting an increased likelihood of casual ridership during these times.\nThe analysis of trip distances, again using logistic regression with distance quartiles, reveals an inverse relationship with membership status. Members are more likely to take shorter trips, while casual users tend to embark on longer journeys. This aligns with the duration findings and reinforces the idea that members use the service for quick, routine travel. Section 3.3\nInterestingly, trip speed shows a strong positive association with membership status in the logistic regression model. The odds of membership increase monotonically across speed quartiles, indicating that members generally ride at higher speeds compared to casual users. Section 3.8\nThese findings, derived from a combination of chi-square tests for independence and multiple binary logistic regression models, paint a picture of two distinct user groups: members who typically use the bike share for short, fast, routine trips during weekdays, and casual users who tend to take longer, slower rides, often during leisure hours or weekends.\nContingency tables and visualizations, including density plots and histograms, supplement these statistical analyses, providing a comprehensive view of the data distribution across various parameters such as bike type, trip duration, time of day, and day of the week.\nThe robust statistical approach, combining hypothesis testing (chi-square) with predictive modeling (logistic regression), provides strong evidence for the observed patterns in user behavior. These insights could prove valuable for tailoring marketing strategies, optimizing bike distribution, and enhancing service offerings to better serve both user segments."
  },
  {
    "objectID": "index.html#geographic-data",
    "href": "index.html#geographic-data",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.10 Geographic Data",
    "text": "3.10 Geographic Data\n\n3.10.1 Traffic Flow\n\nFigure 28 presents an intriguing bird’s-eye view of trip behaviors through an interactive epiflows graph. ]Moraga et al. (2019)] This R package used for creating this graph was re-purposed from its original intent for visualizing the spread of disease. This visualization employs a network of nodes (circles) connected by lines, where the thickness of the lines roughly corresponds to the volume of trips between the nodes, with thicker lines indicating a higher number of trips. The top 34 most frequently traveled stations are depicted in this visual network diagram.\n\nMoraga, P., Dorigatti, I., Kamvar, Z. N., Piatkowski, P., Toikkanen, S. E., Nagraj, V. P., Donnelly, C. A., & Jombart, T. (2019). epiflows: an R package for risk assessment of travel-related spread of disease. https://doi.org/10.12688/f1000research.16032.3\nThe interactive nature of the epiflows allows users to click on individual nodes and lines to access more detailed information. Additionally, a drop-down window provides further exploration capabilities, enabling users to delve deeper into the data.\nThese stations represent the most active locations within the system. Fortunately, Section 3.10.2 explores a potential approach to gain insights into the typical high-traffic station locations and the underlying reasons behind their elevated activity levels.\n\n\n\n\nCreating an EpiFlow\n\n\n\n\n\n\n\n\nFirst, creates the frequency of trips taken to and from pairs of stations. We are only going to look deeper into the top 50 most traveled pairs.flowData &lt;- dplyr::tbl(dbconn, filtered_path) |&gt;\n    dplyr::select(start_station_name, end_station_name) |&gt;\n    dplyr::group_by(start_station_name, end_station_name) |&gt;\n    dplyr::summarize(n = n()) |&gt;\n    dplyr::ungroup() |&gt;\n    dplyr::arrange(desc(n)) |&gt;\n    dplyr::rename(from_station = start_station_name, to_station = end_station_name) |&gt;\n    dplyr::collect() |&gt;\n    dplyr::slice_head(n = 50)\n\n\n\nSecond, we need statistics but also to combine the statistics for every unique station name.locationData &lt;- dplyr::tbl(dbconn, filtered_path) |&gt;\n    dplyr::select(start_station_name, end_station_name, started_at, ended_at, trip_time) |&gt;\n    dplyr::group_by(start_station_name, end_station_name) |&gt;\n    dplyr::mutate(trip_time = round(trip_time, digits = 0)) |&gt;\n    dplyr::summarize(trip_count = dplyr::n(), first_date = min(started_at), last_date = max(ended_at),\n        ) |&gt;\n    dplyr::ungroup() |&gt;\n    dplyr::rename(from_station = start_station_name, to_station = end_station_name) |&gt;\n    dplyr::arrange(desc(trip_count)) |&gt;\n    dplyr::collect()\n\n# Need to combine all names to single column and recalculate or retain other\n# stats.\nlocationData_pivoted &lt;- locationData |&gt;\n    tidyr::pivot_longer(cols = 1:2, values_to = \"allNames\") |&gt;\n    dplyr::group_by(allNames) |&gt;\n    dplyr::summarize(trips_toAndfrom = sum(trip_count), first_date = min(first_date),\n        last_date = max(last_date), ) |&gt;\n    dplyr::arrange(trips_toAndfrom)\n\n\n\nThird, creates epiflow objects, which take in a pair of dataframes and creates the flows between them.# for all the pairs\nef_test &lt;- epiflows::make_epiflows(flows = flowData, locations = locationData_pivoted,\n    num_cases = \"trips_toAndfrom\")\n\n\n\n\n\n\n\n\nTables\n\n\n\n\n\n\n\n\nFirst, just a quick view of the flow data table we made earlier.flowData\n\n# A tibble: 50 × 3\n   from_station                      to_station                   n\n   &lt;chr&gt;                             &lt;chr&gt;                    &lt;dbl&gt;\n 1 Ellis Ave & 60th St               Ellis Ave & 55th St       6927\n 2 Ellis Ave & 60th St               University Ave & 57th St  6600\n 3 Ellis Ave & 55th St               Ellis Ave & 60th St       6349\n 4 University Ave & 57th St          Ellis Ave & 60th St       6168\n 5 Calumet Ave & 33rd St             State St & 33rd St        5417\n 6 State St & 33rd St                Calumet Ave & 33rd St     5343\n 7 DuSable Lake Shore Dr & Monroe St Streeter Dr & Grand Ave   4023\n 8 Loomis St & Lexington St          Morgan St & Polk St       3719\n 9 Morgan St & Polk St               Loomis St & Lexington St  3379\n10 University Ave & 57th St          Kimbark Ave & 53rd St     3112\n# ℹ 40 more rows\n\n\n\nSecond, another quick view, but for thethe location data we pivoted earlier.locationData_pivoted |&gt;\n    dplyr::arrange(desc(trips_toAndfrom))\n\n# A tibble: 1,567 × 4\n   allNames              trips_toAndfrom first_date          last_date          \n   &lt;chr&gt;                           &lt;dbl&gt; &lt;dttm&gt;              &lt;dttm&gt;             \n 1 Streeter Dr & Grand …           86422 2023-01-01 00:05:43 2024-01-01 00:19:01\n 2 Kingsbury St & Kinzi…           61277 2023-01-01 01:21:59 2023-12-31 21:30:50\n 3 DuSable Lake Shore D…           60808 2023-01-01 02:12:09 2023-12-31 23:34:53\n 4 Clark St & Elm St               60552 2023-01-01 01:06:48 2023-12-31 23:29:33\n 5 Clinton St & Washing…           58278 2023-01-01 00:44:39 2023-12-31 18:03:02\n 6 Wells St & Concord Ln           57642 2023-01-01 01:15:27 2023-12-31 23:51:50\n 7 Michigan Ave & Oak St           54000 2023-01-01 00:59:17 2023-12-31 23:09:35\n 8 Wells St & Elm St               52315 2023-01-01 00:59:22 2023-12-31 23:51:48\n 9 DuSable Lake Shore D…           48833 2023-01-01 00:14:47 2023-12-31 16:49:56\n10 Theater on the Lake             48349 2023-01-01 03:14:22 2023-12-31 22:53:53\n# ℹ 1,557 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 28: EpiFlow Network\n\n\n\n\n\n\n\nCode Steps\n\n\nTable Preview\n\n\n\n\n3.10.2 Checking the Map\n\nThis section was made possible thanks to the latitude and longitude coordinates data provided alongside the stations names. Coming from the epiflow diagram, this should help make the data less abstract. The accordion below expands and collapses four OpenStreet maps found in the callout section below. These maps were split for viewing logistics. They contain from the epiflow in the section above. These maps are interactive, so the default views are zoom-able and movable. The transparent burst buttons enable snappy zooming-in of the station groups.\n\n\n\n\nCode for Mapping\n\n\n\n\n\n\n\n\nProcessing ‘flowData’ created earlier to include geolocation data for mapview plots.# All distinct stations in one column\nnames &lt;- flowData |&gt;\n    dplyr::select(from_station, to_station) |&gt;\n    tidyr::pivot_longer(cols = 1:2, names_to = NULL, values_to = \"station_names\") |&gt;\n    dplyr::distinct()\n\n# The important geo-coordinates corresponding to station names\nmapData &lt;- dplyr::tbl(dbconn, filtered_path, check_from = FALSE) |&gt;\n    dplyr::select(start_station_name, start_lat, start_lng, end_station_name, end_lat,\n        end_lng)\n\n# Filter to include all observations that match the station names listed in\n# 'names'. We need the geo-coordinates alongside the names.\nmapData1 &lt;- mapData |&gt;\n    dplyr::collect() |&gt;\n    # Filter, but through a vector of conditions.\ndplyr::filter(start_station_name %in% names[[1]], end_station_name %in% names[[1]]) |&gt;\n    dplyr::select(start_station_name:start_lng)\n\n# Had to split 'mapData' into two and pivot into a single table.\nmapData2 &lt;- mapData |&gt;\n    dplyr::collect() |&gt;\n    dplyr::filter(start_station_name %in% names[[1]], end_station_name %in% names[[1]]) |&gt;\n    dplyr::select(end_station_name:end_lng)\n\n# Nice grouping\nstations_groupMap &lt;- dplyr::bind_rows(mapData1, mapData2) |&gt;\n    dplyr::select(start_station_name, start_lat, start_lng) |&gt;\n    dplyr::rename(station_names = start_station_name, lat = start_lat, lng = start_lng) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::group_by(station_names)\n\n# Setting seed for sampling\nset.seed(113)\n\n# Taking 10 random samples from each station_name group\nsampled_stations &lt;- stations_groupMap |&gt;\n    dplyr::slice_sample(n = 10) |&gt;\n    tidyr::drop_na()\n\n\n\nCreates a map coloring palette excluding grays.# All of the r-colors\nallPalette &lt;- colors()\n\n# The grays are vast so we don't want those watering down the samples.\ncolorfulPal &lt;- purrr::discard(allPalette, stringr::str_detect(allPalette, \"gr(a|e)y\"))\n\n# When we sample the colors, 10 should be slightly more than needed.\nn_colors &lt;- 10\n\n\n\nFirst, sourcing the script needed to generate the maps and creating the list of vectors used as input. These vectors are the slices of the top most traveled stations.slicerVector &lt;- list(c(1:9), c(10:18), c(19:27), c(28:34))\nsource(\"Scripts/mapViewer.R\")\n\n\n\nThe script used to generate the maps.# ----\n# Author: Eric Mossotti\n# CC BY-SA\n# ----\n# I needed the stations groups' burst buttons to fit the viewing window in my \n# document and the only way I could think of is to split the stations into \n# multiple maps. This reduces duplicate code.\n# ----\nmapViewer &lt;- function(x) {\n    \n    nameSlice &lt;- sampled_stations |&gt;\n        dplyr::ungroup() |&gt;\n        dplyr::distinct(station_names) |&gt;\n        dplyr::slice(x)\n    \n    viewMap &lt;- sampled_stations |&gt;\n        dplyr::filter(station_names %in% nameSlice$station_names) |&gt;\n        sf::st_as_sf(coords = c(3:2), crs = 4326) |&gt;\n        mapview::mapview(\n            zcol = \"station_names\",\n            col.regions = randomColors,\n            map.types = \"OpenStreetMap\",\n            burst = TRUE,\n            legend = FALSE)\n    \n    return(viewMap)\n}\n\n\n\n\n\n\n\n\n\nBenson Ave & Church St … Ellis Ave & 60th St\n\n\n\n\n\nCodeset.seed(240)\nrandomColors &lt;- sample(colorfulPal, n_colors)\nmapViewer(slicerVector[[1]])\n\n\n\n\n\n\nFigure 29: Benson Ave & Church St - Ellis Ave & 60th St\n\n\n\n\n\n\n\n\n\nGreenview Ave & Fullteron Ave … Loomis Ave & Lexington St\n\n\n\n\n\n\n\n\n\n\n\nFigure 30: Greenview Ave & Fullteron Ave - Loomis Ave & Lexington St\n\n\n\n\n\n\n\n\n\nMichigan Ave & Oak St … State St & 33rd St\n\n\n\n\n\n\n\n\n\n\n\nFigure 31: Michigan Ave & Oak St - State St & 33rd St\n\n\n\n\n\n\n\n\n\nStreet Dr & Grand Ave … Woodlawn Ave & 55th St\n\n\n\n\n\nCodeset.seed(243)\nrandomColors &lt;- sample(colorfulPal, n_colors)\nmapViewer(slicerVector[[4]])\n\n\n\n\n\n\nFigure 32: Street Dr & Grand Ave - Woodlawn Ave & 55th St\n\n\n\n\n\n\n\n\n3.10.3 Interpretation of the Geographic Data\n\nFor example, suppose the user selects University Ave & 57th St in the epiflow visualization. This intersection happens to be at the heart of the University of Chicago campus. The natural next question is: where does the traffic to and from this location typically flow? By selecting one of the other nodes highlighted with flows directing away from the previous node, the user can identify Kimbark Ave and 53rd St. As seen in the map view, this location is situated adjacent to the Vue 53 Apartments complex. By analyzing such connections between nodes, the user can gain insights into common routes and destinations originating from a particular point of interest, potentially revealing patterns related to student housing, campus facilities, or other points of interest in the vicinity.\nThe data suggests individual members utilize the service multiple times weekly. However, further analysis is needed to determine if a significantly larger volume of unique individuals are annual members. Verifying associations between specific locations and higher or lower traffic could be a next step. Preliminary observations indicate universities, shopping centers, major companies, and nearby apartment complexes tend to have the highest ridership volumes.\nTo improve membership, addressing factors deterring individuals from becoming annual members could be key. These may include a lack of stations within walking distance of residences or destinations, or concerns over electric bicycle battery life and charging station availability, potentially explaining their lower utilization compared to classic bikes. Offering trial periods could allow casual users to experience the service’s reliability and convenience, encouraging conversion to annual memberships."
  },
  {
    "objectID": "index.html#updated-database-tables-list",
    "href": "index.html#updated-database-tables-list",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n3.11 Updated Database Tables List",
    "text": "3.11 Updated Database Tables List\n\nRevisiting the list of db tables, with many more tables added. All of these tables are stored within the data/data.db file.dbList2 &lt;- duckdb::dbListTables(dbconn) |&gt;\n    as.data.frame() |&gt;\n    tabler(title = \"Post-Exploratory Database Tables\", note_list = list(gt::md(\"Tables in `db/data.db` at this stage\")),\n        location_list = list(\"duckdb::dbListTables(dbconn)\"), noteColumns = TRUE,\n        source_note = gt::md(\"**Source**: `db/data.db`\")) |&gt;\n    gt::cols_label(`duckdb::dbListTables(dbconn)` = \"Table Paths\") |&gt;\n    gt::cols_align(align = \"left\")\n\ndbList2\n\n\nTable 49: Database Table List: Post-Exploratory Analysis\n\n\n\n\n\n\n\nPost-Exploratory Database Tables\n    \n\nTable Paths1\n\n    \n\n\ndb/bType.db\ndb/bType_wb.db\ndb/complete_data.db\ndb/data_unduped.db\ndb/distance.db\ndb/distance_wq.db\ndb/dow.db\ndb/dow_wq.db\ndb/duration.db\ndb/duration_wq.db\ndb/filtered_data.db\ndb/hod.db\ndb/hod_wq.db\ndb/membership.db\ndb/moy.db\ndb/moy_wq.db\ndb/original_data.db\ndb/speed.db\ndb/speed_wq.db\n\n\n\nSource: db/data.db\n\n    \n\n\n1 Tables in db/data.db at this stage\n    \n\n\n\n\n\n\n\n\n\n\nNotice the size difference from the previous image. The database is still represented in db folder as one file.."
  },
  {
    "objectID": "index.html#key-findings",
    "href": "index.html#key-findings",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n4.1 Key Findings",
    "text": "4.1 Key Findings\n\n\n\nMembership status significantly influences bike usage patterns:\n\nMembers prefer classic bikes (65%) over electric bikes (35%).\nCasual users have a higher electric bike usage (41%) compared to members.\nMembers typically take shorter, faster trips.\nCasual users tend to engage in longer, slower rides.\n\n\n\nTemporal patterns reveal distinct user behaviors:\n\nWeekdays and typical commuting hours see higher member activity.\nWeekends and evenings show increased casual ridership.\nMembership likelihood is highest during colder months and early spring.\nSummer months see a shift towards more casual ridership.\n\n\n\nTrip characteristics vary by user type:\n\nMembers are associated with shorter ride distances.\nTrip speed shows a strong positive association with membership status.\nThe likelihood of membership decreases as trip duration increases.\n\n\nHigh-traffic stations are often near universities, shopping centers, major companies, and apartment complexes.\nThe large sample size (nearly 4 million users) allows for high statistical significance in observed differences."
  },
  {
    "objectID": "index.html#recommendations",
    "href": "index.html#recommendations",
    "title": "Bike-Sharing in the Streets of Chicago",
    "section": "\n4.2 Recommendations",
    "text": "4.2 Recommendations\n\n\nTailor marketing strategies to target potential members for short, frequent trips, especially for commuting purposes.\nOptimize bike distribution to meet the demand for classic bikes among members and electric bikes among casual users.\nImplement promotional campaigns during summer months to convert casual users to members.\nConsider offering trial periods to allow casual users to experience the benefits of membership.\nInvestigate factors deterring individuals from becoming annual members, such as station proximity to residences or destinations.\nAddress potential concerns over electric bicycle battery life and charging station availability.\nFocus on improving service near high-traffic areas like universities, shopping centers, and residential complexes.\nDevelop targeted strategies to encourage casual users of longer, leisure rides to consider membership benefits.\nUtilize the epiflows visualization tool to identify and optimize popular routes and destinations.\nContinue to collect and analyze data to refine understanding of user behavior and preferences over time."
  }
]