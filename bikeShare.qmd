---
title: "BikeShare"
author: "Eric Mossotti"

bibliography: references.bib
repo: https://github.com/ericMossotti/Bike_Share
page-layout: article
source: bikeShare.qmd

code-links:
    - text: "Project Repo"
      href: repo
      
code-fold: true
code-copy: hover
code-overflow: wrap
code-tools: true

toc: true
toc_float: false
smooth-scroll: true

echo: true


#font: merriweather, futura
---

# Case Study: Bike-Sharing, Rethought

#### References:

-   [Bike-share research (bikeshare-research.org)](https://bikeshare-research.org/#bssid:chicago)

-   [Divvy - Wikipedia](https://en.wikipedia.org/wiki/Divvy)

-   [Cycling in Chicago - Wikipedia](https://en.wikipedia.org/wiki/Cycling_in_Chicago)

-   [Home \| Divvy Bikes](https://divvybikes.com/)

-   [Divvy Membership & Pass Options \| Divvy Bikes](https://divvybikes.com/pricing)

-   [@datalic]

    -   [Data License Agreement \| Divvy Bikes](https://divvybikes.com/data-license-agreement)

-   [@motivate]

    -   [MOTIVATE (motivateco.com)](https://motivateco.com/)

-   [@indexof]

    -   [Index of bucket "divvy-tripdata"](https://divvy-tripdata.s3.amazonaws.com/index.html)

-   [@whyduck]

    -   [Why DuckDB?](https://duckdb.org/why_duckdb)

-   [@rforda]

    -   [R for Data Science: Chapter 22: Arrow](https://r4ds.hadley.nz/arrow "Arrow")

-   [@great-ci]

    -   <https://en.wikipedia.org/wiki/Great-circle_distance>

-   [@average2024]

    -   <https://bikingultimate.com/average-bicycle-speed-how-fast-do-cyclists-ride-and-what-affects-their-pace/>

```{r, include = FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)
```

```{r}



if(dir.exists("db")) {
    
    tblPath <- "db/data.db"
    dbconn <- DBI::dbConnect(duckdb::duckdb(),
                             dbdir = tblPath,
                             read_only = FALSE)
    } else {
        source("import_clean_initial.R") 
        }
```

Can script up to this point?

```{r}
#|label: 'create dupe-table, count n distinct'

# This is a separate table used to analyze the observations returned as not distinct (n > 1). This adds an extra column labeled "n".
dupeTable <- dplyr::tbl(dbconn,
                        tblPath) |>
    dplyr::select(started_at:end_station_name) |>
    # Counts of unique rows added for column 'n'
    dplyr::add_count(started_at,
                     ended_at,
                     start_station_name,
                     end_station_name) |>
    # Only observations that have been duplicated 1 or more
    # times are shown
    dplyr::filter(n > 1) |>
    # We want to see all rows, not just one row for each obs
    dplyr::ungroup() |>
    dplyr::arrange(started_at) |>
    dplyr::collect()

n <- dupeTable |> 
    dplyr::distinct(n) |>
    as.integer()

n
```

We started with 5,719,877 observations (obs) for dates spanning January to December, 2023, then removed 1,388,170 incomplete obs.

Of the other columns, it seems that the start_time, end_time, start_station, and end_station could show if there are possibly hidden duplicated observations. Those 4 variables combined results in the most granular view of any one observation. Meaning, that data would naturally only have duplicates in error.

I assumed that having the same times/dates and stations for two different ride IDs was a mistake. Although, I do not know how that error would happen. I could have assumed one person could check out multiple bikes at once. In that instance, each bike could be assigned a unique ride_id. That, however, has only happened 18 times over a year. Since it's only one copy every time, that also raises a red flag. I did not notice any other correlations with station_id/name, member_casual, or ride_type for those particular duplicated data.

```{r}
#|label: 'output to distinct duplicates and total obs'

cat(" Distinct copy count of dupes: ", n,
    "\n\n",
    "Total observations that have and are duplicates: ",
       length(dupeTable[[1]]))
```

By applying distinct() on dupeTable, we see the only distinct value is 2. We can safely conclude that, of the duplicates, each has a minimum and maximum of 1 extra copy.

Number of rows in the dupeTable is 36. Because each duplicated observation has one duplicate (n = 2), expected removed nobs is 18. The issue is that we need to get rid of not all 36 rows, but just the 1 extra duplicate observation from each, resulting in the expected 18.

```{r}
#|label: 'create un-duped table, count rows'

# The issue is, we need to get rid of not all of these rows, but just the extra duplicate observations. 

# If there were 2 rows of duplicates, we would want to end up with 1 row after removing the extras.
undupedTable <- dupeTable |>
    dplyr::distinct(started_at,
                     start_station_name,
                     ended_at,
                     end_station_name,
                     .keep_all = TRUE)

n <- undupedTable |>
    dplyr::select(started_at) |>
    dplyr::distinct() |>
    dplyr::count() |>
    as.integer()
```

```{r}
#|label: 'output distinct obs, n'

cat("Count of distinct observations: ", n)
```

The count of observed distinct values for the un-duplicated table was indeed 18. So now, it is time to run a count of how rows/observations are in the dataset. There is a difference, though, concerning the correct amount.

```{r}
#|label: 'incorrect/correct distinct observations'

# Run an incorrect count on how many rows or observations there are in the dataset.
incorrectDistinct <- dplyr::tbl(dbconn,
                                tblPath) |>
    dplyr::distinct(dplyr::pick("ride_id")) |>
    dplyr::count(name = "Incorrect Distinct Observations") |>
    dplyr::collect() |>
    as.integer()

# For the correct count of obs
correctDistinct <- dplyr::tbl(dbconn,
                              tblPath) |>
    dplyr::distinct(
        dplyr::pick(
            "started_at",
            "start_station_name",
            "ended_at",
            "end_station_name"
        )
    ) |>
    dplyr::count() |>
    dplyr::collect() |>
    as.integer()
```

```{r}
#| label: 'duplicate correction tibb'
#| fig-cap: "Summary of observations removed by processing."
#| fig-cap-location: margin
#| column: body-outset

# To visualize a summary of what we just determined regarding obs
tibble::tibble(
    #"Original Obs" = original_nobs,
    "Uncorrected Complete Obs" = incorrectDistinct,
    "Corrected Complete Obs" = correctDistinct,
    "Removed Obs" = (incorrectDistinct - correctDistinct)
) |>
    polars::as_polars_df()
```

The incorrect number of observations (nobs) was 4,331,707. The correct nobs after removing duplicated obs was 4,331,689. In short, 18 additional obs were removed.

```{r}
#| label: 'overwrite file with correct obs'
#| column: body-outset

# Saving the data to a file to ensure we have a copy free from incomplete and duplicated obs.
dplyr::tbl(dbconn,
           tblPath,
           check_from = FALSE) |>
    dplyr::select(ride_id:trip_time) |>
    dplyr::distinct(started_at,
                    start_station_name,
                    ended_at,
                    end_station_name,
                    .keep_all = TRUE) |>
    dplyr::arrange(started_at) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = tblPath,
                         overwrite = TRUE)
```

Noting that it was useful for me to retain certain rows at first to determine if there were duplicates.

## Filtering Data, Smartly

To ensure the conclusions are accurate, outliers should be filtered. Negative and very low trip times might skew trends. The underlying reason for very low trip times is somewhat of an unknown. Perhaps people often change their minds?

```{r}
#| echo: false
#| label: "filter db"

tblPath_fltrd <- "db/ftrd.db"

if (duckdb::dbExistsTable(dbconn,
                          name = tblPath_fltrd) == TRUE) {
    tblPath <- "db/data.db"
    if (exists("dbconn",
               inherits = FALSE) == FALSE) {
        dbconn <- DBI::dbConnect(duckdb::duckdb(),
                                 dbdir = tblPath,
                                 read_only = FALSE)
        }
} else {
    
    tblPath_fltrd <- "db/fltrd.db"
    tblPath <- "db/data.db"
    # Because we might still have a valid connection
    if (exists("dbconn",
               inherits = FALSE) == FALSE) {
        dbconn <- DBI::dbConnect(duckdb::duckdb(),
                                 dbdir = tblPath,
                                 read_only = FALSE)
        }
    # Imposing sensible limits on the data we wish to include moving forward.
    dplyr::tbl(dbconn,
               tblPath) |>
        dplyr::filter(trip_time > 1,
                      trip_time < 480,
                      rideable_type != "docked_bike") |>
        dplyr::collect() |>
        # Might as well calculate distance traveled while at it.
        dplyr::mutate(
            miles = geosphere::distGeo(
                p1 = cbind(start_lng, start_lat),
                p2 = cbind(end_lng, end_lat)
            ) / 1000 * 0.62137119,
            mph = (miles / (trip_time / 60))
        ) |>
        # It's nonsensical to rent a bike for distances easily walked.
        # Also, there could be randomly generated data.
        dplyr::filter(miles > 0.1,
                      # Seems that pro cyclists average around 20 mph,
                      # so I set that as the ceiling.
                      mph < 21,
                     # To account for time spent idling, stoplights and
                     # traffic.
                      mph > 1) |>
        duckdb::dbWriteTable(conn = dbconn,
                             name = tblPath_fltrd,
                             overwrite = TRUE,
                             check_from = FALSE)
}

source("duckDrops.R")
```

# Data Modeling

**Non-parametric descriptive:**

-   median, interquartile-range (IQR)

## **Semi-parametric and non-parametric** methods

**Description**

-   To predict the outcome variable using independent variables

    -   outcome variable(s) to test

        -   member_casual

**Statistical methods**

-   Binary Logistic regression analysis

**Data type**

-   Outcome variable:

    -   Categorical (\>= 2 categories)

        -   member_casual

        -   rideable_type

-   Independent variable(s):

    -   Categorical (\>= 2 categories) or

        -   hour

            -   24 categories

        -   day_of_week

            -   7 categories

        -   month

            -   12 categories

        -   holiday

            -   2 categories (yes or no?)

        -   member_casual

            -   2 categories

        -   rideable_type

            -   2 categories

    -   Continuous or

        -   trip_time

        -   mph

        -   miles

        -   geospatial location

    -   both

        -   member_causal

        -   rideable_type

        -   hour

        -   day

        -   trip_time

        -   mph

        -   miles

        -   geospatial location

# Frequency Tables

```{r}

dplyr::tbl(dbconn_fltrd,
           tblPath_fltrd) |>
    dplyr::filter(trip_time)
```

```{r}

# Member_casual
dplyr::tbl(dbconn,
           tblPath_fltrd,
           check_from = FALSE) |>
    dplyr::select(member_casual) |>
    dplyr::collect() |>
    table()

# Rideable_type 
dplyr::tbl(dbconn,
           tblPath_fltrd,
           check_from = FALSE) |>
    dplyr::select(rideable_type) |>
    dplyr::collect() |>
    table()

# Trip_time
trip_time <- dplyr::tbl(dbconn,
                        tblPath_fltrd,
                        check_from = FALSE) |>
    dplyr::select(trip_time) |>
    dplyr::mutate(trip_time = round(trip_time, digits = 0)) |>
    dplyr::collect() |>
    table() |>
    as.data.frame()

trip_time[1] <- as.integer(trip_time[[1]])
trip_time[2] <- as.integer(trip_time[[2]])

#iqr_tripTime <- IQR(trip_time$Freq)
summary_tripTime <- summary(trip_time)

summary_tripTime
```

The 3rd quartile for Freq (the count, or frequency, per minute group) was 676. To get a better distribution, I'm going to set 676 as the min Freq value to be included in the frequency table for trip_time.

```{r}

# The 3rd quartile for Frequency was 676. To get a better distribution, I'm going to set 676 as the min Freq value to be included in the frequency table for trip_time.
trip_time_fltrd <- trip_time |>
    dplyr::filter(Freq >= 676)

summary_tripTime_fltrd <- summary(trip_time_fltrd)
```

```{r}

# Miles
miles <- dplyr::tbl(dbconn_fltrd,
                        tblPath_fltrd,
                        check_from = FALSE) |>
    dplyr::select(miles) |>
    dplyr::mutate(miles = round(miles, digits = 0)) |>
    dplyr::collect() |>
    table() |>
    as.data.frame()

miles[1] <- as.integer(miles[[1]])
miles[2] <- as.integer(miles[[2]])

summary_miles <- summary(miles)

summary_miles
```

To get a better distribution for the first quartile and median value, miles' frequency table, I'm going to set the min to the median of the above table.

```{r}

# To get a better distribution for the first quartile and median value, miles' frequency table, I'm going to set the min to the median of the above table.
miles_fltrd <- miles |>
    dplyr::filter(Freq >= 686)

summaryMiles_fltrd <- summary(miles_fltrd)

summaryMiles_fltrd
```

```{r}

# Miles
mph <- dplyr::tbl(dbconn_fltrd,
                        tblPath_fltrd,
                        check_from = FALSE) |>
    dplyr::select(mph) |>
    dplyr::mutate(mph = round(mph, digits = 0)) |>
    dplyr::collect() |>
    table() |>
    as.data.frame()

mph[1] <- as.integer(mph[[1]])
mph[2] <- as.integer(mph[[2]])

summary_mph <- summary(mph)

summary_mph
```

By doing frequency tables, I quickly gain insight into the optimal settings of filter parameters as opposed to making educated guesses..

```{r}



if(dir.exists("db_fltrd")) {
    
    tblPath_fltrd <- "db_fltrd/fltrd.db"
    
    dbconn_fltrd <- DBI::dbConnect(duckdb::duckdb(),
                              dbdir = tblPath_fltrd,
                              read_only = FALSE)
} else {
    dir.create("db_fltrd")
    
    tblPath_fltrd <- "db_fltrd/fltrd.db"
    
    dbconn_fltrd <- DBI::dbConnect(duckdb::duckdb(),
                                   dbdir = tblPath_fltrd,
                                   read_only = FALSE)
    
    # Imposing sensible limits on the data we wish to include moving forward.
    dplyr::tbl(dbconn,
               tblPath) |>
        dplyr::filter(trip_time > 1,
                      trip_time < 480,
                      rideable_type != "docked_bike") |>
        dplyr::collect() |>
        # Might as well calculate distance traveled while at it.
        dplyr::mutate(
            miles = geosphere::distGeo(
                p1 = cbind(start_lng, start_lat),
                p2 = cbind(end_lng, end_lat)
            ) / 1000 * 0.62137119,
            mph = (miles / (trip_time / 60))
        ) |>
        # It's nonsensical to rent a bike for distances easily walked.
        # Also, there could be randomly generated data.
        dplyr::filter(miles > 0.1,
                      # Seems that pro cyclists average around 20 mph,
                      # so I set that as the ceiling.
                      mph < 21,
                     # To account for time spent idling, stoplights and
                     # traffic.
                      mph > 1) |>
        duckdb::dbWriteTable(conn = dbconn_fltrd,
                             name = tblPath_fltrd,
                             overwrite = TRUE,
                             check_from = FALSE)
}
```

```{r}
#|label: 'rider count by hour table'

hours_of_Riders <- dplyr::tbl(dbconn_fltrd,
                              tblPath_fltrd,
                              check_from = FALSE) |>
    dplyr::select(started_at) |>
    dplyr::mutate("hour" = lubridate::hour(started_at)) |>
    dplyr::group_by(hour) |>
    dplyr::summarise("Total_Riders" = dplyr::count(started_at)) |>
    dplyr::arrange(hour) |>
    dplyr::collect() |>
    dplyr::mutate("hour" = hms::hms(hours = hour),
                  "hour" = format(strptime(hour, format = "%H"), "%r"),
                  "index" = seq(1:24))
```

```{r}

x <-
    stringr::str_sub_all(hours_of_Riders[[1]],
                         start = 1,
                         end = 2) |>
    as.character() |>
    stringr::str_remove(pattern = "^0")

y <- stringr::str_sub(hours_of_Riders[[1]],
                      start = -2,
                      end = -1) |>
    stringr::str_to_lower()

simpleTimes <- stringr::str_c(x, sep = " ", y)

hours_of_Riders[[1]] <- simpleTimes

hours_of_Riders
```

# Visualizations

::: column-page
```{r}
#| label: 'radial-column plot'
#| fig-column: page
#| fig-cap: "The time of day people tend to be riding."
#| fig-cap-location: bottom
#| title: "Time of Day and Volume of Cyclers"
#| fig-width: 15
#| fig-height: 12

hoursAnimate <- ggplot2::ggplot(data = hours_of_Riders,
                mapping = ggplot2::aes(
                    x = reorder(hour, .data$index),
                    y = Total_Riders,
                    fill = Total_Riders)) +
    ggplot2::geom_col() +
    ggplot2::coord_radial(start = 2 * pi,
                          inner.radius = .2) +
    ggplot2::xlab(NULL) +
    ggplot2::ylab(NULL) +
    ggplot2::scale_fill_distiller(palette = "Spectral",
                                  direction = 1) +
    ggplot2::labs(
        title = "Average Riders by the Hour of Day",
        subtitle = "(Jan-Dec 2023)",
        caption = "Data from cyclistic database.",
        tag = "Figure 1.c"
        ) +
    ggplot2::theme(
        title = ggplot2::element_text(
            size = 20,
            lineheight = 4,
            color = "white"
        ),
        
        text = ggplot2::element_text(color = "white"),
        
        panel.background = ggplot2::element_rect(fill = "black"),
        panel.grid.major.x = ggplot2::element_line(linewidth = 1,
                                                   color = 'grey10'),
        panel.grid.major.y = ggplot2::element_blank(),
        
        
        plot.background = ggplot2::element_rect(fill = "black"),
        
        axis.line.x = ggplot2::element_line(
            linewidth = 1,
            color = 'grey10',
            arrow = ggplot2::arrow()
        ),
        
        axis.ticks.y = ggplot2::element_blank(),
        
        axis.text.x = ggplot2::element_text(
            size = 18,
            color = "grey90",
            face = "bold"
        ),
        axis.text.y = ggplot2::element_blank(),
        
        legend.background = ggplot2::element_rect(fill = "black"),
        legend.ticks = ggplot2::element_line(color = "black",
                                             linewidth = .5),
        legend.text = ggplot2::element_text(color = 'grey80',
                                            size = 13),
        legend.position = "right",
        legend.justification = "center",
        legend.direction = "vertical",
        legend.key.size = unit(1.5, "cm")
       )

hoursAnimate

        #gganimate::transition_reveal(along = seq(length(hour)))
#my_anim <- gganimate::animate(hoursAnimate,
        #                     renderer = gganimate::gifski_renderer())

#my_anim
```
:::

```{r}
#| label: "column plot"
#| column: body-outset
#| include: false
#| eval: false

memberCasuals_monthly  <- dplyr::tbl(dbconn,
           db_path) |>
    dplyr::select(started_at,
                  member_casual) |>
    dplyr::mutate('month' = lubridate::month(started_at)) |>
    dplyr::group_by(month,
                    member_casual) |>
    dplyr::summarize("riderCount" = dplyr::count(member_casual)) |>
    dplyr::arrange(month)

dplyr::collect(memberCasuals_monthly) |>
    ggplot2::ggplot() +
    ggplot2::geom_col(mapping = ggplot2::aes(x = factor(month),
                                             y = riderCount,
                                             fill = member_casual),
                      color = "black",
                      position = 'dodge2') +
    ggplot2::scale_x_discrete(labels = month.abb,
                              name = "Month") +
    ggplot2::scale_fill_brewer(palette = 'Set2') +
    ggplot2::theme_dark() +
    ggplot2::labs(
    title = "Monthly Ridership: Members vs Casuals",
    subtitle = "(Jan-Dec 2023)",
    caption = "Data from cyclistic database.",
    tag = "Figure 1.b")
```

for quick reference with using Tsibble syntax

```{r}
#|label: 'grouped tibb'

grouped_byDay <- dplyr::tbl(dbconn_fltrd,
                            tblPath_fltrd) |>
    dplyr::select(started_at,
                  member_casual) |>
    dplyr::collect() |>
    dplyr::mutate(started_at = as.Date(started_at)) |>
    dplyr::group_by(started_at,
                    member_casual) |>
    dplyr::summarize(n = dplyr::n(),
                     sdev = stats::sd(n))
```

```{r}
#|label: 'to grouped tsibb'

# tsibble, time-series table/tibble seems to make time series plots more straightforward
grouped_tsi <- grouped_byDay |>
    tsibble::as_tsibble(key = c(member_casual,
                                n),
                        index = started_at) |>
    dplyr::arrange(started_at)
```

```{r}
#| label: 'scatter plot'
#| include: false
#| eval: false

grouped_tsi |> ggplot2::ggplot(
    mapping = ggplot2::aes(x = started_at, 
                           y = n,
                           color = grouped_tsi$member_casual
                           )) +
    ggplot2::geom_point(size = 3,
                        alpha = 0.25) +
    ggplot2::scale_color_brewer(palette = "Dark2") +
    ggplot2::labs(title = "Daily Count by Membership Type",
                  subtitle = "2023",
                  x = "Month",
                  y = "Count")
```

```{r}
#|label: "map query setup"

# chicago starting coordinates for leaflet, setView
chicago <- maps::us.cities |>
    dplyr::select("name",
                  "long",
                  "lat") |>
    dplyr::filter(name == "Chicago IL")

# full dataset coordinates, might need to sample
coordQry <- dplyr::tbl(dbconn_fltrd,
                       tblPath_fltrd) |>
    dplyr::select(start_lng,
                  start_lat) |>
    dplyr::add_count(start_lng,
                     start_lat) |>
    dplyr::distinct() |>
    dplyr::arrange(desc(n)) |>
    dplyr::collect()


coordQry_small <- dplyr::tbl(dbconn_fltrd,
                             tblPath_fltrd) |>
    dplyr::select(start_lng,
                  start_lat) |>
    dplyr::add_count(start_lng,
                     start_lat) |>
    dplyr::distinct() |>
    dplyr::arrange(desc(n)) |>
    dplyr::collect() |>
    dplyr::slice_head(n = 50)
```

```{r}
#| label: "leaflet"
#| eval: false
#| include: false


leaflet::leaflet() |>
    leaflet::addTiles() |>
    leaflet::setView(lng = chicago$long,
                     lat = chicago$lat,
                     zoom = 10) |>
    leaflet::addMarkers(lng = coordQry$start_lng[1:50],
                        lat = coordQry$start_lat[1:50],
                        clusterOptions = leaflet::markerClusterOptions())
```

```{r}
#|label: "mapview"

coordQry_small |>
    sf::st_as_sf(coords = c(1:2),
                crs = 4326) |>
    mapview::mapview()
```

```{r}
#| label: "tmap"
#| eval: false
#| include: false

illi <- subset(spData::us_states, NAME == "Illinois")
tmap::tmap_mode("view")
coordQry_small |>
    sf::st_as_sf(coords = c(1:2),
                 crs = 4326) |>
    tmap::tm_shape() +
    tmap::tm_markers(clustering = TRUE) +
    tmap::tm_basemap(server = c('OpenStreetMap'))
```

```{r}
ojs_define(js_tsi = grouped_tsi)
```

```{ojs}
jsData = transpose(js_tsi)
```

::: column-page
```{ojs}
Plot.plot({
    grid: true,
    color: {legend: true},
    marks: [
        Plot.dot(jsData, {x: 'started_at', y: 'n', fill: 'member_casual'})
]
})
```
:::

```{ojs}
Plot.lineY(jsData, {x: "started_at", y: "n"}).plot()
```

```{ojs}
Inputs.table(jsData, {
rows: 20
})
```

```{r}
#| label: 'line plot'
#| eval: false
#| include: false

grouped_tsi |> ggplot2::ggplot(
    mapping = ggplot2::aes(x = started_at, 
                           y = n,
                           color = grouped_tsi$member_casual
                           )) +
    ggplot2::geom_line(stat = 'align',
                       lineend = 'round',
                       linejoin = 'mitre',
                       linewidth = .5,
                       alpha = .8) +
    ggplot2::scale_color_brewer(palette = "Set1") +
    ggplot2::labs(title = "Daily Count by Membership Type",
                  subtitle = "2023",
                  x = "Year-Month",
                  y = "Count")
```

```{r}
#| label: 'area plot'
#| column: body-outset
#| eval: false
#| include: false

grouped_tsi |> ggplot2::ggplot(
    mapping = ggplot2::aes(x = started_at, 
                           y = n,
                           fill = grouped_tsi$member_casual)) +
    ggplot2::geom_area(alpha = 0.8) +
    ggplot2::scale_x_date(date_breaks = "month",
                          minor_breaks = "day",
                          date_labels = "%b") +
    ggplot2::scale_fill_brewer(palette = "Dark2") +
    ggplot2::labs(title = "Daily Count by Membership Type",
                  subtitle = "2023",
                  x = "Month",
                  y = "Count")
```

```{r}
#| label: 'histogram plot'
#| include: false
#| eval: false

# query for the histogram plot
qry4_histo <- dplyr::tbl(dbconn_fltrd,
                         tblPath_fltrd) |>
    dplyr::select(started_at, member_casual) |>
    dplyr::collect() |>
    dplyr::mutate(started_at = as.Date(started_at)) |>
    dplyr::group_by(member_casual) |>
    dplyr::arrange(started_at)

# histogram plot
qry4_histo |> ggplot2::ggplot(
    mapping = ggplot2::aes(x = started_at, 
                           fill = qry4_histo$member_casual)) +
    ggplot2::geom_histogram(alpha = 0.6,
                            bins = 365
                            ) +
    ggplot2::scale_x_date(date_breaks = "1 month",
                          date_minor_breaks = 'days',
                          date_labels = "%b") +
    ggplot2::scale_fill_brewer(palette = "Dark2") +
    ggplot2::labs(title = "Daily Count by Membership Type",
                  subtitle = "2023",
                  x = "Months",
                  y = "Count")
```

```{r}
#|label: 'grouped stats tibb'

# Need a useful data frame for basic aggregations
groupedStats_byDay <- dplyr::tbl(dbconn_fltrd,
                                 tblPath_fltrd) |>
    dplyr::select(started_at,
                  member_casual,
                  rideable_type,
                  trip_time,
                  miles,
                  mph) |>
    dplyr::collect() |>
    dplyr::mutate(started_at = as.Date(started_at)) |>
    dplyr::group_by(started_at,
                    member_casual,
                    rideable_type) |>
    dplyr::summarize(n = dplyr::n(),
                     trip_time_Mean = mean(trip_time),
                     trip_time_stDev = stats::sd(trip_time),
                     miles_Mean = mean(miles),
                     miles_stDev = stats::sd(miles),
                     mph_Mean = mean(miles),
                     mph_stDev = stats::sd(mph))
```

```{r}
#|label: 'grouped stats tsibb'

# Would prefer to work with a tsibble for time-series data
groupedStats_tsib <- groupedStats_byDay |>
    tsibble::as_tsibble(key = c(member_casual:mph_stDev),
                        index = started_at) |>
    dplyr::arrange(started_at)
```

```{r}
#| eval: false
#| label: 'Ribbon-Line Plot'
#| include: false

groupedStats_tsib |> 
    ggplot2::ggplot(ggplot2::aes(started_at,
                                 group =  rideable_type)) +
    ggplot2::geom_ribbon(alpha = 0.4,
        ggplot2::aes(
            ymin = (groupedStats_tsib$trip_time_Mean -
                groupedStats_tsib$miles_stDev),
            ymax = (groupedStats_tsib$trip_time_Mean +
                groupedStats_tsib$miles_stDev)),
                         fill = 'white') +
        ggplot2::geom_line(ggplot2::aes(y = trip_time_Mean,
                                    color = rideable_type),
                           alpha = 1) + 
    ggplot2::scale_x_date(date_labels = '%B',
                          date_minor_breaks = 'days',
                          limits = as.Date(c('2023-01-01', '2024-01-01'))) +
    ggplot2::scale_color_brewer(palette = 'Pastel1') +
    ggplot2::theme_dark()
```

```{r}
#| label: 'Facet-Wrap Plot'
#| column: page
#| fig-width: 14
#| fig-height: 12

# A solution to help visualize these mutli-dimensional relationships of membership and bike type to time.
groupedStats_tsib |>
    ggplot2::ggplot(ggplot2::aes(x = started_at,
                                 y = trip_time_Mean,
                                 color = trip_time_Mean)) +
    ggplot2::geom_count(size = 3) +
    ggplot2::facet_wrap(~member_casual+rideable_type) +
    ggplot2::scale_x_date(date_minor_breaks = "days",
                          date_labels = "%b",
                          breaks = "months") +
    ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45,
                                                       hjust = 1),
                   panel.background = ggplot2::element_rect(fill = 'grey20'),
                   panel.grid.major.y = ggplot2::element_line(
                       linetype = 'dashed',
                       color = 'grey30'),
                   panel.grid.major.x = ggplot2::element_line(
                       linetype = 'dotted',
                       color = 'grey30'),
                   panel.grid.minor = ggplot2::element_blank(),
                   strip.background.x = ggplot2::element_rect(
                       fill = 'yellowgreen')) +
    ggplot2::scale_color_distiller(palette = 'Spectral')
```

```{r}
#|label: "dygraph"

sumDF <- groupedStats_byDay |>
    dplyr::select(started_at,
                  n) |>
    dplyr::group_by(started_at,
                    member_casual) |>
    dplyr::summarise("count" = sum(n)) |>
    tidyr::pivot_wider(names_from = member_casual,
                       values_from = count)

dygraphs::dygraph(sumDF, main = "ever",
                  ylab = "what") |>
    dygraphs::dyGroup(name = c("member", "casual"),
                       color = c("green", "red"))
```

These maps track bike-sharing activity going on worldwide and in Chicago.

[Bike Share Map](https://bikesharemap.com/#/8/-87.5771/41.3747/) [@bikesha]

[CityBikes: bike sharing networks around the world](https://citybik.es/) [@citybike]

```{r, eval = FALSE}
#|label: 'drops duckDB tables'

source("duckDrops.R")
```

```{r}
#|label: 'duckDB Shutdown'
duckdb::dbDisconnect(dbconn_fltrd, shutdown = TRUE)
duckdb::dbDisconnect(dbconn, shutdown = TRUE)
```
