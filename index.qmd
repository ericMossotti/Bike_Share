---
title: "Bike-Sharing in the Streets of Chicago"
author: "Eric Mossotti"
date: "05-23-2024"
date-modified: last-modified
date-format: "MMM D, YYYY"

bibliography: references.bib
repo: https://github.com/ericMossotti/Bike_Share
source: index.qmd
abstract-title: "Objective"
abstract: "Communicating reproducible, data-driven insights."
description-meta: "Communicate reproducible, data-driven insights."

code-links:
    - text: "Project Repo"
      href: https://github.com/ericMossotti/Bike_Share
code-fold: true
code-copy: hover
code-overflow: wrap
code-tools: true
code-link: true

toc: true
toc-location: left
toc-depth: 5
number-sections: true
link-external-newwindow: true

smooth-scroll: true
fig-responsive: true
echo: true

citation-location: margin
citations-hover: true
link-citations: true
csl: csl/apa.csl
zotero: true

callout-appearance: simple

license: CC BY-SA
funding: "The author(s) received no specific funding for this work."
---

```{r, include = FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE
                      #cache.lazy = FALSE,
                      #cache = TRUE
                      )
```

------------------------------------------------------------------------

# Intro

::: {#offcanvas1 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {#offcanvasLabel .h5 .offcanvas-title}
Import Processing Code
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: importOrConnect
#| code-summary: First, we decide whether to download and do the necessary initial processing steps or skip that if we have already done this and are just tinkering around with the project. 

if(exists("dbconn") == FALSE &&
   dir.exists("db") == FALSE) {
    # Script within if-else to simplify workflow
    source("Scripts/import_clean_initial.R")
} else {
    tblPath <- "db/data.db"
    
    dbconn <- DBI::dbConnect(
        duckdb::duckdb(),
        dbdir = tblPath,
        read_only = FALSE)
}

# Paths one might still need if script doesn't need to execute.
tblPath <- "db/data.db"
tblPath_fltrd <- "db/data_fltrd.db"
rawPath <- "db/rawData.db"

# Loading plot and table scripts while at it. 
source("Scripts/tabler.R")
source("Scripts/plotter.R")
source("Scripts/TransformData.R")

```

```{r}
#| label: importProcessScript
#| code-summary: This then would be executed if conditions were met. Usually, this would only execute if there is no db folder and associated files.
#| file: "Scripts/import_clean_initial.R"
#| eval: false 
```
:::
:::
:::

## Stakeholders

::: p-1
The primary stakeholders in this analysis are Divvy, Lyft (the parent company of Divvy), and the City of Chicago Department of Transportation. The analysis aims to provide these stakeholders with data-driven insights to enhance the Divvy bike-sharing service, better serving the residents of Chicago and its users. The initial rationale behind Divvy's implementation included improving air quality, promoting economic recovery, and reducing traffic congestion within the city. [@aboutdi]
:::

## Source

::: p-1
The raw 2023 dataset was imported from Divvy Data. [@divvyda]
:::

::: column-screen-inset
```{r}
#| label: tbl-raw
#| tbl-cap: Raw data
#| cap-location: top

# List of column labels to feed tabler() and add_multiple_footnotes()
location_list <- dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
colnames() |>
as.list()

# A simple list of footnotes to feed tabler() and add_multiple_footnotes().
note_list <- list(
"Anonymized trip identifier.", 
"The bicycle type.", 
"Starting date-time (to the second).",
"Ending date-time (to the second).",
"Station name of where the trip started.",
"Station ID of where the trip started.",
"Station name of where the trip ended.",
"Station ID of where the trip ended.",
"Latitude associated with the starting location.",
"Longitude associated with the starting location.",
"Latitude associated with the ending location.",
"Longitude associated with the ending location.",
"If someone is an annual subscriber or not."
)

dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
dplyr::slice_head(n = 10) |>
tabler(
title = "A Glimpse of the Raw Data",
source_note = gt::md("**Source**: Divvy Data"),
note_list = note_list,
location_list = location_list,
value_columns = NULL
) |>
gt::tab_options(
table.font.size = gt::pct(75),
footnotes.multiline = FALSE
)

```
:::

::: {#offcanvas100 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Glimpse
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: glimpseRaw
#| code-summary: A quick overview of the raw data.

dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
tibble::glimpse() 
```
:::
:::
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas100" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: #F4511E;"></i>
```
:::
:::

## Design

::: p-1
Another worthy objective of this analysis is to achieve reproducibility and efficiency. To facilitate future research and enable subsequent analyst teams to build upon this work, the project aimed to provide adequate code documentation and adhere to best practices regarding clean code and mod-ability.

For instance, certain design decisions were incorporated to eliminate the need for re-downloading and re-processing data. For analysts conducting analysis over an extended period, such as days or months, on this dataset, it is now possible to simply reconnect to the single database file containing all the original data, including tables generated throughout the analysis process, following the initial download and subsequent processing.

The underlying code incorporates an if-else decision, which includes a source code script responsible for handling the initial data processing and establishing the database filesystem. Opting for a persistent DuckDB filesystem (as opposed to a purely in-memory solution) appeared optimal in terms of simplicity, cost-effectiveness of SQL database queries, and retaining progress made over extended periods. [@whyduck]

To streamline the process, reduce code duplication, and maintain consistent formatting throughout the project, reusable functions were developed for generating most of the tables and figures. These functions are located in the "Scripts" folder within the working directory. Their modular design not only simplifies the implementation of formatting changes but also facilitates the integration of additional code snippets when necessary. For instance, certain plots might require limiting the range of the axes, which can be achieved by combining these functions with appropriate code addendum. By leveraging these functions, the project benefits from reduced redundancy, improved efficiency, and cohesive formatting across all visualizations and data representations.
:::

## Initial Database Table List

```{r}
#| label: tbl-dbList
#| code-summary: "These are the starting tables contained in the data/data.db file. Noting this as we will be adding many more tables in the later stages."
#| tbl-cap: "Initial DB Table List"


dbList <- duckdb::dbListTables(dbconn) |>
as.data.frame() |>
tabler(
title = "Starting Database Tables",
note_list = list(gt::md("The tables contained <br>in data.db, at the end of the analysis.")),
location_list = list("duckdb::dbListTables(dbconn)")
) |>
gt::cols_label("duckdb::dbListTables(dbconn)" = "Table Paths") |>
gt::tab_style(
gt::cell_text(
align = "center",
stretch = "semi-expanded"
), 
locations = list(
gt::cells_body(columns = gt::everything()),
gt::cells_column_labels(columns = gt::everything()))
)

dbList
```

::: flex-code
```{r}
#| label: tablerScript
#| code-summary: This code was used for generating many of the tables. See the later code dropdowns alongside tables for clues as to how it is implented in this document.
#| file: "Scripts/tabler.R"
#| eval: false 
```
:::

::: flex-code
```{r}
#| label: plotterScript
#| code-summary: This code was used for generating many of the plots. See the later code dropdowns alongside tables for clues as to how it is implented in this document.
#| file: "Scripts/plotter.R"
#| eval: false 
```
:::

# Tidying

::: p-3
The starting observation count was 5,719,877. Then 1,388,170 incomplete observations were then removed by the initial processing script.
:::

::: {.callout-warning .calloutWarning icon="false" width="auto"}
Code processing steps are accessible through embedded code icon links, like the one below. Drop-down code summaries provide context on data processing rationale and methodology at various analysis stages, enhancing reader understanding.
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas1" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: 1.5rem; color: #00BFA5;"></i>
```
:::
:::

## Duplicates

::: {#offcanvas2 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Code to Remove Duplicates
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: originalNobs
#| code-summary: First, record original observations from the raw data.

# Need to save this count for the summary table later
original_nobs <- dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
nrow()

```

```{r}
#| label: duplicates_gt
#| code-summary: Create a table containing the duplicated observations.

# This is a separate table used to analyze the observations 
#  returned as not distinct (n > 1). 
#   This adds an extra column, labeled "n".
dupeTable <- dplyr::tbl(dbconn,
                        tblPath) |>
    dplyr::select(started_at:end_station_name) |>
# Counts of unique rows added for column 'n'
    dplyr::add_count(started_at,
                     ended_at,
                     start_station_name,
                     end_station_name) |>
# Only observations that have been duplicated 1 or more times are shown.
    dplyr::filter(n > 1) |>
# To see all rows, not just one row for each obs.
    dplyr::ungroup() |>
    dplyr::arrange(started_at) |>
    dplyr::collect()
```

```{r}
#| label: duplicateObs count
#| code-summary: Record a count of distinct duplicates and total observations.

distinctCopiesCount <- dupeTable |>
    dplyr::distinct(n) |>
    as.integer() 

duplicateObs <- length(dupeTable[[1]])
```

```{r}
#| label: undupedTable
#| code-summary: Create a table of the now unduplicated observations seen earlier.

# The issue is, we need to get rid of not all of these rows, but just the extra duplicate observations.

# If there were 2 rows of duplicates, one would want to end up with 1 row after removing the extras.
undupedTable <- 
dupeTable |>
dplyr::distinct(started_at, 
start_station_name, 
ended_at, 
end_station_name)
```

```{r}
#| label: incorrect distinct obs count
#| code-summary: Record a count of the incorrect observations.

# Run an incorrect count on how many rows or observations there are in the dataset.
count_incorrectDists <- dplyr::tbl(dbconn,
                                   tblPath) |>
    dplyr::distinct(dplyr::pick("ride_id")) |>
    dplyr::count(name = "Incorrect Distinct Observations") |>
    dplyr::collect() |>
    as.integer()
```

```{r}
#| label: count_correctDists count
#| code-summary: Record a count of the correct observations.

# For the correct count of obs
count_correctDists <- dplyr::tbl(dbconn,
                                 tblPath) |>
    dplyr::distinct(
        dplyr::pick(
            "started_at",
            "start_station_name",
            "ended_at",
            "end_station_name")) |>
    dplyr::count() |>
    dplyr::collect() |>
    as.integer()
```

```{r}
#| label: overwrite file with correct obs
#| code-summary: Lastly, write the unduplicated data to the database.

dplyr::tbl(dbconn,
           tblPath) |>
    dplyr::distinct(started_at,
                    start_station_name,
                    ended_at,
                    end_station_name,
                    .keep_all = TRUE) |>
    dplyr::arrange(started_at) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = tblPath,
                         overwrite = TRUE)

```
:::
:::
:::

::: p-1
A crucial question arises: How can one identify and handle duplicate data? This section covers the process of checking for duplicates and selectively removing them while exercising caution. It is essential to recognize that the presence of unique values in a single column does not necessarily guarantee the uniqueness of each observation or row.

While all values in the **ride_id** column were found to be unique, not all observations were truly distinct. To verify the uniqueness of each observation, additional columns such as **start_time**, **end_time**, **start_station**, and **end_station** were utilized. These columns provide more granular information, including the precise starting and ending times down to the second, as well as the starting and ending locations. It was assumed that observations with identical starting and ending date-times and stations, despite having different rider IDs, were potentially erroneous duplicates.
:::

::: {.tableScroller .p-2}
```{r}
#| label: tbl-duplicates
#| tbl-cap: Duplicates Table
#| eval: false
#| include: false

# Not using the tabler function for this one. Might figure out a way later
# but just a lot of customization not used in other tables.
gtDupes <- dupeTable |>
dplyr::group_by(started_at) |>
gt::gt(
rowname_col = "row",
groupname_col = "started_at",
row_group_as_column = TRUE
) |>
gt::tab_style(
style = list(
gt::cell_text(weight = "bold", align = "center"),
gt::cell_borders(sides = c("bottom"))
),
locations = gt::cells_column_labels(gt::everything())
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = c("left", "right"), color = "transparent"),
gt::cell_text(align = "center", v_align = "middle")
),
locations = gt::cells_body(gt::everything())
) |>
gt::data_color(
columns = start_station_name,
target_columns = gt::everything(),
method = "auto",
palette = "basetheme::brutal"
) |>
gt::tab_header(title = "A view of duplicated observations", subtitle = "Grouping follows the starting date-time value") |>
gt::tab_options(
heading.title.font.weight = "bolder",
heading.subtitle.font.weight = "lighter",
heading.align = "center",
table.background.color = "transparent",
table.font.color = "SeaShell",
table.font.size = gt::pct(75),
)

gtDupes
```
:::

::: {.p-2 .mt-2}
Although the cause of such duplication errors is unknown, it could be assumed that one person checked out multiple bikes simultaneously. In that scenario, each bike would be assigned a unique **ride_id**. However, this occurrence was relatively rare, happening only **18** times over the course of a year. Since there is only one duplicate for each instance, it raises concerns and warrants further investigation. It is possible that trips could be grouped where one person pays for another rider's fare. However, if that were the case, it raises the question of why there is always precisely one duplicate.

In @tbl-duplicates, duplicate observations are listed and grouped by color for visual clarity. In contrast, @tbl-unduplicated presents the data after removing the extra copy of each duplicate observation while preserving the unique observations. Of the duplicates identified, each had one extra copy. It was noted that the number of rows in the duplicates table is 36. Each duplicated observation has one duplicate, where **n** (the count) is always 2. Therefore, the expected number of observations to be removed was 18. A complication arose in determining how to remove not all observations but only the extra duplicate observation from each group.
:::

::: {.p-2 .tableScroller}
```{r}
#| label: tbl-unduplicated
#| tbl-cap: Un-duplicated Table
#| eval: false
#| include: false

gt_undupes <- undupedTable |>
dplyr::collect() |>
dplyr::group_by(started_at) |>
gt::gt(
rowname_col = "row",
groupname_col = "started_at",
row_group_as_column = TRUE
) |>
gt::fmt_number(decimals = 0) |>

gt::tab_style(
style = list(
gt::cell_text(weight = "bold", align = "center"),
gt::cell_borders(sides = c("bottom"))
),
locations = gt::cells_column_labels(gt::everything())
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = c("left", "right")),
gt::cell_text(align = "center", v_align = "middle")
),
locations = gt::cells_body(gt::everything())
) |>
gt::data_color(
columns = start_station_name,
target_columns = gt::everything(),
method = "auto",
palette = "basetheme::brutal"
) |>
gt::tab_header(title = "After duplicates were removed", subtitle = "Same grouping") |>
gt::tab_options(
heading.title.font.weight = "bolder",
heading.subtitle.font.weight = "lighter",
heading.align = "center",
table.background.color = "transparent",
table.font.color = "SeaShell",
table.font.size = gt::pct(75)
)

gt_undupes
```
:::

::: {.p-2 .mt-2}
To ensure the accurate removal of duplicates, the count of distinct n-values (representing the number of occurrences) for the un-duplicated table was computed, confirming the expected 18 unique instances. Subsequently, the total number of observations in the dataset was recorded, initially standing at 4,331,707. After removing the identified duplicate observations, the correct count of observations was 4,331,689. In summary, 18 additional observations were successfully removed, aligning with the expected number of duplicates identified earlier. These steps are documented in @tbl-observationHistory for reference.

By carefully analyzing the count of distinct n-values and the total observation count before and after reduplication, it was ensured that only the precise number of duplicate observations was removed, preserving the integrity of the unique data while eliminating the identified duplicates. This meticulous approach to data cleaning is crucial for maintaining data quality and reliability throughout the analysis process.
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas2" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: 1.5rem; color: #00BFA5;"></i>
```
:::
:::

## Outliers

::: {#offcanvas33 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Filter Database
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: filtering db
#| code-summary: First, if you happen to be re-using this code - this is so you do not have to re-download or re-filter after making further adjustments.

#tblPath <- "db/data.db"
#dupelessPath <- "db/dupeless.db"
tblPath_fltrd <- "db/data_fltrd.db"

if (exists("dbconn") == FALSE && dir.exists("db") == TRUE) {
    dbconn <- DBI::dbConnect(
        duckdb::duckdb(),
        dbdir = tblPath,
        read_only = FALSE)
}

if (duckdb::dbExistsTable(dbconn,
                          "tblPath_fltrd") == FALSE) {
    source("Scripts/filterDatabase.R")
    filterDatabase()
}


```
:::
:::
:::

Observations deemed erroneous or irrelevant for identifying usage trends among members and casual users were filtered out. Keeping track of these errors is a good practice, as they might provide insights into the differences in how members and casuals utilize the service.

Trips with negative duration were flagged as errors and removed. Additionally, trips lasting less than a minute but greater than zero were noted and removed, as they could potentially skew the derived statistics. These extremely short trips might be attributed to users briefly trying out the service before committing or quickly realizing their dissatisfaction with it. While some observations seemed nonsensical, most of the data was retained.

Consistent with the previous approach, an **if-else** decision was employed to facilitate testing. An external database filtering script was utilized to streamline the code within the main Quarto document. The resulting filtered data served as the foundation for subsequent analysis and table generation.

::: {.p-2 .flex-code}
```{r}
#| label: countFiltered
#| code-summary: "To get a count of the new total observations after filtering."
#| tidy: formatR

count_filtered <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(ride_id) |>
dplyr::distinct() |>
dplyr::count() |>
dplyr::collect() |>
as.integer()

```
:::

::: {.p-3 .flex-code max-width="auto"}
```{r}
#| label: tbl-observationHistory
#| tbl-cap: Observation Processing History
#| tidy: formatR

# To see the history of obs in our dataset.
summaryProcessTable <- tidyr::tribble(
~ "Observations",
~ "Counts",
"Original   ",
original_nobs,
"Complete Observations   ",
count_incorrectDists,
"Duplicates   ",
(count_incorrectDists - count_correctDists),
"Filtered     ",
(count_correctDists - count_filtered),
"Total Corrected   ",
count_filtered
) |>
gt::gt(rownames_to_stub = FALSE) |>
gt::tab_header(title = "Tallying Observations") |>
gt::tab_footnote(
footnote = gt::md("Row counts throughout the cleaning steps."),
locations = gt::cells_column_labels(columns = Counts)
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = "bottom"),
gt::cell_text(
align = "left",
stretch = "semi-expanded",
whitespace = "break-spaces"
)
),
locations = gt::cells_body(gt::everything())
) |>
gt::tab_style(
gt::cell_text(
align = "center",
stretch = "semi-expanded",
whitespace = "break-spaces"
),
locations = list(
gt::cells_title(groups = c("title", "subtitle")),
gt::cells_column_labels(gt::everything())
)
) |>
gt::fmt_number(decimals = 0) |>
gt::tab_options(
column_labels.font.weight = "bold",
table.background.color = "transparent",
table.font.color = "SeaShell",
row.striping.background_color = "gray10",
row.striping.include_table_body = TRUE
)

summaryProcessTable
```
:::

::: {.d-flex max-width="auto"}
::: {.p .note .note-primary}
::: {#filterScript .flex-code}
```{r}
#| label: filterScript
#| code-summary: This would execute if the if-else conditions were met to filter the db/data.db database table
#| file: "Scripts/filterDatabase.R"
#| eval: false
```
:::
:::
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas33" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: 1.5em; color: #00BFA5;"></i>
```
:::
:::

# Exploratory Analysis

## Contingency Tables

Contingency tables were created to gain quick insights into the data through a methodical, albeit simple, approach that facilitates understanding the bigger picture. Many of these tables are utilized in the tab-set section while some required further customization in the following section.

::: {.d-flex .justify-content-center .mb-3}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas10" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: .75em; color: #00BFA5;"></i>
```
:::
:::

::: {#offcanvas10 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Frequency Tables (other code)
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: frequencyWrites_totals
#| code-summary: First, write the totals frequency tables to database.

# For the membership frequency
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual) |>
    dplyr::group_by(member_casual) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_member.db",
                         overwrite = TRUE)

# For the rideable types.
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(rideable_type) |>
    dplyr::group_by(rideable_type) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_rTypes.db",
                         overwrite = TRUE)

# For the miles
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(miles) |>
    dplyr::collect() |>
    dplyr::mutate(miles = dplyr::case_when(
        miles >= 1 ~ round(miles,
                           digits = 0),
        miles < 1 ~ round(signif(miles, 3),
                          digits = 1)
    )) |>
    dplyr::group_by(miles) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(miles) |>
    duckdb::dbWriteTable(
        conn = dbconn,
        name = "db/freq_miles.db",
        overwrite = TRUE)

# For the mph
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(mph) |>
    dplyr::mutate(mph = round(mph, digits = 0)) |>
    dplyr::group_by(mph) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    dplyr::arrange(mph) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_mph.db",
                         overwrite = TRUE)

# For the days of the week
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(started_at) |>
    dplyr::mutate(wkday = lubridate::wday(started_at)) |>
    dplyr::group_by(wkday) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(wkday) |>
    dplyr::collect() |>
    dplyr::mutate(wkday = c("Sun",
                            "Mon",
                            "Tue",
                            "Wed",
                            "Thu",
                            "Fri",
                            "Sat"),
                  wkday = forcats::as_factor(wkday),
                  wkday = forcats::fct_inorder(wkday)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_wkDay.db",
                         overwrite = TRUE)

# For the months.
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(started_at) |>
    dplyr::mutate(months = lubridate::month(started_at,
                                            label = FALSE,
                                            abbr = TRUE
                                            )) |>
    dplyr::group_by(months) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    dplyr::arrange(months) |>
    dplyr::mutate(months = c(month.abb),
                  months = forcats::as_factor(months),
                  months = forcats::fct_inorder(months)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_month.db",
                         overwrite = TRUE)

# For the trip times.
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::mutate(trip_time = round(trip_time,
                                    digits = 0)) |>
    dplyr::group_by(trip_time) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(trip_time) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_tripTime.db",
                         overwrite = TRUE)

# For the start station names
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(start_station_name) |>
    dplyr::group_by(start_station_name) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(start_station_name) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_startNames.db",
                         overwrite = TRUE)


# For the station name pairs.
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(start_station_name,
                  end_station_name) |>
    dplyr::group_by(start_station_name,
                    end_station_name) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(start_station_name) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_pairStations.db",
                         overwrite = TRUE)

# for the hours
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(started_at) |>
    dplyr::mutate("hour" = lubridate::hour(started_at)) |>
    dplyr::group_by(hour) |>
    dplyr::summarise("Total_Riders" = dplyr::n()) |>
    dplyr::arrange(hour) |>
    dplyr::collect() |>
    dplyr::mutate("hour" = hms::hms(hours = hour),
                  "hour" = format(strptime(hour, format = "%H"), "%r"),
                  "index" = seq(1:24)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freq_hours.db",
                         overwrite = TRUE)

```

```{r}
#| label: frequencyWrites_comparisons
#| code-summary: Then, write all of the frequency comparison tables to the database.

# For the rideable type comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  rideable_type) |>
    dplyr::group_by(rideable_type,
                    member_casual) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_rType.db",
                         overwrite = TRUE)

# For the miles comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  miles) |>
    dplyr::collect() |>
    dplyr::mutate(miles = dplyr::case_when(
        miles >= 1 ~ round(miles,
                           digits = 0),
        miles < 1 ~ round(signif(miles, 3),
                          digits = 1)
    )) |>
    dplyr::group_by(miles,
                    member_casual) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(miles) |>
    duckdb::dbWriteTable(
        conn = dbconn,
        name = "db/freqCompare_miles.db",
        overwrite = TRUE)

# For the mph comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(mph,
                  member_casual) |>
    dplyr::mutate(mph = round(mph, digits = 0)) |>
    dplyr::group_by(member_casual,
                    mph) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    dplyr::arrange(mph) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_mph.db",
                         overwrite = TRUE)

# For the week days comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  started_at) |>
    dplyr::mutate(wkday = lubridate::wday(started_at)) |>
    dplyr::group_by(member_casual,
                    wkday) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(wkday) |>
    dplyr::collect() |>
    dplyr::mutate(wkday = c("Sun",
                            "Mon",
                            "Tue",
                            "Wed",
                            "Thu",
                            "Fri",
                            "Sat"),
                  wkday = forcats::as_factor(wkday),
                  wkday = forcats::fct_inorder(wkday)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_wkDay.db",
                         overwrite = TRUE)

# For the months comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  started_at) |>
    dplyr::mutate(months = lubridate::month(started_at,
                                            label = FALSE,
                                            abbr = TRUE)) |>
    dplyr::group_by(member_casual,
                    months) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::collect() |>
    dplyr::arrange(months) |>
    dplyr::mutate(months = c(month.abb),
                  months = forcats::as_factor(months),
                  months = forcats::fct_inorder(months)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_month.db",
                         overwrite = TRUE)


# For the trip times comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  trip_time) |>
    dplyr::mutate(trip_time = round(trip_time,
                                    digits = 0)) |>
    dplyr::group_by(member_casual,
                    trip_time) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(trip_time) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_tripTime.db",
                         overwrite = TRUE)

# For the start station names comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  start_station_name) |>
    dplyr::group_by(member_casual,
                    start_station_name) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(start_station_name) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_startNames.db",
                         overwrite = TRUE)

# For the station name pairs comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(member_casual,
                  start_station_name,
                  end_station_name) |>
    dplyr::group_by(start_station_name,
                    end_station_name,
                    member_casual) |>
    dplyr::summarize(n = dplyr::n()) |>
    dplyr::arrange(start_station_name,
                   end_station_name) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_pairStations.db",
                         overwrite = TRUE)
# For the hours comparison
dplyr::tbl(dbconn,
           tblPath_fltrd) |>
    dplyr::select(started_at, member_casual) |>
    dplyr::mutate("hour" = lubridate::hour(started_at)) |>
    dplyr::group_by(member_casual, hour) |>
    dplyr::summarize("Total_Riders" = dplyr::n()) |>
    dplyr::arrange(hour, member_casual) |>
    dplyr::collect() |>
    dplyr::mutate("hour" = hms::hms(hours = hour),
                  "hour" = format(strptime(hour, format = "%H"), "%r"),
                  "index" = seq(1:24)) |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = "db/freqCompare_hours.db",
                         overwrite = TRUE)
```
:::
:::
:::


## Membership

::: {.callout-important icon="false"}
<!-- -->

-   @tbl-memberTotals displays the total trip count for annual members and casual riders.

-   The remaining tabs in this section provide total counts as well as group-wise counts based on membership status.
:::

### Counting Members

```{r}
#| label: tbl-memberTotals
#| tbl-cap: Total Member Frequency

dplyr::tbl(dbconn, "db/freq_member.db") |>
tabler (
title = "Membership", 
source_note = gt::md("**Source**: `db/freq_member.db`"),
footnote = gt::md("The recorded observations."),
location = n
) |>
gt::cols_label(n = "Trips", member_casual = " ")
```

```{r}
#| label: fig-totalmemberFrequency
#| fig-cap: Total Member Frequency


gplot <- dplyr::tbl(dbconn, "db/freq_member.db") |>
plotter(
x_col = member_casual, 
y_col = n, 
geomType = "column", 
title = "Membership Types", 
x_label = "Rider Types", 
y_label = "Trips")

gplot
```


## Cycle Types

::: {.callout-important icon="false"}
<!-- -->

-   @tbl-ctypeTotals and @fig-ctypeTotals compare the total trips taken on conventional and electric bicycles, clearly showing that electric bikes are not utilized as much as conventional ones.

-   @tbl-ctypeCompare and @fig-ctypeCompare further break down the trip frequency by membership status, revealing a substantial disparity not only in the overall trip count between annual members and casual riders but also within the annual member group itself. While casual riders exhibit a small difference in trip counts between conventional and electric bikes, this difference is more pronounced among annual members.

-   With $p < 0.05$ in @tbl-chiTypes, there appears to be a strong association between membership status (annual member or casual rider) and the type of bicycle preferred, suggesting that these factors are not independent.
:::

### Counting Bicycles

```{r}
#| label: tbl-ctypeTotals
#| tbl-cap: Cycle Type Total Frequency

dplyr::tbl(dbconn, "db/freq_rTypes.db") |>
tabler( 
title = "Bicycles", 
footnote = gt::md("The recorded observations."),
location = n
)

```

```{r}
#| label: fig-ctypeTotals
#| fig-cap: Cycle Type Total Frequency 

gplot <- dplyr::tbl(dbconn, "db/freq_rTypes.db") |>
plotter(
x_col = rideable_type, 
y_col = n, 
geomType = "column", 
title = "Bicycle Type", 
x_label = "Type", 
y_label = "Trips")

gplot
```

### Bicycle by Membership

```{r}
#| label: tbl-ctypeCompare
#| tbl-cap: Cycle Type Group Frequency

dplyr::tbl(dbconn, "db/freqCompare_rType.db") |>
dplyr::arrange(rideable_type, member_casual) |>
dplyr::collect() |>
tabler(
title = "Bicycle Type to Membership", 
groupName = "rideable_type", 
footnote = "The recorded observations.", 
location = n,
source_note = gt::md("**Source**: `db/freqCompare_rType`"),
label_n = "n",
label_member = " "
) 
```

```{r}
#| label: fig-ctypeCompare
#| fig-cap: Cycle Type Group Frequency

source("Scripts/plotter.R")
gplot <- dplyr::tbl(dbconn, "db/freqCompare_rType.db") |>
plotter(
title = "Bicycle Groups",
x_label = "Type",
y_label = "Trips",
x_col = rideable_type, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
is_colGroup = TRUE,
color_col = "black",
colPosition = "dodge",
colGroup_palette = "Paired"
)

gplot
```

### Testing the association between membership and bicycle type

```{r}
#| label: tbl-chiTypes

dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(rideable_type, member_casual) |>
dplyr::collect() |>
tabler(
title = "Chi-Square: Bicycles & Rider Type",
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
label = list(
rideable_type = "Bicycle Type", 
member_casual = "Membership"),
by = member_casual,
isSummary = TRUE
)

```

```{r}
#| label: query cycle type with weights
#| code-summary: "Return aggregated distinct rows utilize weights. Aggregated rows allows the models to run faster and requires less memory, it seems."

source("Scripts/transformData.R")

weighted_data <- transformData(
dbconn,
tblPath_fltrd,
select_cols = c("rideable_type", "member_casual"),
group_cols = c("rideable_type", "member_casual"),
#pred_col = "rideable_type",
binary_col = "member_casual",
zero_val = "casual",
one_val = "member",
doWeights = TRUE
)

```

```{r}
#| label: cycle type modeling
#| code-summary: "Predicting the log-odds of being a member versus being a casual user based on the particular bicycle type."

# 23% less likely for members to ride an electric bike  
model <- weighted_data |>
glm(formula = member_casual ~ rideable_type, weights = n, family = binomial)
```

```{r}
#| label: tbl-ctypeModel

regression_tbl <- model |>
gtsummary::tbl_regression(
label = list(rideable_type = "Cycle Type"), conf.int = FALSE, exponentiate = TRUE)

regression_tbl |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Cycle Type to Membership"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)

```


## Duration

::: {.callout-important icon="false"}
<!-- -->

-   As evident from @tbl-triptimeTotals2 and @fig-triptimeTotals2, the duration of most trips falls within the range of 5 to 15 minutes.

-   The group comparison in @tbl-triptimeCompare2 and @fig-triptimeCompare2 reveals that both casual riders and members largely follow the overall pattern observed in the totals. However, beyond the 42-minute mark, the count of casual riders exceeds that of members. While members ride more frequently overall, casual riders are more likely to undertake longer trips.

-   Given that $\beta_1 < 0$ (@tbl-logTimes2), the results indicate that members are more likely to take shorter trips in terms of duration compared to casual riders.
:::

### Counting Duration

::: tableScroller
```{r}
#| label: tbl-triptimeTotals
#| tbl-cap: Trip-Time Totals


dplyr::tbl(dbconn, "db/freq_tripTime.db") |>
dplyr::arrange(trip_time) |>
tabler( 
title = "Duration", 
footnote = gt::md("The recorded observations."),
location = n
) |>
gt::cols_align(columns = "trip_time", align = "left")
```
:::

```{r}
#| label: fig-triptimeTotals
#| fig-cap: Trip-Time Totals
#| fig-dpi: 600
#| column: body-outset-right

gplot <- dplyr::tbl(dbconn, "db/freq_tripTime.db") |>
dplyr::filter(trip_time <= 100) |>
plotter(
x_col = trip_time, 
y_col = n,
geomType = "column", 
title = "Duration", 
x_label = "Minutes", 
y_label = "Overall Trips",
color_col = "black") 

gplot
```

### Duration by Membership

::: tableScroller
```{r}
#| label: tbl-triptimeCompare
#| tbl-cap: Trip Time Comparison


dplyr::tbl(dbconn, "db/freqCompare_tripTime.db") |>
dplyr::collect() |>
dplyr::arrange(trip_time, member_casual) |>
tabler(
title = "Duration Compare",
source_note = gt::md("**Source:** `db/freqCompare_tripTime.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "trip_time",
label_n = "n",
label_member = " "
)

```
:::

```{r}
#| label: fig-triptimeCompare
#| fig-cap: Trip-Time Group Frequency
#| fig-dpi: 600
#| column: body-outset-right

gplot <- dplyr::tbl(dbconn, "db/freqCompare_tripTime.db") |>
dplyr::arrange(trip_time, member_casual) |>
dplyr::filter(trip_time <= 100) |>
dplyr::collect() |>
plotter(
title = "Duration Groups",
x_label = "Minutes",
y_label = "Trips",
x_col = trip_time, 
y_col = n, 
group_col = member_casual,
geomType = "column",
is_colGroup = TRUE,
colPosition = ggplot2::position_stack(reverse = TRUE),
color_col = "black"
)

gplot
```

### Predicting with Duration?

```{r}
#| label: fig-durationModeling
#| fig-dpi: 600
#| column: body-outset-right

# The basic query for running stats on the various parameters. This version returns aggregated distinct rows for running models that utilize weights. Aggregated rows allows the models to run faster and requires less memory, it seems.

dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(trip_time, member_casual) |>
dplyr::mutate(trip_time = round(trip_time, digits = 0)) |>
dplyr::collect() |>
duckdb::dbWriteTable(
conn = dbconn,
name = "db/rounded_trip_time.db",
overwrite = TRUE)

source("Scripts/transformData.R")

weighted_data <- transformData(
dbconn, 
"db/rounded_trip_time.db", 
select_cols = c("trip_time", "member_casual"), 
group_cols = c("trip_time", "member_casual"), 
binary_col = "member_casual", 
ntile_col = "ntile_col", 
pred_col = "trip_time", 
zero_val = "casual", 
one_val = "member",
qtile_levels = c(
"[1 : 6]", "(6 : 10]", "(10 : 16]", "(16 : 475]"),
doWeights = TRUE,
doQuantile = TRUE)

expanded_data <- weighted_data |>
tidyr::uncount(n, .remove = FALSE) |>
dplyr::select(trip_time, member_casual)

model <- weighted_data |> 
glm(
formula = member_casual ~ ntile_col, 
weights = n, 
family = binomial)

regression_tbl <- model |>
gtsummary::tbl_regression(
label = list(ntile_col = "Duration Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE)

regression_tbl |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Duration & Rider Type"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)
```

```{r}
#| label: axis breaks for casuals' duration
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "casual", trip_time <= 100) |>
calcBreaks()
```

```{r}
#| label: fig-cDurationHistogram
#| fig-cap: "Casuals Duration Histogram"
#| fig-dpi: 600
#| column: body-outset-right

# histogram IQR viz for the duration metric
#gplot <- duration_factored |>
gplot <- expanded_data |>
dplyr::filter(member_casual == "casual") |>
dplyr::select(trip_time) |>
plotter(
title = "Duration - Casuals",
x_label = "Duration (minutes)",
y_label = "Trips",
x_col = trip_time, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(0, 100),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot

```

```{r}
#| label: axis breaks for members' duration
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "member", trip_time <= 100) |>
calcBreaks()
```

```{r}
#| label: fig-mDurationHistogram
#| fig-dpi: 600
#| column: body-outset-right

# histogram IQR viz for the duration metric
gplot <- expanded_data |>
dplyr::filter(member_casual == "member") |>
dplyr::select(trip_time) |>
plotter(
title = "Duration - Members",
x_label = "Duration (minutes)",
y_label = "Trips",
x_col = trip_time, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(0, 100),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot

```

68.26% of the data points are located between -1 and +1 standard deviations (34.13% in either direction). 95.44% of the data points are located between -2 and +2 standard deviations (47.72% in either direction). 99.72% of the data points are located between -3 and +3 standard deviations (49.86% in either direction)

```{r}
#| label: transformDuration

source("Scripts/transformData.R")

unrounded_data <- transformData(
dbconn, 
tblPath_fltrd, 
select_cols = c("trip_time", "member_casual"), 
binary_col = "member_casual", 
zero_val = "casual", 
one_val = "member"
)
```

```{r}
#| label: fig-durationDensity
#| fig-dpi: 600
#| column: body-outset-right

source("Scripts/plotter.R")

# density viz for the duration metric
gplot <- 
unrounded_data |>
plotter(
title = "Trip Duration Group Density",
x_label = paste0("Duration", "\n", "(minutes)"),
y_label = "Trips",
x_col = trip_time, 
#y_col = n,
group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
isDensity = TRUE,
#isHistogram = TRUE,
is_colGroup = TRUE,
limits = c(0, 100),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 1,
density_color = "gray",
density_fill = "transparent",
#alpha = 0.75,
#vline_color = "lightyellow",
#vline_size = 0.5,
density_alpha = 0.6,
)

gplot
```

```{r}
#| label: tbl-durationSummary

source("Scripts/tabler.R")

unrounded_data |>
gtsummary::tbl_summary(
by = member_casual,
type = trip_time ~ "continuous2",
label = list(trip_time ~ "Duration (minutes)"),
digits = list(
trip_time ~ c(2, 2)),
statistic = 
gtsummary::all_continuous() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
gtsummary::italicize_levels() |>
tabler(
title = gt::md("Summary Statistics: <br> Duration - Membership"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE,
)

```

```{r}
#| label: fig-rocDuration
#| fig-dpi: 600
#| column: body-outset-right

source("Scripts/plotter.R")

# Generate ROC curve
roc_duration <- pROC::roc(
unrounded_data$member_casual, unrounded_data$trip_time, levels = c("casual", "member"))

# Find the area under the curve value
auc_duration <- round(pROC::auc(roc_duration), 4)

gplot <- roc_duration |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0("ROC Curve for Duration", " (AUC = ", auc_duration, ")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red")

# false positive rate = x-axis; true positive rate = y-axis
gplot
```


## Month

::: {.callout-important icon="false"}
<!-- -->

-   Examining the monthly totals in @tbl-monthTotals and @fig-monthTotals, it is evident that warmer months coincide with higher overall trip frequency.

-   The comparison between subscriber and casual rider groups in @tbl-monthCompare and @fig-monthCompare reveals that both groups exhibit seasonal variations in trip frequency. However, the fluctuations appear to be less pronounced for subscribers compared to casual riders. The disparity in the extent of frequency changes is more apparent when contrasting winter and summer months between the two groups.

-   With $p < 0.05$, (@tbl-chiMonths), there is strong evidence to suggest that membership status is associated with an individual's usage of the service during a particular month or season.
:::

### Counting Months

```{r}
#| label: tbl-monthTotals
#| tbl-cap: Month Total Frequency

dplyr::tbl(dbconn, "db/freq_month.db") |>
tabler(
title = "Months",
source_note = gt::md("**Source:** `db/freq_month.db`"),
footnote = "The recorded observations.",
location = n
)

```

```{r}
#| label: fig-monthTotals
#| fig-cap: Month Total Frequency

gplot <- dplyr::tbl(dbconn, "db/freq_month.db") |>
plotter(
x_col = months, 
y_col = n, 
geomType = "column", 
title = "Months", 
x_label = "Months", 
y_label = "Trips")

gplot

```

### Month by Membership

```{r}
#| label: tbl-monthCompare
#| tbl-cap: Month Group Frequency

dplyr::tbl(dbconn, "db/freqCompare_month.db") |>
dplyr::arrange(months, member_casual) |>
dplyr::collect() |>
tabler(
title = "Months",
source_note = gt::md("**Source:** `db/freqCompare_month.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "months",
label_n = "n",
label_member = " "
)

```

```{r}
#| label: fig-monthCompare
#| fig-cap: Month Group Frequency

gplot <- dplyr::tbl(dbconn, "db/freqCompare_month.db") |>
plotter(
title = "Month Groups",
x_label = "Months",
y_label = "Trips",
x_col = months, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot

```

### Testing the association between membership and month

```{r}
#| label: tbl-chiMonths

# For finding chi-square p-value in a nicely formatted table
month_tbl <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(member_casual, started_at) |>
dplyr::arrange(started_at) |>
dplyr::mutate(months = lubridate::month(started_at, label = TRUE, abbr = TRUE)) |>
dplyr::collect() |>
dplyr::mutate(
months = forcats::as_factor(months))

month_tbl |>
dplyr::select(member_casual, months) |>
tabler(
title = "Chi-Square: Month & Rider Type",
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
label = list(
months = "Month"),
by = member_casual,
isSummary = TRUE
)

```

```{r}
#| label: accurate simple month density query and plot 

compare_months <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
member_casual = factor(member_casual, levels = c("casual", "member")))


gplot <- compare_months |>
plotter(
title = "Month Group Density",
x_label = paste0("Month"),
x_col = started_at, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 month",
date_labels = "%b")

gplot

```


## Day

::: {.callout-important icon="false"}
<!-- -->

-   @tbl-wkdayTotals and @fig-wkdayTotals indicate a higher total number of trips taken between Tuesday and Saturday compared to Sunday and Monday.

-   The trend becomes more intricate in @tbl-wkdayCompare and @fig-wkdayCompare, which compare trip frequencies across weekdays for annual members and casual riders separately. Casual riders exhibit an increase in trips towards the weekend, with a dip on weekdays when annual members are more active. Conversely, when annual members are less active, casual riders tend to be more active.

-   As $p < 0.05$ in @tbl-chiDays, there appears to be a significant association between membership status and the likelihood of using the service on a particular day of the week, suggesting that these factors are not independent.
:::

### Counting Days

```{r}
#| label: tbl-wkdayTotals
#| tbl-cap: Weekday Total Frequency

dplyr::tbl(dbconn, "db/freq_wkday.db") |>
tabler( 
title = "Days", 
footnote = gt::md("The recorded observations."),
location = n
)

```

```{r}
#| label: fig-wkdayTotals
#| fig-cap: Weekday Totals Frequency

gplot <- dplyr::tbl(dbconn, "db/freq_wkday.db") |>
plotter(
x_col = wkday, 
y_col = n, 
geomType = "column", 
title = "Days for all Riders", 
x_label = "Days of the Week", 
y_label = "Trips") +
# To zoom the data a bit
ggplot2::coord_cartesian(ylim = c(4.5 * 10^5, NA))

gplot

```

### Day by Membership

```{r}
#| label: tbl-wkdayCompare
#| tbl-cap: Weekday Group Frequency


dplyr::tbl(dbconn, "db/freqCompare_wkday.db") |>
dplyr::collect() |>
dplyr::arrange(wkday, member_casual) |>
tabler(
title = "Weekday Compare",
source_note = gt::md("**Source:** `db/freqCompare_wkday.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "wkday",
label_n = "n",
label_member = " "
)

```

```{r}
#| label: fig-wkdayCompare
#| fig-cap: Weekday Group Frequency


gplot <- dplyr::tbl(dbconn, "db/freqCompare_wkday.db") |>
plotter(
title = "Day Groups",
x_label = "Days",
y_label = "Trips",
x_col = wkday, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot

```

### Testing the association between day and membership

```{r}
#| label: accurate wkday query and density plot

compare_wkdays <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
wkdays = lubridate::wday(started_at, week_start = 7),
member_casual = factor(member_casual, levels = c("casual", "member")))

compare_wkdays$started_at <- update(
compare_wkdays$started_at, 
year = 2024, 
month = 9, 
day = compare_wkdays$wkdays)


gplot <- compare_wkdays |>
plotter(
title = "Weekday Group Density",
x_label = paste0("Day"),
#y_label = "Trips",
x_col = started_at, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 day",
date_labels = "%a")

gplot
```

```{r}
#| label: accurate day of week chi-square query and table 

compare_wkdays |>
dplyr::select(member_casual, started_at) |>
dplyr::arrange(started_at) |>
dplyr::mutate(
wday_abb = lubridate::wday(started_at, label = TRUE, abbr = TRUE)) |>
tabler(
title = "Chi-Square: Day & Rider Type",
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
label = list(wday_abb = "Day"),
by = member_casual,
isSummary = TRUE
)

```


## Hour

::: {.callout-important icon="false"}
<!-- -->

-   The overall trend follows the typical work day cycle where one would expect to see with spikes in the mornings and evenings. See @tbl-hourTotals and @fig-hourTotals.

-   There is a noted discrepancy between member and casual use during peak commute hours. Members have more notable spike during morning commute hours than casuals, which appears more flat throughout the day. See @tbl-hourCompare and @fig-hourCompare.

-   Given, $p < 0.05$, members and casuals tend to take trips at different hours of the day. @tbl-chiHours
:::


```{r}
#| label: write hod to duckdb
#| code-summary: Write hod.db to the database.
#| tidy: true
  
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
started_at_time = update(started_at, year = 2023, month = 1, day = 1),
hr = stringr::str_to_lower(
format(lubridate::round_date(started_at, unit = "hour"), "%I %p")),
hrMin = stringr::str_to_lower(
format(lubridate::round_date(started_at, unit = "minute"), "%I:%M %p")),
hrminSec = stringr::str_to_lower(
format(lubridate::round_date(started_at, unit = "second"), "%r"))
) |>
dplyr::select(member_casual:hrminSec) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/hod.db",
overwrite = TRUE)

```


```{r}
#| label: tbl-dbHours
#| code-summary: Output of hod.db.
#| tidy: formatR

dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::collect() |>
head()
kableExtra::kable()
```


```{r}
#| label: hod_n
#| code-summary: Transform hod.db and write as hod_n.db to the databse.

dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::collect() |>
dplyr::add_count(started_at_time, member_casual) |>
dplyr::arrange(started_at_time, hrminSec, member_casual) |>
dplyr::distinct() |>
duckdb::dbWriteTable(conn = dbconn, 
name = "db/hod_n.db", 
overwrite = TRUE)
```


```{r}
#| label: tbl-nHours
#| code-summary: Display hod_n.db.
#| tidy: formatR

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::collect() |>
head()
kableExtra::kable()
```

::: tableScroller
```{r}
#| label: tbl-hourTotals
#| tbl-cap: Total freqeuncy by the hour of day

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr) |>
dplyr::summarize(n = sum(n)) |>
dplyr::collect() |>
tabler( 
title = "Hours", 
footnote = gt::md("The recorded observations."), 
location = n)
```
:::

```{r}
#| label: fig-hourTotals
#| fig-cap: Total frequency by hour of day.
#| fig-dpi: 600
#| column: body-outset-right

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr) |>
dplyr::summarize(n = sum(n)) |>
dplyr::collect() |>
plotter(
x_col = hr, 
y_col = n,
geomType = "column", 
title = "Hour of Day", 
x_label = "Hour", 
y_label = "Trips",
) +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))
```



::: tableScroller
```{r}
#| label: tbl-hourMembership
#| tbl-cap: Frequencies for membership by hour.

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::collect() |>
tabler(
title = "Hours Membership Groups",
source_note = gt::md("**Source:** `db/fltrd_db.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "member_casual",
label_n = "n",
label_member = " "
)
```
:::


```{r}
#| label: fig-hourCompare
#| fig-cap: Grouped hour frequency
#| fig-dpi: 600
#| column: body-outset-right

gplot <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::collect() |>
plotter(
title = "Hour Groups",
x_label = "Hour of Day",
y_label = "Trips",
x_col = hr, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
) +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))

gplot
```



```{r}
#| label: fig-cHistogram
#| code-summary: Casual histogram plot with quartile ranges. 

source("Scripts/plotter.R")

qdf <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::select(started_at_time, member_casual, n, isMidnight) |>
dplyr::filter(
member_casual == "casual",
isMidnight != TRUE
) |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE)


quartiles <- quantile(qdf$started_at_time, probs = c(0.25, 0.5, 0.75))

gplot <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::select(started_at_time, member_casual, n, isMidnight) |>
dplyr::filter(
member_casual == "casual",
isMidnight != TRUE
) |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE) |>
plotter(
title = "Hours - Casuals",
x_label = "Hours (12-hour clock)",
y_label = "Trips",
x_col = started_at_time, 
geomType = "column", 
isHistogram = TRUE,
isTimeHist = TRUE,
date_breaks = "1 hour", 
date_labels = "%I %p", 
angle = 45,
color_col = "black",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles,
qformat = "%I:%M %p"
) 

gplot

```
```{r}
qdf |> dplyr::slice_head(n = 1)
qdf |> dplyr::slice_tail(n = 1)
```


```{r}
#| label: fig-mHistogram
#| code-summary: Member histogram plot with quartile ranges. 

source("Scripts/plotter.R")

qdf <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::select(started_at_time, member_casual, n) |>
dplyr::filter(member_casual == "member") |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE)

quartiles <- quantile(qdf$started_at_time, probs = c(0.25, 0.5, 0.75))

gplot <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::select(started_at_time, member_casual, n) |>
dplyr::filter(member_casual == "member") |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE) |>
plotter(
title = "Hours - Members",
x_label = "Hours (12-hour clock)",
y_label = "n",
x_col = started_at_time, 
geomType = "column", 
isHistogram = TRUE,
isTimeHist = TRUE,
date_breaks = "1 hour", 
date_labels = "%I %p", 
angle = 45,
color_col = "black",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles,
qformat = "%I:%M %p"
) 

gplot


```


```{r}
quantile(qdf$started_at_time)

qdf$started_at_time[[1]]
```


```{r}
#| label: fig-hourDensity
#| code-summary: Query, load, and plot the grouped densities from hod.db. 
#| fig-dpi: 600
#| column: body-outset-right

gplot <- 
dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::collect() |>
plotter(
title = "Hour Group Density",
x_label = paste0("Hours", "\n", "(12-hour clock)"),
x_col = started_at_time, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 hour",
date_labels = "%I %p",
)

gplot
```


```{r}
#| label: hoursWeightedQuantiles
#| code-summary: Query hod.db, transform and write weighted quartile data to hod_wq.db. 
#| tidy: formatR

transformData(
conn = dbconn,
path = "db/hod.db",
select_cols = c("started_at_time", "member_casual"),
group_cols = c("started_at_time", "member_casual"),
binary_col = "member_casual",
pred_col = "started_at_time",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c("Q1 (00:04 - 12:46]", "Q2 (12:46 - 15:58]", "Q3 (15:58 - 19:56]", "Q4 (19:56 - 23:58]"),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn, name = "db/hod_wq.db", overwrite = TRUE)
```


```{r}
#| label: tbl-hoursWTQ
#| code-summary: A kable output of the hour's weighted quantile db table.
#| tidy: formatR

dplyr::tbl(dbconn, "db/hod_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```


```{r}
#| label: modelHourQ
#| code-summary: Query hod_wq.db, process and create model R object for hour based on quartile range. 

model <- 
dplyr::tbl(dbconn, "db/hod_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```


```{r}
#| label: tbl-modelHourQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  

model |>
gtsummary::tbl_regression(
label = list(quartile = "Hour Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Hour & Rider Type"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)
```



```{r}
#| label: tbl-chiHours
#| tbl-cap: Chi-Squared for aggregated hours data to the level of rounded hours.
#| code-summary: Query hod_n, then process and display Chi-Squared statistical summary.

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE) |>
tabler(
title = "Chi-Square: Hour & Rider Type",
source_note = gt::md("**Source**: `db/hod_n.db`"),
label = list(hr = "Hour"),
by = member_casual,
isSummary = TRUE
)
```



## Distance

::: {.callout-important icon="false"}
<!-- -->

-   The distance of most observed trips in @tbl-milesTotals and @fig-milesTotals fall in between 0.3 to 3 miles.

-   The groups comparison seen in @tbl-milesCompare and @fig-milesCompare show the same pattern. The casual and member differ mainly in overall scale of trips taken between the 0.3 and 3 mile trip distances.

-   $\beta_1 < 0$, members are less likely to ride as distance traveled in a given trip increases. So, members tend to take shorter trips compared to casual users. @tbl-logMiles
:::


### Counting Distance

```{r}
#| label: tbl-milesTotals
#| tbl-cap: Miles Total Frequency

dplyr::tbl(dbconn, "db/freq_miles.db") |>
dplyr::arrange(miles) |>
dplyr::collect() |>
dplyr::mutate(
miles = forcats::as_factor(miles),
) |>
tabler( 
title = "Distance", 
footnote = gt::md("The recorded observations."),
location = n
)
```

```{r}
#| label: fig-milesTotals
#| fig-cap: Miles Total Frequency

miles_tbl <- dplyr::tbl(dbconn, "db/freq_miles.db") |>
dplyr::filter(miles <= 11) |>
dplyr::collect() |>
dplyr::mutate(
miles = forcats::as_factor(miles),
miles = forcats::fct_inorder(miles)
)


gplot <- miles_tbl |>
plotter(
x_col = miles, 
y_col = n,
geomType = "column", 
title = "Distance", 
x_label = "Miles", 
y_label = "Trips") 

gplot +
ggplot2::scale_x_discrete(
guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))
```

### Distance by Membership

```{r}
#| label: tbl-milesCompare
#| tbl-cap: Miles Group Frequency

miles_compTbl <- dplyr::tbl(dbconn, "db/freqCompare_miles.db") |>
dplyr::collect()

dir.create("tables")

miles_compTbl |> data.table::fwrite("tables\\mile_groups.csv")

miles_compTbl |>
tabler(
title = "Distance Groups",
source_note = gt::md("**Source:** `db/freqCompare_miles.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "miles",
label_n = "n",
label_member = " "
)
```

```{r}
#| label: fig-milesCompare
#| fig-cap: Miles Group Frequency

# For the miles group frequency membership comparison
milesCompare_tbl <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(member_casual, miles) |>
dplyr::collect() |>
dplyr::mutate(miles = dplyr::case_when(
miles >= 1 ~ round(miles, digits = 0),
miles < 1 ~ round(signif(miles, 3), digits = 1)
)) |>
dplyr::arrange(miles) |>
dplyr::filter(miles <= 11) |>
dplyr::mutate(
miles = forcats::as_factor(miles))
```

```{r}
#| label: compareMiles
#| code-summary: plot of miles

gplot <- milesCompare_tbl |>
dplyr::group_by(miles, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::ungroup() |>
plotter(
title = "Distance Groups (Aggregated)",
x_label = "Miles",
y_label = "Trips",
x_col = miles, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot
```

### Trip distance has weak predictive value on membership status

```{r}
#| label: distance weighted stats modeling
#| code-summary: "The basic query for running stats on the various parameters. This version returns aggregated distinct rows for running models that utilize weights. Aggregated rows allows the models to run faster and requires less memory, it seems."


dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(miles, member_casual) |>
dplyr::mutate(miles = round(miles, digits = 1)) |>
dplyr::collect() |>
duckdb::dbWriteTable(
conn = dbconn,
name = "db/rounded_miles.db",
overwrite = TRUE)


source("Scripts/transformData.R")


weighted_data <- transformData(
  conn = dbconn, 
  path = "db/rounded_miles.db", 
  select_cols = c("miles", "member_casual"), 
  group_cols = c("miles", "member_casual"), 
  binary_col = "member_casual", 
  ntile_col = "ntile_col", 
  pred_col = "miles", 
  zero_val = "casual", 
  one_val = "member",
  qtile_levels = c(
  "[0.10 : 0.60]", "(0.60 : 1.00]", "(1.00 : 1.80]", "(1.80 : 20.5]"),
  doQuantile = TRUE,
  doWeights = TRUE
)


expanded_data <- weighted_data |>
tidyr::uncount(n, .remove = FALSE) |>
dplyr::select(miles, member_casual)


model <- weighted_data |> 
glm(
formula = member_casual ~ ntile_col, 
weights = n, 
family = binomial)


regression_tbl <- model |>
gtsummary::tbl_regression(
label = list(ntile_col = "Mile Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE)


regression_tbl |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Distance & Rider Type"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)

# 
# members are about 2.1 times to fall into Q1 as casuals
# 11% less likely Q2 as Q1
# 61% less likely Q3 as Q1
# 78% less likely Q4 as Q1
# 

#     25%     ,   25%  ,    25%        25%
# 0.1<=x<=0.6, 0.6<x<=1, 1<x<=1.8, 1.8<x<=20.5

```

```{r}
#| label: axis breaks for casuals' distance 
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "casual", miles <= 10) |>
calcBreaks()

plotBreaks
```

```{r}

source("Scripts/plotter.R")

# histogram IQR viz for the distance metric
#gplot <- distance_factored |>
gplot <- expanded_data |>
#tidyr::uncount(n, .remove = FALSE) |>
#dplyr::select(miles, member_casual) |>
dplyr::filter(member_casual == "casual") |>
dplyr::select(miles) |>
plotter(
title = "Distance - Casuals",
x_label = "Distance (miles)",
y_label = "Trips",
x_col = miles, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(0, 10),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot

```

```{r}
#| label: axis breaks for members' distance 
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "member", miles <= 10) |>
calcBreaks()
```

```{r}

source("Scripts/plotter.R")

# histogram IQR viz for the distance metric
gplot <- expanded_data |>
dplyr::filter(member_casual == "member") |>
dplyr::select(miles) |>
plotter(
title = "Distance - Members",
x_label = "Distance (miles)",
y_label = "Trips",
x_col = miles, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(0, 10),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot
```

```{r}
#| label: axis breaks for all distance 
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(miles <= 10) |>
calcBreaks()
```

```{r}

source("Scripts/plotter.R")

# density viz for the miles metric
gplot <- expanded_data |>
plotter(
title = "Distance Group Density",
x_label = paste0("Distance", "\n", "(miles)"),
y_label = "Trips",
x_col = miles, 
#y_col = n,
group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
isDensity = TRUE,
#isHistogram = TRUE,
is_colGroup = TRUE,
limits = c(0, 10),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 1,
#density_color = "gray",
#density_fill = "transparent",
#alpha = 0.75,
#vline_color = "lightyellow",
#vline_size = 0.5,
density_alpha = 0.7
)

gplot
```

```{r}

expanded_data |>
gtsummary::tbl_summary(
by = member_casual,
type = miles ~ "continuous2",
label = list(miles ~ "Distance (miles)"),
digits = list(
miles ~ c(2, 2)),
statistic = 
gtsummary::all_continuous() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
gtsummary::italicize_levels() |>
tabler(
title = gt::md("Summary Statistics: <br> Distance - Membership"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE
)

```

```{r}
#| label: fig-rocMiles

# Generate ROC curve
roc_miles <- pROC::roc(
expanded_data$member_casual, expanded_data$miles, levels = c("casual", "member"))

# Find the area under the curve value
auc_miles <- round(pROC::auc(roc_miles), 4)

gplot <- roc_miles |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0(
"ROC Curve for Distance", 
" (AUC = ", 
auc_miles, 
")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red"
)

# false positive rate = x-axis; true positive rate = y-axis
gplot
```

## Speed

::: {.callout-important icon="false"}
<!-- -->

-   This information, derived from @tbl-mphTotals and @fig-mphTotals, indicates that most riders (both casual and member) travel at speeds between 2 and 12 mph. This range likely represents typical urban cycling speeds, accounting for factors like traffic, road conditions, and rider fitness.

-   The information, shown in @tbl-mphCompare and @fig-mphCompare, suggests that members tend to ride at higher speeds compared to casual riders

-   Applying the binary logistic regression model, where $\beta_1 > 0$, members tend to have a slightly higher estimated average speed for the duration of their trips compared to casuals. @tbl-logMph
:::

### Counting Speed

```{r}
#| label: tbl-mphTotals
#| tbl-cap: Mph Total Frequency

dplyr::tbl(dbconn, "db/freq_mph.db") |>
dplyr::arrange(mph) |>
tabler(
title = "Speed",
note_list = list("miles per hour"),
location_list = list("mph")
) |>
gt::cols_label(mph = "Mph") |>
gt::cols_align(mph, align = "left")
```

```{r}
#| label: fig-mphTotals
#| fig-cap: Mph Total Frequency

gplot <- dplyr::tbl(dbconn, "db/freq_mph.db") |>
plotter(
x_col = mph, 
y_col = n,
geomType = "column", 
title = "Speed", 
x_label = "Miles per Hour", 
y_label = "Trips")

gplot
```

### Speed by Membership

```{r}
#| label: tbl-mphCompare
#| tbl-cap: Mph Group Frequency

dplyr::tbl(dbconn, "db/freqCompare_mph.db") |>
dplyr::collect() |>
dplyr::arrange(mph, member_casual) |>
tabler(
title = "Mph Groups",
source_note = gt::md("**Source:** `db/freqCompare_mph.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "mph",
label_n = "n",
label_member = " "
)
```

```{r}
#| label: fig-mphCompare
#| fig-cap: Mph Group Frequency

gplot <- dplyr::tbl(dbconn, "db/freqCompare_mph.db") |>
dplyr::arrange(mph, member_casual) |>
dplyr::collect() |>
plotter(
title = "Speed Groups (Aggregated)",
x_label = "Miles per Hour",
y_label = "Trips",
x_col = mph, 
y_col = n, 
color_col = member_casual,
geomType = "column",
#is_lineGroup = TRUE,
is_colGroup = TRUE,
isFaceted = TRUE
)

gplot

```

### Speed has weak predictive value on membership status

```{r}
#| label: tbl-mphModel
#| code-summary: "The basic query for running stats on the various parameters. This version returns aggregated distinct rows for running models that utilize weights. Aggregated rows allows the models to run faster and requires less memory, it seems."

dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(mph, member_casual) |>
dplyr::mutate(mph = round(mph, digits = 0)) |>
dplyr::collect() |>
duckdb::dbWriteTable(
conn = dbconn,
name = "db/rounded_mph.db",
overwrite = TRUE)

source("Scripts/transformData.R")

weighted_data <- transformData(
dbconn, 
"db/rounded_mph.db", 
select_cols = c("mph", "member_casual"), 
group_cols = c("mph", "member_casual"), 
binary_col = "member_casual", 
ntile_col = "ntile_col", 
pred_col = "mph", 
zero_val = "casual", 
one_val = "member",
qtile_levels = c(
"[1 : 5]", "(5 : 7]", "(7 : 9]", "(9 : 20]"),
doQuantile = TRUE,
doWeights = TRUE)

expanded_data <- weighted_data |>
tidyr::uncount(n, .remove = FALSE) |>
dplyr::select(mph, member_casual)

model <- weighted_data |> 
glm(
formula = member_casual ~ ntile_col, 
weights = n, 
family = binomial)

regression_tbl <- model |>
gtsummary::tbl_regression(
label = list(ntile_col = "Range (mph)"), 
conf.int = FALSE, 
exponentiate = TRUE)

regression_tbl |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Speed & Rider Type"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)
```

```{r}
#| label: axis breaks for speed
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics for casuals.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "casual") |>
calcBreaks()
```

```{r}

source("Scripts/plotter.R")

# histogram IQR viz for the speed metric
gplot <- expanded_data |>
dplyr::filter(member_casual == "casual") |>
dplyr::select(mph) |>
plotter(
title = "Speed - Casuals",
x_label = paste0("Speed", "\n", "(miles per hour)"),
y_label = "Trips",
x_col = mph, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(1, 20),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot
```

```{r}
#| label: axis breaks for members' speed
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- expanded_data |>
dplyr::filter(member_casual == "member") |>
calcBreaks()
```

```{r}

source("Scripts/plotter.R")

# histogram IQR viz for the speed metric
gplot <- expanded_data |>
dplyr::filter(member_casual == "member") |>
dplyr::select(mph) |>
plotter(
title = "Speed - Member",
x_label = paste0("Speed", "\n", "(miles per hour)"),
y_label = "Trips",
x_col = mph, 
#y_col = n, 
#group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
#isDensity = TRUE,
isHistogram = TRUE,
#is_colGroup = TRUE,
limits = c(1, 20),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 4,
#density_color = "black",
#density_fill = "red",
#alpha = 0.75,
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red"
) 

gplot

```

```{r}

source("Scripts/transformData.R")

unrounded_data <- transformData(
dbconn, 
tblPath_fltrd, 
select_cols = c("mph", "member_casual"), 
binary_col = "member_casual", 
zero_val = "casual", 
one_val = "member"
)

```

```{r}
#| label: axis breaks for all speed
#| code-summary: Determining optimal breaks in the duration charts based on the x-axis metrics.

source("Scripts/calcBreaks.R")

plotBreaks <- unrounded_data |>
#dplyr::mutate(
#mph = round(mph, digits = 0)) |>
#dplyr::filter(member_casual == "member") |>
calcBreaks()
```

```{r}
#| label: fig-densityMPH

source("Scripts/plotter.R")

# density viz for the mph metric
gplot <- 
unrounded_data |>
#dplyr::mutate(
#mph = round(mph, digits = 2)) |>
plotter(
title = "Trip Speed Group Density",
x_label = paste0("Speed", "\n", "(miles per hour)"),
y_label = "Trips",
x_col = mph, 
#y_col = n,
group_col = member_casual,
geomType = "column", 
#isFaceted = TRUE,
isDensity = TRUE,
#isHistogram = TRUE,
is_colGroup = TRUE,
#limits = c(1, 20),
angle = 45,
breaks = plotBreaks,
color_col = "black",
#binwidth = 1,
#density_color = "gray",
#density_fill = "transparent",
#alpha = 0.75,
#vline_color = "lightyellow",
#vline_size = 0.5,
density_alpha = 0.7,
)

gplot
```

```{r}
#| label: tbl-mphSummary

source("Scripts/tabler.R")

unrounded_data |>
gtsummary::tbl_summary(
by = member_casual,
type = mph ~ "continuous2",
label = list(mph ~ "Speed (miles per hour)"),
digits = list(
mph ~ c(2, 2)),
statistic = 
gtsummary::all_continuous() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
gtsummary::italicize_levels() |>
tabler(
title = gt::md("Summary Statistics: <br> Speed - Membership"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE
)

```

```{r}
#| label: fig-rocMph

source("Scripts/plotter.R")

# Generate ROC curve
roc_mph <- pROC::roc(
expanded_data$member_casual, expanded_data$mph, levels = c("casual", "member"))

# Find the area under the curve value
auc_mph <- round(pROC::auc(roc_mph), 4)

gplot <- roc_mph |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0("ROC Curve for Speed", " (AUC = ", auc_mph, ")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red"
)

# false positive rate = x-axis; true positive rate = y-axis
gplot

```

## Interpretation of EDA

::: p-1
After exploring the associations between the behaviors of annual members and casual riders, several correlations with predictive potential were identified. Chi-squared tests, [@summary], analyzed relationships between categorical variables like membership type, bicycle type, month, day, and hour. Binary logistic regression models, [@regression], examined correlations between the binary dependent variable (membership type) and continuous variables such as distance, duration, and speed. These insights empower stakeholders to make informed decisions to increase service utilization.

Annual members exhibit distinct usage patterns compared to casual riders. They use the service more consistently year-round, preferring manual "classic" bicycles. Annual members take more weekday trips, favoring shorter distances but traveling at faster speeds. These individuals likely have specific destinations in mind, using bicycles as a practical transportation mode akin to cars. Multiple factors likely motivate their choice, including cost savings, avoiding traffic congestion, environmental sustainability, and incorporating exercise. The picture of an annual member is someone with somewhere to be.

In contrast, casual riders tend to be more leisure-oriented, taking longer, slower rides predominantly during warmer months. These fair-weather riders may be visiting Chicago on vacation, opting for bicycles over rental cars as a sightseeing or recreational activity. Some casual users may be prospective annual members, weighing the service's value. The picture of a casual rider is someone who needs something to do.
:::

## Geographic Data

### Traffic Flow {#sec-epiflow}

::: p-1
@fig-epiflowNetwork presents an intriguing bird's-eye view of trip behaviors through an interactive *epiflows* graph. \]@moraga\] This R package used for creating this graph was re-purposed from its original intent for visualizing the spread of disease. This visualization employs a network of nodes (circles) connected by lines, where the thickness of the lines roughly corresponds to the volume of trips between the nodes, with thicker lines indicating a higher number of trips. The top 34 most frequently traveled stations are depicted in this visual network diagram.

The interactive nature of the epiflows allows users to click on individual nodes and lines to access more detailed information. Additionally, a drop-down window provides further exploration capabilities, enabling users to delve deeper into the data.

These stations represent the most active locations within the system. Fortunately, @sec-mapview explores a potential approach to gain insights into the typical high-traffic station locations and the underlying reasons behind their elevated activity levels.
:::

::: {#offcanvas13 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Creating an EpiFlow
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: createFlows dataframe
#| code-summary: First, creates the frequency of trips taken to and from pairs of stations. We are only going to look deeper into the top 50 most traveled pairs.

flowData <- dplyr::tbl(dbconn,
                       tblPath_fltrd) |>
    dplyr::select(start_station_name,
                  end_station_name) |>
    dplyr::group_by(start_station_name,
                    end_station_name) |>
    dplyr::summarize(n = n()) |>
    dplyr::ungroup() |>
    dplyr::arrange(desc(n)) |>
    dplyr::rename("from_station" = start_station_name,
                  "to_station" = end_station_name) |>
    dplyr::collect() |>
    dplyr::slice_head(n = 50)
```

```{r}
#| label: location stats
#| code-summary: Second, we need statistics but also to combine the statistics for every unique station name. 

locationData <- dplyr::tbl(dbconn,
                           tblPath_fltrd) |>
    dplyr::select(start_station_name,
                  end_station_name,
                  started_at,
                  ended_at,
                  trip_time) |>
    dplyr::group_by(start_station_name,
                    end_station_name
                ) |>
    dplyr::mutate("trip_time" = round(trip_time,
                                      digits = 0)) |>
    dplyr::summarize(
        "trip_count" = dplyr::n(),
        "first_date" = min(started_at),
        "last_date" = max(ended_at),
    ) |>
    dplyr::ungroup() |>
    dplyr::rename("from_station" = start_station_name,
                  "to_station" = end_station_name
               ) |>
    dplyr::arrange(desc(trip_count)) |>
    dplyr::collect()

# Need to combine all names to single column and recalculate 
# or retain other stats.
locationData_pivoted <- locationData |>
    tidyr::pivot_longer(cols = 1:2, 
                        values_to = "allNames") |>
    dplyr::group_by(allNames) |>
    dplyr::summarize("trips_toAndfrom" = sum(trip_count),
                     first_date = min(first_date),
                     last_date = max(last_date),
                     ) |>
    dplyr::arrange(trips_toAndfrom)

```

```{r}
#| label: MakeEpiflows
#| code-summary: Third, creates epiflow objects, which take in a pair of dataframes and creates the flows between them. 

# for all the pairs
ef_test <- epiflows::make_epiflows(flows = flowData,
                                   locations = locationData_pivoted,
                                   num_cases = "trips_toAndfrom")
```
:::
:::
:::

::: {#offcanvas14 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Tables
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: summaryFlowData
#| code-summary: First, just a quick view of the flow data table we made earlier.
#| title: Flow Data View

flowData
```

```{r}
#| label: pivotedLocations
#| code-summary: Second, another quick view, but for thethe location data we pivoted earlier.
#| title: Pivoted Location Data

locationData_pivoted |>
    dplyr::arrange(desc(trips_toAndfrom))
```
:::
:::
:::

::: {.article style="color: Black"}
```{r}
#| label: fig-epiflowNetwork
#| fig-cap: EpiFlow Network
#| echo: false

epiflows::vis_epiflows(ef_test)
```
:::

::: {.d-flex .justify-content-center}
::: {.btn-group role="group" aria-label="third"}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas13" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="color: #00BFA5"></i>
```
:::

::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas14" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: #F4511E;"></i>
```
:::
:::
:::

### Checking the Map {#sec-mapview}

::: p-1
This section was made possible thanks to the latitude and longitude coordinates data provided alongside the stations names. Coming from the epiflow diagram, this should help make the data less abstract. The accordion below expands and collapses four *OpenStreet* maps found in the callout section below. These maps were split for viewing logistics. They contain from the epiflow in the section above. These maps are interactive, so the default views are zoom-able and movable. The transparent burst buttons enable snappy zooming-in of the station groups.
:::

::: {#offcanvas20 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Code for Mapping
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: mapData
#| code-summary: "Processing 'flowData' created earlier to include geolocation data for mapview plots."

# All distinct stations in one column
names <- flowData |>
    dplyr::select(from_station,
                  to_station) |>
    tidyr::pivot_longer(cols = 1:2,
                        names_to = NULL,
                        values_to = "station_names") |>
    dplyr::distinct()


# The important geo-coordinates corresponding to station names
mapData <- dplyr::tbl(dbconn,
                      tblPath_fltrd,
                      check_from = FALSE) |>
    dplyr::select(start_station_name,
                  start_lat,
                  start_lng,
                  end_station_name,
                  end_lat,
                  end_lng)

# Filter to include all observations that match the station names listed in 'names'. We need the geo-coordinates alongside the names.
mapData1 <- mapData |>
    dplyr::collect() |>
# Filter, but through a vector of conditions.
    dplyr::filter(start_station_name %in% names[[1]],
                  end_station_name %in% names[[1]]) |>
    dplyr::select(start_station_name:start_lng)


# Had to split 'mapData' into two and pivot into a single table.
mapData2 <- mapData |>
    dplyr::collect() |>
    dplyr::filter(start_station_name %in% names[[1]],
                  end_station_name %in% names[[1]]) |>
    dplyr::select(end_station_name:end_lng)

# Nice grouping
stations_groupMap <- dplyr::bind_rows(mapData1, mapData2) |>
dplyr::select(start_station_name, start_lat, start_lng) |>
dplyr::rename("station_names" = start_station_name,
"lat" = start_lat,
"lng" = start_lng) |>
dplyr::distinct() |>
dplyr::group_by(station_names)

# Setting seed for sampling
set.seed(113)

# Taking 10 random samples from each station_name group
sampled_stations <- stations_groupMap |>
    dplyr::slice_sample(n = 10) |>
    tidyr::drop_na()
```

```{r}
#| label: mapColors
#| code-summary: "Creates a map coloring palette excluding grays."

# All of the r-colors
allPalette <- colors()

# The grays are vast so we don't want those watering down the samples.
colorfulPal <- purrr::discard(allPalette, stringr::str_detect(allPalette, "gr(a|e)y"))

# When we sample the colors, 10 should be slightly more than needed.
n_colors <- 10
```

```{r}
#| label: mapViewer
#| code-summary: First, sourcing the script needed to generate the maps and creating the list of vectors used as input. These vectors are the slices of the top most traveled stations.

slicerVector <- list(c(1:9), c(10:18), c(19:27), c(28:34))
source("Scripts/mapViewer.R")
```

```{r}
#| file: "Scripts/mapViewer.R"
#| eval: false
#| code-summary: "The script used to generate the maps."
#| label: mapViewerScript
```
:::
:::
:::

::: {#accordionParent .accordion .mt-3 .mb-3}
::: accordion-item
::: {#headingOne .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne" style="background-color: #222"}
Benson Ave & Church St ... Ellis Ave & 60th St
:::
:::

::: {#collapseOne .accordion-collapse .collapse aria-labelledby="headingOne" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map1
#| fig-cap: "Benson Ave & Church St - Ellis Ave & 60th St"

set.seed(240)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[1]])

```
:::
:::
:::

::: accordion-item
::: {#headingTwo .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo" style="background-color: #222"}
Greenview Ave & Fullteron Ave ... Loomis Ave & Lexington St
:::
:::

::: {#collapseTwo .accordion-collapse .collapse aria-labelledby="headingTwo" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map2
#| echo: false
#| fig-cap: "Greenview Ave & Fullteron Ave - Loomis Ave & Lexington St"

set.seed(241)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[2]])

```
:::
:::
:::

::: accordion-item
::: {#headingThree .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree" style="background-color: #222"}
Michigan Ave & Oak St ... State St & 33rd St
:::
:::

::: {#collapseThree .accordion-collapse .collapse aria-labelledby="headingThree" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map3
#| echo: false
#| fig-cap: "Michigan Ave & Oak St - State St & 33rd St"

set.seed(242)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[3]])

```
:::
:::
:::

::: accordion-item
::: {#headingFour .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour" style="background-color: #222"}
Street Dr & Grand Ave ... Woodlawn Ave & 55th St
:::
:::

::: {#collapseFour .accordion-collapse .collapse aria-labelledby="headingFour" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map4
#| fig-cap: "Street Dr & Grand Ave - Woodlawn Ave & 55th St"

set.seed(243)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[4]])
```
:::
:::
:::
:::

### Interpretation of the Geographic Data

::: p-1
For example, suppose the user selects *University Ave & 57th St* in the epiflow visualization. This intersection happens to be at the heart of the University of Chicago campus. The natural next question is: where does the traffic to and from this location typically flow? By selecting one of the other nodes highlighted with flows directing away from the previous node, the user can identify *Kimbark Ave and 53rd St*. As seen in the map view, this location is situated adjacent to the *Vue 53 Apartments* complex. By analyzing such connections between nodes, the user can gain insights into common routes and destinations originating from a particular point of interest, potentially revealing patterns related to student housing, campus facilities, or other points of interest in the vicinity.

The data suggests individual members utilize the service multiple times weekly. However, further analysis is needed to determine if a significantly larger volume of unique individuals are annual members. Verifying associations between specific locations and higher or lower traffic could be a next step. Preliminary observations indicate universities, shopping centers, major companies, and nearby apartment complexes tend to have the highest ridership volumes.

To improve membership, addressing factors deterring individuals from becoming annual members could be key. These may include a lack of stations within walking distance of residences or destinations, or concerns over electric bicycle battery life and charging station availability, potentially explaining their lower utilization compared to classic bikes. Offering trial periods could allow casual users to experience the service's reliability and convenience, encouraging conversion to annual memberships.
:::

## Updated Database Tables List

```{r}
#| label: tbl-dbList2
#| code-summary: "Revisiting the list of db tables, with many more tables added. All of these tables are stored within the data/data.db file."
#| tbl-cap: "Database Table List: Post-Exploratory Analysis"

dbList2 <- duckdb::dbListTables(dbconn) |>
as.data.frame() |>
tabler(
title = "Post-Exploratory Database Tables",
note_list = list(
gt::md("The tables contained in data.db, <br> at the end of the analysis.")
),
location_list = list("duckdb::dbListTables(dbconn)")
) |>
gt::cols_label("duckdb::dbListTables(dbconn)" = "Table Paths") |>
gt::tab_style(
gt::cell_text(align = "center", stretch = "semi-expanded"),
locations = list(
gt::cells_column_labels(columns = gt::everything())
)
)

dbList2
```

# Conclusion

::: p-1
These findings empower stakeholders with data-driven insights to increase service utilization and make informed decisions regarding resource allocation, marketing, and service enhancements.
:::

## Key Findings

::: p-1
-   Annual members exhibit consistent, practical usage patterns - frequent weekday trips, shorter distances at faster speeds, favoring "classic" bikes. Likely using the service for transportation, motivated by factors like cost, convenience, and exercise.

-   Casual riders demonstrate more leisurely behavior - longer, slower rides concentrated in warmer months, potentially for sightseeing/recreation purposes when visiting the city.

-   Correlations identified between membership type and variables like distance, duration, speed, month, day, hour, and bike type through statistical testing.
:::

## Recommendations:

::: p-1
-   Verify associations between specific locations (universities, shopping centers, businesses, residential areas) and higher/lower traffic to optimize service distribution.

-   Analyze the volume of unique individuals represented in each membership type to gauge potential for conversion from casual to annual.

-   Leverage insights into usage patterns and motivations to tailor marketing strategies, targeting prospective annual members among casual rider demographics.
:::

```{r}
#| eval: false
#| include: false

# If you need to drop any tables without deleting the entire database.
source("Scripts/duckDrops.R")
```
