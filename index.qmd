---
title: "Bike-Sharing in the Streets of Chicago"
author: "Eric Mossotti"
date: "05-23-2024"
date-modified: last-modified
date-format: "MMM D, YYYY"

bibliography: references.bib
repo: https://github.com/ericMossotti/Bike_Share
source: index.qmd
abstract-title: "Objective"
abstract: "Communicating reproducible, data-driven insights."
description-meta: "Communicate reproducible, data-driven insights."

code-links:
    - text: "Project Repo"
      href: https://github.com/ericMossotti/Bike_Share
code-fold: true
code-copy: hover
code-overflow: wrap
code-tools: true
code-link: true

toc: true
toc-location: left
toc-depth: 5
number-sections: true
link-external-newwindow: true

smooth-scroll: true
fig-responsive: true
echo: true

citation-location: margin
citations-hover: true
link-citations: true
csl: csl/apa.csl
zotero: true

callout-appearance: simple

license: CC BY-SA
funding: "The author(s) received no specific funding for this work."
---

```{r, include = FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)
```

------------------------------------------------------------------------

# Intro

::: {#offcanvas1 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {#offcanvasLabel .h5 .offcanvas-title}
Import Processing Code
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: importOrConnect
#| code-summary: First, we decide whether to download and do the necessary initial processing steps or skip that if we have already done this and are just tinkering around with the project. 
#| tidy: true

if(exists("dbconn") == FALSE &&
   dir.exists("db") == FALSE) {
  # Script within if-else to simplify workflow
  source("Scripts/import_clean_initial.R")
} else {
  tblPath <- "db/data.db"
  
  dbconn <- DBI::dbConnect(duckdb::duckdb(), dbdir = tblPath, read_only = FALSE)
}

# Paths one might still need if script doesn't need to execute.
tblPath <- "db/data.db"
tblPath_fltrd <- "db/data_fltrd.db"
rawPath <- "db/rawData.db"

# Loading plot and table scripts while at it. 
source("Scripts/tabler.R")
source("Scripts/plotter.R")
source("Scripts/TransformData.R")
```

```{r}
#| label: importProcessScript
#| code-summary: This then would be executed if conditions were met. Usually, this would only execute if there is no db folder and associated files.
#| file: "Scripts/import_clean_initial.R"
#| eval: false 
```
:::
:::
:::

## Stakeholders

The primary stakeholders in this analysis are Divvy, Lyft (the parent company of Divvy), and the City of Chicago Department of Transportation. The analysis aims to provide these stakeholders with data-driven insights to enhance the Divvy bike-sharing service, better serving the residents of Chicago and its users. The initial rationale behind Divvy's implementation included improving air quality, promoting economic recovery, and reducing traffic congestion within the city. [@aboutdi]

## Source

::: p-1
The raw 2023 dataset was imported from Divvy Data. [@divvyda]
:::

::: column-screen-inset
```{r}
#| label: tbl-raw
#| tbl-cap: Raw data
#| cap-location: top
#| tidy: true

# List of column labels to feed tabler() and add_multiple_footnotes()
location_list <- dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
colnames() |>
as.list()

# A simple list of footnotes to feed tabler() and add_multiple_footnotes().
note_list <- list(
"Anonymized trip identifier.", 
"The bicycle type.", 
"Starting date-time (to the second).",
"Ending date-time (to the second).",
"Station name of where the trip started.",
"Station ID of where the trip started.",
"Station name of where the trip ended.",
"Station ID of where the trip ended.",
"Latitude associated with the starting location.",
"Longitude associated with the starting location.",
"Latitude associated with the ending location.",
"Longitude associated with the ending location.",
"If someone is an annual subscriber or not."
)

dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
dplyr::slice_head(n = 10) |>
tabler(
title = "A Glimpse of the Raw Data",
source_note = gt::md("**Source**: Divvy Data"),
note_list = note_list,
location_list = location_list,
value_columns = NULL
) |>
gt::tab_options(
table.font.size = gt::pct(75),
footnotes.multiline = FALSE
)

```
:::

::: {#offcanvas100 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Glimpse
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: glimpseRaw
#| code-summary: A quick overview of the raw data.
#| tidy: true

dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
tibble::glimpse() 
```
:::
:::
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas100" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: #F4511E;"></i>
```
:::
:::

## Design

Another worthy objective of this analysis is to achieve reproducibility and efficiency. To facilitate future research and enable subsequent analyst teams to build upon this work, the project aimed to provide adequate code documentation and adhere to best practices regarding clean code and mod-ability.

For instance, certain design decisions were incorporated to eliminate the need for re-downloading and re-processing data. For analysts conducting analysis over an extended period, such as days or months, on this dataset, it is now possible to simply reconnect to the single database file containing all the original data, including tables generated throughout the analysis process, following the initial download and subsequent processing.

The underlying code incorporates an if-else decision, which includes a source code script responsible for handling the initial data processing and establishing the database filesystem. Opting for a persistent DuckDB filesystem (as opposed to a purely in-memory solution) appeared optimal in terms of simplicity, cost-effectiveness of SQL database queries, and retaining progress made over extended periods. [@whyduck]

To streamline the process, reduce code duplication, and maintain consistent formatting throughout the project, reusable functions were developed for generating most of the tables and figures. These functions are located in the "Scripts" folder within the working directory. Their modular design not only simplifies the implementation of formatting changes but also facilitates the integration of additional code snippets when necessary. For instance, certain plots might require limiting the range of the axes, which can be achieved by combining these functions with appropriate code addendum. By leveraging these functions, the project benefits from reduced redundancy, improved efficiency, and cohesive formatting across all visualizations and data representations.

## Initial Database Table List

```{r}
#| label: tbl-dbList
#| code-summary: "These are the starting tables contained in the data/data.db file. Noting this as we will be adding many more tables in the later stages."
#| tbl-cap: "Initial DB Table List"
#| tidy: true


dbList <- duckdb::dbListTables(dbconn) |>
as.data.frame() |>
tabler(
title = "Starting Database Tables",
note_list = list(gt::md("The tables contained <br>in data.db, at the end of the analysis.")),
location_list = list("duckdb::dbListTables(dbconn)")
) |>
gt::cols_label("duckdb::dbListTables(dbconn)" = "Table Paths") |>
gt::tab_style(
gt::cell_text(
align = "center",
stretch = "semi-expanded"
), 
locations = list(
gt::cells_body(columns = gt::everything()),
gt::cells_column_labels(columns = gt::everything()))
)

dbList
```

::: flex-code
```{r}
#| label: tablerScript
#| code-summary: This code was used for generating many of the tables. See the later code dropdowns alongside tables for clues as to how it is implented in this document.
#| file: "Scripts/tabler.R"
#| eval: false 
```
:::

::: flex-code
```{r}
#| label: plotterScript
#| code-summary: This code was used for generating many of the plots. See the later code dropdowns alongside tables for clues as to how it is implented in this document.
#| file: "Scripts/plotter.R"
#| eval: false 
```
:::

# Tidying

::: p-3
The starting observation count was 5,719,877. Then 1,388,170 incomplete observations were then removed by the initial processing script.
:::

::: {.callout-warning .calloutWarning icon="false" width="auto"}
Code processing steps are accessible through embedded code icon links, like the one below. Drop-down code summaries provide context on data processing rationale and methodology at various analysis stages, enhancing reader understanding.
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas1" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: 1.5rem; color: #00BFA5;"></i>
```
:::
:::

## Duplicates

::: {#offcanvas2 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Code to Remove Duplicates
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: originalNobs
#| code-summary: First, record original observations from the raw data.
#| tidy: true

# Need to save this count for the summary table later
original_nobs <- dplyr::tbl(dbconn, rawPath) |>
dplyr::collect() |>
nrow()
```

```{r}
#| label: duplicates_gt
#| code-summary: Create a table containing the duplicated observations.
#| tidy: true

# This is a separate table used to analyze the observations
# returned as not distinct (n > 1). This adds an extra column, labeled "n".
dupeTable <- dplyr::tbl(dbconn, tblPath) |>
dplyr::select(started_at:end_station_name) |>
# Counts of unique rows added for column 'n'
dplyr::add_count(started_at, ended_at, start_station_name, end_station_name) |>
# Only observations that have been duplicated 1 or more times are shown.
dplyr::filter(n > 1) |>
# To see all rows, not just one row for each obs.
dplyr::ungroup() |>
dplyr::arrange(started_at) |>
dplyr::collect()
```

```{r}
#| label: duplicateObs count
#| code-summary: Record a count of distinct duplicates and total observations.
#| tidy: true

distinctCopiesCount <- dupeTable |>
dplyr::distinct(n) |>
as.integer()

duplicateObs <- length(dupeTable[[1]])
```

```{r}
#| label: undupedTable
#| code-summary: Create a table of the now unduplicated observations seen earlier.
#| tidy: true

# The issue is, we need to get rid of not all of these rows, but just the extra duplicate observations.

# If there were 2 rows of duplicates, one would want to end up with 1 row after removing the extras.
undupedTable <- 
dupeTable |>
dplyr::distinct(started_at, 
start_station_name, 
ended_at, 
end_station_name)
```

```{r}
#| label: incorrect distinct obs count
#| code-summary: Record a count of the incorrect observations.
#| tidy: true

# Run an incorrect count on how many rows or observations there are in the dataset.
count_incorrectDists <- dplyr::tbl(dbconn, tblPath) |>
dplyr::distinct(dplyr::pick("ride_id")) |>
dplyr::count(name = "Incorrect Distinct Observations") |>
dplyr::collect() |>
as.integer()
```

```{r}
#| label: count_correctDists count
#| code-summary: Record a count of the correct observations.
#| tidy: true

# For the correct count of obs
count_correctDists <- dplyr::tbl(dbconn, tblPath) |>
dplyr::distinct(dplyr::pick(
"started_at",
"start_station_name",
"ended_at",
"end_station_name"
)) |>
dplyr::count() |>
dplyr::collect() |>
as.integer()
```

```{r}
#| label: writeUnduplicated
#| code-summary: Lastly, write the unduplicated data to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/unduped.db"))) {
dplyr::tbl(dbconn, tblPath) |>
dplyr::distinct(started_at,
start_station_name,
ended_at,
end_station_name,
.keep_all = TRUE) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/data_unduped.db",
overwrite = TRUE)
}
```
:::
:::
:::

::: p-1
A crucial question arises: How can one identify and handle duplicate data? This section covers the process of checking for duplicates and selectively removing them while exercising caution. It is essential to recognize that the presence of unique values in a single column does not necessarily guarantee the uniqueness of each observation or row.

While all values in the **ride_id** column were found to be unique, not all observations were truly distinct. To verify the uniqueness of each observation, additional columns such as **start_time**, **end_time**, **start_station**, and **end_station** were utilized. These columns provide more granular information, including the precise starting and ending times down to the second, as well as the starting and ending locations. It was assumed that observations with identical starting and ending date-times and stations, despite having different rider IDs, were potentially erroneous duplicates.
:::

::: {.tableScroller .p-2}
```{r}
#| label: tbl-duplicates
#| tbl-cap: Duplicates Table
#| eval: true
#| include: true
#| tidy: true

gtDupes <- dupeTable |>
dplyr::group_by(started_at) |>
gt::gt(
rowname_col = "row",
groupname_col = "started_at",
row_group_as_column = TRUE
) |>
gt::tab_style(
style = list(
gt::cell_text(weight = "bold", align = "center"),
gt::cell_borders(sides = c("bottom"))
),
locations = gt::cells_column_labels(gt::everything())
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = c("left", "right"), color = "transparent"),
gt::cell_text(align = "center", v_align = "middle")
),
locations = gt::cells_body(gt::everything())
) |>
gt::data_color(
columns = start_station_name,
target_columns = gt::everything(),
method = "auto",
palette = "basetheme::brutal"
) |>
gt::tab_header(title = "A view of duplicated observations", subtitle = "Grouping follows the starting date-time value") |>
gt::tab_options(
heading.title.font.weight = "bolder",
heading.subtitle.font.weight = "lighter",
heading.align = "center",
table.background.color = "transparent",
table.font.color = "SeaShell",
table.font.size = gt::pct(75),
)

gtDupes
```
:::

::: {.p-2 .mt-2}
Although the cause of such duplication errors is unknown, it could be assumed that one person checked out multiple bikes simultaneously. In that scenario, each bike would be assigned a unique **ride_id**. However, this occurrence was relatively rare, happening only **18** times over the course of a year. Since there is only one duplicate for each instance, it raises concerns and warrants further investigation. It is possible that trips could be grouped where one person pays for another rider's fare. However, if that were the case, it raises the question of why there is always precisely one duplicate.

In @tbl-duplicates, duplicate observations are listed and grouped by color for visual clarity. In contrast, @tbl-unduplicated presents the data after removing the extra copy of each duplicate observation while preserving the unique observations. Of the duplicates identified, each had one extra copy. It was noted that the number of rows in the duplicates table is 36. Each duplicated observation has one duplicate, where **n** (the count) is always 2. Therefore, the expected number of observations to be removed was 18. A complication arose in determining how to remove not all observations but only the extra duplicate observation from each group.
:::

::: {.p-2 .tableScroller}
```{r}
#| label: tbl-unduplicated
#| tbl-cap: Un-duplicated Table

gt_undupes <- undupedTable |>
dplyr::collect() |>
dplyr::group_by(started_at) |>
gt::gt(
rowname_col = "row",
groupname_col = "started_at",
row_group_as_column = TRUE
) |>
gt::fmt_number(decimals = 0) |>
gt::tab_style(
style = list(
gt::cell_text(weight = "bold", align = "center"),
gt::cell_borders(sides = c("bottom"))
),
locations = gt::cells_column_labels(gt::everything())
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = c("left", "right")),
gt::cell_text(align = "center", v_align = "middle")
),
locations = gt::cells_body(gt::everything())
) |>
gt::data_color(
columns = start_station_name,
target_columns = gt::everything(),
method = "auto",
palette = "basetheme::brutal"
) |>
gt::tab_header(title = "After duplicates were removed", subtitle = "Same grouping") |>
gt::tab_options(
heading.title.font.weight = "bolder",
heading.subtitle.font.weight = "lighter",
heading.align = "center",
table.background.color = "transparent",
table.font.color = "SeaShell",
table.font.size = gt::pct(75)
)

gt_undupes

```
:::

::: {.mb-2.mt-2}
To ensure the accurate removal of duplicates, the count of distinct n-values (representing the number of occurrences) for the un-duplicated table was computed, confirming the expected 18 unique instances. Subsequently, the total number of observations in the dataset was recorded, initially standing at 4,331,707. After removing the identified duplicate observations, the correct count of observations was 4,331,689. In summary, 18 additional observations were successfully removed, aligning with the expected number of duplicates identified earlier. These steps are documented in @tbl-observationHistory for reference.

By carefully analyzing the count of distinct n-values and the total observation count before and after reduplication, it was ensured that only the precise number of duplicate observations was removed, preserving the integrity of the unique data while eliminating the identified duplicates. This meticulous approach to data cleaning is crucial for maintaining data quality and reliability throughout the analysis process.
:::

::: {.d-flex .justify-content-center}
::: {.btn .btn-outline-light type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas2" aria-controls="offcanvas"}
Record observations
:::
:::

## Outliers

::: {#offcanvas33 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Filter Database
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: filterDecisions
#| code-summary: If you happen to be re-using this code - this is so you do not have to re-download or re-filter after making further adjustments.
#| tidy: true

tblPath_fltrd <- "db/data_fltrd.db"

# Do we still need to filter the database?
if (duckdb::dbExistsTable(dbconn, tblPath_fltrd) == FALSE) {
source("Scripts/filterDatabase.R")
filterDatabase(conxn = dbconn, oldPath = "db/data_unduped.db", newPath = tblPath_fltrd)
}
```
:::
::: {.flex-code}
```{r}
#| label: filterScript
#| code-summary: This would execute if the if-else conditions were met to filter the db/data.db database table
#| file: "Scripts/filterDatabase.R"
#| eval: false
```
:::
:::
:::

Observations deemed erroneous or irrelevant for identifying usage trends among members and casual users were filtered out. Keeping track of these errors is a good practice, as they might provide insights into the differences in how members and casuals utilize the service.

Trips with negative duration were flagged as errors and removed. Additionally, trips lasting less than a minute but greater than zero were noted and removed, as they could potentially skew the derived statistics. These extremely short trips might be attributed to users briefly trying out the service before committing or quickly realizing their dissatisfaction with it. While some observations seemed nonsensical, most of the data was retained.

Consistent with the previous approach, an **if-else** decision was employed to facilitate testing. An external database filtering script was utilized to streamline the code within the main Quarto document. The resulting filtered data served as the foundation for subsequent analysis and table generation.

::: {.p-2 .flex-code}
```{r}
#| label: countFiltered
#| code-summary: "To get a count of the new total observations after filtering."
#| tidy: true

count_filtered <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(ride_id) |>
dplyr::distinct() |>
dplyr::count() |>
dplyr::collect() |>
as.integer()

```
:::

::: {.p-3 .flex-code max-width="auto"}
```{r}
#| label: tbl-observationHistory
#| tbl-cap: Observation Processing History

# To see the history of obs in our dataset.
summaryProcessTable <- tidyr::tribble(
~ "Observations",
~ "Counts",
"Original   ",
original_nobs,
"Complete Observations   ",
count_incorrectDists,
"Duplicates   ",
(count_incorrectDists - count_correctDists),
"Filtered     ",
(count_correctDists - count_filtered),
"Total Corrected   ",
count_filtered
) |>
gt::gt(rownames_to_stub = FALSE) |>
gt::tab_header(title = "Tallying Observations") |>
gt::tab_footnote(
footnote = gt::md("Row counts throughout the cleaning steps."),
locations = gt::cells_column_labels(columns = Counts)
) |>
gt::tab_style(
style = list(
gt::cell_borders(sides = "bottom"),
gt::cell_text(
align = "left",
stretch = "semi-expanded",
whitespace = "break-spaces"
)
),
locations = gt::cells_body(gt::everything())
) |>
gt::tab_style(
gt::cell_text(
align = "center",
stretch = "semi-expanded",
whitespace = "break-spaces"
),
locations = list(
gt::cells_title(groups = c("title", "subtitle")),
gt::cells_column_labels(gt::everything())
)
) |>
gt::fmt_number(decimals = 0) |>
gt::tab_options(
column_labels.font.weight = "bold",
table.background.color = "transparent",
table.font.color = "SeaShell",
row.striping.background_color = "gray10",
row.striping.include_table_body = TRUE
)

summaryProcessTable
```
:::



::: {.d-flex .justify-content-center}
::: {.btn .btn-outline-success type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas33" aria-controls="offcanvas"}
Filter and write
:::
:::

# Exploratory Analysis

## Membership

::: {.callout-important icon="false"}
<!-- -->
-   @tbl-memberTotals displays the total trip count for annual members and casual riders.
:::

::: {#offcanvas33243 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Membership Tables
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeMembership
#| code-summary: Write ... to db/... .db
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/membership.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(member_casual) |>
dplyr::arrange(member_casual) |>
dplyr::collect() |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/membership.db",
overwrite = TRUE)
}
```

```{r}
#| label: tbl-kableMembership
#| tbl-cap: Kable output
#| tidy: true

dplyr::tbl(dbconn, "db/membership.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
::: {.d-flex .justify-content-center}
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas33243" aria-controls="offcanvas"}
Write, then preview tables for this section
:::
:::

::: panel-tabset
### [Totals]{.panel-tabset-label}
::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-memberTotals
#| tbl-cap: Total Member Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/membership.db") |>
dplyr::select(member_casual) |>
dplyr::group_by(member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
tabler (
title = "Membership", 
source_note = gt::md("**Source**: `db/membership.db`"),
footnote = gt::md("The recorded observations."),
location = n
) |>
gt::cols_label(member_casual = "Membership")
```

#### [Plot]{.panel-tabset-label}

::: column-page-inset-right
```{r}
#| label: fig-totalmemberFrequency
#| fig-cap: Total Member Frequency
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/membership.db") |>
dplyr::select(member_casual) |>
dplyr::group_by(member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
plotter(
x_col = member_casual, 
y_col = n, 
geomType = "column", 
title = "Membership Types", 
x_label = "Rider Types", 
y_label = "n")

gplot
```
:::
:::
:::

## Cycle Types

::: {.callout-important icon="false"}
<!-- -->

-   @tbl-ctypeTotals and @fig-ctypeTotals compare the total trips taken on conventional and electric bicycles, clearly showing that electric bikes are not utilized as much as conventional ones.
:::

::: {#offcanvas48 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Bicycle Type Tables
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: write bType to duckdb
#| code-summary: Write bType.db to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/bType.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(rideable_type, member_casual) |>
dplyr::arrange(rideable_type, member_casual) |>
dplyr::collect() |>
dplyr::mutate(rideable_type = forcats::as_factor(rideable_type)) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/bType.db",
overwrite = TRUE)
}
```

```{r}
#| label: btypeTransform
#| code-summary: Transform and write ... for modeling.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/bType_w.db"))) {
transformData(
conn = dbconn,
path = "db/bType.db",
select_cols = c("rideable_type", "member_casual"),
group_cols = c("rideable_type", "member_casual"),
binary_col = "member_casual",
zero_val = "casual",
one_val = "member",
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/bType_w.db",
overwrite = TRUE)
}
```

::: {layout="[[1,2]]"}
```{r}
#| label: tbl-kableBtype
#| tbl-cap: Kable output
#| tidy: true

dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-kableBtypeW
#| tbl-cap: Kable output
#| tidy: true

dplyr::tbl(dbconn, "db/bType_w.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas48" aria-controls="offcanvas"}
Write, then preview tables for this section
:::
:::
:::

::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-btypeTotal
#| tbl-cap: Cycle Type Total Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::select(rideable_type) |>
dplyr::group_by(rideable_type) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
tabler( 
title = "Bicycles", 
footnote = gt::md("The recorded observations."),
location = n
)
```

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-btypeTotal
#| fig-cap: Cycle Type Total Frequency 
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::select(rideable_type) |>
dplyr::group_by(rideable_type) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
plotter(
x_col = rideable_type, 
y_col = n, 
geomType = "column", 
title = "Bicycle Type", 
x_label = "Type", 
y_label = "Trips")

gplot
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-btypeGroups
#| tbl-cap: Cycle Type Group Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::select(rideable_type, member_casual) |>
dplyr::group_by(rideable_type, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
tabler(
title = "Bicycle Type to Membership", 
groupName = "rideable_type", 
footnote = "The recorded observations.", 
location = n,
source_note = gt::md("**Source**: `db/freqCompare_rType`"),
label_n = "n",
label_member = " "
) 
```

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-btypeGroups
#| fig-cap: Bicycle to Membership Freq
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::select(rideable_type, member_casual) |>
dplyr::group_by(rideable_type, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
plotter(
title = "Bicycle Groups",
x_label = "Type",
y_label = "Trips",
x_col = rideable_type, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
is_colGroup = TRUE,
color_col = "black",
colPosition = "dodge",
colGroup_palette = "Paired"
)

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

```{r}
#| label: tbl-btypeChiSquare
#| tidy: true

dplyr::tbl(dbconn, "db/bType.db") |>
dplyr::select(rideable_type, member_casual) |>
dplyr::collect() |>
tabler(
title = "Chi-Square: Bicycle Type & Membership",
source_note = gt::md("**Source**: `db/bType.db`"),
label = list(
rideable_type = "Bicycle Type", 
member_casual = "Membership"),
by = member_casual,
isSummary = TRUE
)
```

#### [Density]{.panel-tabset-label}

::: column-body-outset-right
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: btypeModel
#| code-summary: Predicting the log-odds of being a member versus being a casual user based on ...
#| tidy: true

model <- 
dplyr::tbl(dbconn, "db/bType_w.db") |>
glm(formula = member_casual ~ rideable_type, weights = n, family = binomial)
```

```{r}
#| label: tbl-btypeModel
#| tidy: true

regression_tbl <- model |>
gtsummary::tbl_regression(
label = list(rideable_type = "Cycle Type"), conf.int = FALSE, exponentiate = TRUE)

regression_tbl |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Cycle Type to Membership"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

::: column-body-outset-right
:::

#### [Summary Stats]{.panel-tabset-label}

#### [AUC]{.panel-tabset-label}

::: column-body-outset-right
:::
:::
:::

## Duration

::: {.callout-important icon="false"}
<!-- -->
:::

::: {#offcanvas68 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Bicycle Type Tables
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: write duration to duckdb
#| code-summary: Write ... to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/duration.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(trip_time, member_casual) |>
dplyr::arrange(trip_time, member_casual) |>
dplyr::collect() |>
dplyr::mutate(
trip_time = round(trip_time, digits = 2),
mins = round(trip_time, digits = 0),
mins = forcats::as_factor(mins)
) |>
dplyr::arrange(trip_time, member_casual) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/duration.db",
overwrite = TRUE)
}
```

```{r}
#| label: durationWeightedQuantiles
#| code-summary: Query ... .db, transform and write weighted quartile data to ... _wq.db. 
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/duration_wq.db"))) {
transformData(
conn = dbconn,
path = "db/duration.db",
select_cols = c("trip_time", "member_casual"),
group_cols = c("trip_time", "member_casual"),
binary_col = "member_casual",
pred_col = "trip_time",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c(
"Q1 (1.02 - 5.73]",
"Q2 (5.73 - 9.55]",
"Q3 (9.55 - 16.13]",
"Q4 (16.13 - 475.22]"
),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/duration_wq.db",
overwrite = TRUE)
}
```

::: {layout="[[1,2]]"}
```{r}
#| label: tbl-kableDuration
#| tbl-cap: Kable output
#| tidy: true

dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-kableDurationWQ
#| tbl-cap: Kable output
#| tidy: true

dplyr::tbl(dbconn, "db/duration_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::m-3
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas68" aria-controls="offcanvas"}
Write, then preview tables for this section
:::
:::
:::

::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-triptimeTotals
#| tbl-cap: Trip-Time Totals
#| tidy: true

dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::group_by(mins) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
tabler( 
title = "Duration", 
footnote = gt::md("The recorded observations."),
location = n
) |>
gt::cols_align(columns = "mins", align = "left")
```
:::

#### [Plot]{.panel-tabset-label}

::: column-page-inset-right
```{r}
#| label: fig-triptimeTotals
#| fig-cap: Trip Duration Totals
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::select(mins) |>
dplyr::filter(as.integer(mins) <= 100) |>
dplyr::group_by(mins) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
plotter(
x_col = as.integer(mins), 
y_col = n,
geomType = "column", 
title = "Duration", 
x_label = "Minutes", 
y_label = "Overall Trips",
color_col = "black") +
ggplot2::scale_x_continuous(
limits = c(0, 100),
breaks = seq(0, 100, by = 5),
guide = ggplot2::guide_axis(n.dodge = 1, angle = 45)
)

gplot
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-triptimeCompare
#| tbl-cap: Trip Time Comparison
#| tidy: true

dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::select(mins, member_casual) |>
dplyr::filter(as.integer(mins) <= 100) |>
dplyr::group_by(mins, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mins, member_casual) |>
dplyr::collect() |>
tabler(
title = "Duration Compare",
source_note = gt::md("**Source:** `db/freqCompare_tripTime.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "mins",
label_n = "n",
label_member = " "
)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-page-inset-right
```{r}
#| label: fig-triptimeCompare
#| fig-cap: Trip-Time Group Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::select(mins, member_casual) |>
dplyr::filter(as.integer(mins) <= 100) |>
dplyr::group_by(mins, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mins, member_casual) |>
dplyr::collect() |>
plotter(
title = "Duration Groups",
x_label = "Minutes",
y_label = "Trips",
x_col = mins, 
y_col = n, 
group_col = member_casual,
geomType = "column",
is_colGroup = TRUE,
colPosition = ggplot2::position_stack(reverse = TRUE),
color_col = "black"
) +
ggplot2::scale_x_discrete(
guide = ggplot2::guide_axis(n.dodge = 1, angle = 45), 
breaks = forcats::as_factor(seq(0, 100, by = 5)))

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

#### [Density]{.panel-tabset-label}

::: column-page-inset-right
```{r}
#| label: fig-durationDensity
#| code-summary: Density plot for duration by membership.
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::select(trip_time, member_casual) |>
dplyr::arrange(trip_time, member_casual) |>
dplyr::collect() |>
plotter(
title = "Duration Group Density",
x_label = paste0("Minutes"),
x_col = trip_time, 
group_col = member_casual,
geomType = "column",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isDensity = TRUE,
is_colGroup = TRUE,
breaks = seq(0, 100, by = 5),
limits = c(0, 100)
)

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: modeldurationQ
#| code-summary: Query ..._wq.db, process and create model R object for hour based on quartile range. 

model <- 
dplyr::tbl(dbconn, "db/duration_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```

```{r}
#| label: tbl-modeldurationQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  

model |>
gtsummary::tbl_regression(
label = list(quartile = "Duration Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Duration & Membership"),
source_note = gt::md("**Source**: `db/duration_wq.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

```{r}
#| label: durationQuantile
#| code-summary: Create a data frame, then extract the desired quartile info to supplement histogram visualization for ... data.
#| tidy: true

qdf <- dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::select(trip_time) |>
dplyr::collect()

quartiles <- quantile(qdf$trip_time, probs = c(0.25, 0.5, 0.75))
```

::: column-page-inset-right
```{r}
#| label: fig-durationHistogram
#| tidy: true
#| fig-dpi: 150

gplot <- 
qdf |>
plotter(
title = "Duration",
x_label = "Duration",
y_label = "Trips",
x_col = trip_time, 
geomType = "column", 
isHistogram = TRUE,
angle = 45,
color_col = "transparent",
vline_color = "lightyellow",
vline_size = 0.5,
low = "red",
high = "blue",
limits = c(0,100),
breaks = seq(0, 100, by = 5),
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles
)

gplot
```
:::

#### [AUC]{.panel-tabset-label}

```{r}
#| label: durationROC
#| code-summary: Generate the ROC Curve

roc_duration <- 
dplyr::tbl(dbconn, "db/duration.db") |>
dplyr::collect() |>
pROC::roc(member_casual, trip_time, levels = c("casual", "member"))


```

```{r}
#| label: durationAUC
#| code-summary: Find the area under the curve value (AUC), round to 4 decimals.

auc_duration <- round(pROC::auc(roc_duration), 4)
```

::: column-page-inset-right
```{r}
#| label: fig-rocDuration
#| fig-dpi: 150
#| tidy: true

gplot <- roc_duration |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0("ROC Curve for Duration", " (AUC = ", auc_duration, ")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red")

gplot
```
:::
:::
:::

## Month

::: {.callout-important icon="false"}
<!-- -->
:::

::: {#offcanvas78 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Months of the Year
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeMonths
#| code-summary: Write moy.db to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/moy.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
member_casual = factor(member_casual, levels = c("casual", "member")),
abbMonths = lubridate::month(started_at, label = TRUE, abbr = TRUE),
abbMonths = forcats::as_factor(abbMonths)
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/moy.db",
overwrite = TRUE)
}
```

```{r}
#| label: monthsWeightedQuantiles
#| code-summary: Query ..., transform, and write weighted quartile data to ..._wq.db.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/moy_wq.db"))) {
transformData(
conn = dbconn,
path = "db/moy.db",
select_cols = c("started_at", "member_casual"),
group_cols = c("started_at", "member_casual"),
binary_col = "member_casual",
pred_col = "started_at",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c(
"Q1 (Jan 01 - May 20]",
"Q2 (May 20 - Jul 21]",
"Q3 (Jul 21 - Sep 18]",
"Q4 (Sep 18 - Dec 31]"
),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/moy_wq.db",
overwrite = TRUE)
}

```

::: {layout="[[1,2]]"}
```{r}
#| label: tbl-kableMoy
#| tbl-cap: Kable output for months of the year
#| tidy: true

dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-kableMoy
#| tbl-cap: Kable output for weighted months of the year.
#| tidy: true

dplyr::tbl(dbconn, "db/moy_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas78" aria-controls="offcanvas"}
Write, then preview the tables for this section
:::
:::
:::

::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-monthTotals
#| tbl-cap: Month Total Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(abbMonths) |>
dplyr::group_by(abbMonths) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
tabler(
title = "Months",
source_note = gt::md("**Source:** `db/moy.db`"),
footnote = "The recorded observations.",
location = n
)
```

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-monthTotals
#| fig-cap: Month Total Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(abbMonths) |>
dplyr::group_by(abbMonths) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
plotter(
x_col = abbMonths, 
y_col = n, 
geomType = "column", 
title = "Months", 
x_label = "Months", 
y_label = "Trips")

gplot
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-monthCompare
#| tbl-cap: Month Group Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(abbMonths, member_casual) |>
dplyr::group_by(abbMonths, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
dplyr::arrange(abbMonths, member_casual) |>
dplyr::collect() |>
tabler(
title = "Months",
source_note = gt::md("**Source:** `db/moy.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "abbMonths",
label_n = "n",
label_member = " "
)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-monthCompare
#| fig-cap: Month Group Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(abbMonths, member_casual) |>
dplyr::group_by(abbMonths, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
dplyr::arrange(abbMonths, member_casual) |>
dplyr::collect() |>
plotter(
title = "Month Groups",
x_label = "Months",
y_label = "Trips",
x_col = abbMonths, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

```{r}
#| label: tbl-chiMonths
#| tidy: true

dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(abbMonths, member_casual) |>
dplyr::arrange(abbMonths, member_casual) |>
dplyr::collect() |>
tabler(
title = "Chi-Square: Month & Membership",
source_note = gt::md("**Source**: `db/moy.db`"),
label = list(
months = "Month"),
by = member_casual,
isSummary = TRUE
)
```

#### [Density]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-monthDensity
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::collect() |>
plotter(
title = "Month Group Density",
x_label = paste0("Months"),
x_col = started_at, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 month",
date_labels = "%b",
)

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: modelMonthsQ
#| code-summary: Query ..._wq.db, process and create model R object for hour based on quartile range. 

model <- 
dplyr::tbl(dbconn, "db/moy_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```

```{r}
#| label: tbl-modelMonthsQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  
#| tidy: true

model |>
gtsummary::tbl_regression(
label = list(quartile = "Months Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Months & Membership"),
source_note = gt::md("**Source**: `db/moy.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-monthHistogram
#| fig-dpi: 150
#| tidy: true

qdf <- dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(started_at) |>
dplyr::collect()

quartiles <- quantile(qdf$started_at, probs = c(0.25, 0.5, 0.75))

gplot <- dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::select(started_at) |>
dplyr::collect() |>
plotter(
title = "Months",
x_label = "Months",
y_label = "Trips",
x_col = started_at, 
geomType = "column", 
isHistogram = TRUE,
isTimeHist = TRUE,
date_breaks = "1 month", 
date_labels = "%b", 
angle = 45,
color_col = "black",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles,
qformat = "%b-%d"
)

gplot
```
:::

#### [AUC]{.panel-tabset-label}

::: column-screen-inset-right
:::
:::
:::

## Day

::: {.callout-important icon="false"}
<!-- -->
:::


::: {#offcanvas98 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Months of the Year
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeDow
#| code-summary: Write dow.db to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/dow.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
wkdays = lubridate::wday(started_at, week_start = 7),
member_casual = factor(member_casual, levels = c("casual", "member")),
started_at = update(
started_at,
year = 2024,
month = 9,
day = wkdays
),
abbDays = lubridate::wday(started_at, label = TRUE, abbr = TRUE),
abbDays = forcats::as_factor(abbDays)
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/dow.db",
overwrite = TRUE)
}

```

::: {layout="[[1]]"}
```{r}
#| label: tbl-kableDay
#| tbl-cap: Kable output: days of the week.
#| tidy: true

dplyr::tbl(dbconn, "db/moy.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas98" aria-controls="offcanvas"}
Write, then preview the tables for this section
:::
:::
:::



::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-wkdayTotals
#| tbl-cap: Weekday Total Frequency

dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(abbDays) |>
dplyr::group_by(abbDays) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
tabler( 
title = "Days", 
footnote = gt::md("The recorded observations."),
location = n
)
```

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-wkdayTotals
#| fig-cap: Weekday Totals Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(abbDays) |>
dplyr::group_by(abbDays) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
plotter(
x_col = abbDays, 
y_col = n, 
geomType = "column", 
title = "Days for all Riders", 
x_label = "Days of the Week",
y_label = "Trips"
) +
ggplot2::coord_cartesian(ylim = c(4.5 * 10^5, NA))
# To zoom the data a bit

gplot
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

```{r}
#| label: tbl-wkdayCompare
#| tbl-cap: Weekday Group Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(abbDays, member_casual) |>
dplyr::group_by(abbDays, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
dplyr::arrange(abbDays, member_casual) |>
tabler(
title = "Weekday Compare",
source_note = gt::md("**Source:** `db/dow.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "abbDays",
label_n = "n",
label_member = " "
)
```

#### [Plot]{.panel-tabset-label}
::: column-body-outset-right
```{r}
#| label: fig-wkdayCompare
#| fig-cap: Weekday Group Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(abbDays, member_casual) |>
dplyr::group_by(abbDays, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::collect() |>
dplyr::arrange(abbDays, member_casual) |>
plotter(
title = "Day Groups",
x_label = "Days",
y_label = "Trips",
x_col = abbDays, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

```{r}
#| label: tbl-chiDays

dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(abbDays, member_casual) |>
dplyr::collect() |>
dplyr::arrange(abbDays, member_casual) |>
tabler(
title = "Chi-Square: Day & Rider Type",
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
label = list(abbDays = "Day"),
by = member_casual,
isSummary = TRUE
)
```

#### [Density]{.panel-tabset-label}
::: column-body-outset-right
```{r}
#| label: fig-dayDensity
#| code-summary: Density by day of the week.
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(started_at, member_casual) |>
dplyr::collect() |>
plotter(
title = "Weekday Group Density",
x_label = paste0("Day"),
x_col = started_at, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 day",
date_labels = "%a")

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

#### [Histogram Plot]{.panel-tabset-label}
::: column-body-outset-right
```{r}
#| label: fig-Hdays
#| fig-dpi: 150
#| tidy: true

qdf <- dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(started_at) |>
dplyr::collect()

quartiles <- quantile(qdf$started_at, probs = c(0.25, 0.5, 0.75))

gplot <- qdf |>
plotter(
title = "Days",
x_label = "Days",
y_label = "n",
x_col = started_at, 
geomType = "column", 
isHistogram = TRUE,
isTimeHist = TRUE,
date_breaks = "1 day", 
date_labels = "%a", 
angle = 45,
color_col = "black",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles,
qformat = "%a %I %p"
) 

gplot
```
:::

#### [Summary Stats]{.panel-tabset-label}

```{r}
#| label: tbl-daySummary
#| code-summary: Taking a shot at summary stats with datetime data. Seems to work, but a little confusing. 
#| tidy: true

dplyr::tbl(dbconn, "db/dow.db") |>
dplyr::select(started_at, abbDays, member_casual) |>
dplyr::collect() |>
gtsummary::tbl_summary(
by = member_casual,
type = started_at ~ "continuous2",
label = list(started_at ~ "Day"),
statistic = 
gtsummary::all_continuous2() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
tabler(
title = gt::md("Summary: <br> Days - Membership"),
source_note = gt::md("**Source**: `db/dow.db`"),
isBinary = TRUE)
```

#### [AUC]{.panel-tabset-label}

::: column-body-outset-right
:::
:::
:::

## Hour

::: {.callout-important icon="false"}
<!-- -->
:::


::: {#offcanvas108 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Hour of the Day
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeHod
#| code-summary: Write ... to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/hod.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(started_at, member_casual) |>
dplyr::arrange(started_at) |>
dplyr::collect() |>
dplyr::mutate(
started_at_time = update(
started_at,
year = 2023,
month = 1,
day = 1
),
hr = stringr::str_to_lower(format(
lubridate::round_date(started_at, unit = "hour"), "%I %p"
)),
hrMin = stringr::str_to_lower(format(
lubridate::round_date(started_at, unit = "minute"),
"%I:%M %p"
)),
hrminSec = stringr::str_to_lower(format(
lubridate::round_date(started_at, unit = "second"), "%r"
))
) |>
dplyr::select(member_casual:hrminSec) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/hod.db",
overwrite = TRUE)
}

```

```{r}
#| label: hod_n
#| code-summary: Transform hod.db and write as hod_n.db to the databse.

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/hod_n.db"))) {
dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::arrange(started_at_time, member_casual) |>
dplyr::collect() |>
dplyr::add_count(started_at_time, member_casual) |>
dplyr::arrange(started_at_time, member_casual) |>
dplyr::distinct() |>
dplyr::mutate(
hr = forcats::as_factor(hr),
hrMin = forcats::as_factor(hrMin)) |>
duckdb::dbWriteTable(conn = dbconn, 
name = "db/hod_n.db", 
overwrite = TRUE)
}

```

```{r}
#| label: hoursWeightedQuantiles
#| code-summary: Query ..., transform and write weighted quartile data to hod_wq.db.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/hod_wq.db"))) {
transformData(
conn = dbconn,
path = "db/hod.db",
select_cols = c("started_at_time", "member_casual"),
group_cols = c("started_at_time", "member_casual"),
binary_col = "member_casual",
pred_col = "started_at_time",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c(
"Q1 (12:00 am - 10:59 am]",
"Q2 (10:59 am - 03:24 pm]",
"Q3 (03:24 pm - 06:05 pm]",
"Q4 (06:05 pm - 11:59 pm]"
),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/hod_wq.db",
overwrite = TRUE)
}

```

::: {layout="[[1,2],[3]]"}
```{r}
#| label: tbl-dbhod
#| tbl-cap: Kable output of hod.db
#| tidy: true

dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-nHours
#| tbl-cap: Kable output of hod_n.db
#| tidy: true

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-hoursWQ
#| tbl-cap: Kable output of hod_wq.db
#| tidy: true

dplyr::tbl(dbconn, "db/hod_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas108" aria-controls="offcanvas"}
Write, then preview the tables for this section
:::
:::
:::



::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-hourTotals
#| tbl-cap: Total freqeuncy by the hour of day
#| tidy: true

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr) |>
dplyr::summarize(n = sum(n)) |>
dplyr::collect() |>
tabler( 
title = "Hours", 
footnote = gt::md("The recorded observations."), 
location = n)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-hourTotals
#| fig-cap: Total frequency by hour of day.
#| fig-dpi: 150
#| tidy: true

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr) |>
dplyr::summarize(n = sum(n)) |>
dplyr::collect() |>
plotter(
x_col = hr, 
y_col = n,
geomType = "column", 
title = "Hour of Day", 
x_label = "Hour", 
y_label = "Trips",
) +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-hourMembership
#| tbl-cap: Frequencies for membership by hour.
#| tidy: true

dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr, member_casual) |>
dplyr::summarize(n = sum(n)) |>
dplyr::arrange(hr, member_casual) |>
dplyr::collect() |>
tabler(
title = "Hours Membership Groups",
source_note = gt::md("**Source:** `db/hod_n.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "hr",
label_n = "n",
label_member = " "
)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-hourCompare
#| fig-cap: Grouped hour frequency
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::group_by(hr, member_casual) |>
dplyr::summarize(n = sum(n)) |>
dplyr::arrange(hr, member_casual) |>
dplyr::collect() |>
plotter(
title = "Hour Groups",
x_label = "Hour of Day",
y_label = "Trips",
x_col = hr, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
) +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

```{r}
#| label: tbl-chiHours
#| tbl-cap: Chi-Squared for aggregated hours data to the level of rounded hours.
#| code-summary: Query hod_n, then process and display Chi-Squared statistical summary.
#| tidy: true

dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::select(started_at_time, hr, member_casual) |>
dplyr::arrange(started_at_time) |>
dplyr::collect() |>
dplyr::mutate(hr = forcats::as_factor(hr)) |>
tabler(
title = "Chi-Square: Hour & Rider Type",
source_note = gt::md("**Source**: `db/hod.db`"),
label = list(hr = "Hour"),
by = member_casual,
isSummary = TRUE
)
```

#### [Density]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-hourDensity
#| fig-cap: Query, load, and plot the grouped densities 
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::collect() |>
plotter(
title = "Hour Group Density",
x_label = paste0("Hours", "\n", "(12-hour clock)"),
x_col = started_at_time, 
group_col = member_casual,
geomType = "other",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isTime = TRUE,
date_breaks = "1 hour",
date_labels = "%I %p",
)

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: modelHourQ
#| code-summary: Query hod_wq.db, process and create model R object for hour based on quartile range. 
#| tidy: true

model <- 
dplyr::tbl(dbconn, "db/hod_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```

```{r}
#| label: tbl-modelHourQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  
#| tidy: true

model |>
gtsummary::tbl_regression(
label = list(quartile = "Hour Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Hour & Rider Type"),
source_note = gt::md("**Source**: `db/fltrd_data.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-Histogram
#| code-summary: Member histogram plot with quartile ranges. 
#| fig-dpi: 150
#| tidy: true

qdf <- dplyr::tbl(dbconn, "db/hod_n.db") |>
dplyr::select(started_at_time, n) |>
dplyr::collect() |>
tidyr::uncount(n, .remove = TRUE)

quartiles <- quantile(qdf$started_at_time, probs = c(0.25, 0.5, 0.75))

gplot <- qdf |>
plotter(
title = "Hours",
x_label = "Hours (12-hour clock)",
y_label = "n",
x_col = started_at_time, 
geomType = "column", 
isHistogram = TRUE,
isTimeHist = TRUE,
date_breaks = "1 hour", 
date_labels = "%I %p", 
angle = 45,
color_col = "black",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
quartiles = quartiles,
qformat = "%I:%M %p"
) 

gplot
```
:::

#### [Summary Stats]{.panel-tabset-label}

```{r}
#| label: tbl-hourSummaryStats
#| code-summary: Taking a shot at summary stats with datetime data. Seems to work, but a little confusing. 
#| tidy: true

dplyr::tbl(dbconn, "db/hod.db") |>
dplyr::select(started_at_time, hr, member_casual) |>
dplyr::arrange(started_at_time) |>
dplyr::collect() |>
dplyr::mutate(hr = forcats::as_factor(hr)) |>
gtsummary::tbl_summary(
by = member_casual,
type = started_at_time ~ "continuous2",
label = list(started_at_time ~ "Hour"),
statistic = 
gtsummary::all_continuous2() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
gtsummary::italicize_levels() |>
tabler(
title = gt::md("Summary Statistics: <br> Hour - Membership"),
source_note = gt::md("**Source**: `db/hod.db`"),
isBinary = TRUE
)
```

#### [AUC]{.panel-tabset-label}

::: column-body-outset-right
:::
:::
:::

## Distance

::: {.callout-important icon="false"}
<!-- -->
:::

::: {#offcanvas118 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Distance
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeDistance
#| code-summary: Write distance.db to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/distance.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(miles, member_casual) |>
dplyr::arrange(miles) |>
dplyr::collect() |>
dplyr::mutate(
miles = dplyr::case_when(
miles >= 1 ~ round(miles, digits = 0),
miles < 1 ~ round(signif(miles, 3), digits = 1)
),
miles = forcats::as_factor(miles)
) |>
dplyr::arrange(miles, member_casual) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/distance.db",
overwrite = TRUE)
}

```

```{r}
#| label: distanceWeightedQuantiles
#| code-summary: Query ... .db, transform and write weighted quartile data to ... _wq.db. 
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/distance_wq.db"))) {
transformData(
conn = dbconn,
path = "db/distance.db",
select_cols = c("miles", "member_casual"),
group_cols = c("miles", "member_casual"),
binary_col = "member_casual",
pred_col = "miles",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c("Q1 (0.1 - 0.6]", "Q2 (0.6 - 1.0]", "Q3 (1.0 - 2.0]", "Q4 (2.0 - 21.0]"),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn,
name = "db/distance_wq.db",
overwrite = TRUE)
}

```

::: {layout="[[1,2]]"}
```{r}
#| label: tbl-dbhod
#| tbl-cap: Kable output: Distance
#| tidy: true

dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-hoursWQ
#| tbl-cap: Kable output: Distance, Weighted Quantiles
#| tidy: true

dplyr::tbl(dbconn, "db/distance_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas118" aria-controls="offcanvas"}
Write, then preview the tables for this section
:::
:::
:::




::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}

::: panel-tabset
#### [Table]{.panel-tabset-label}

::: tableScroller
```{r}
#| label: tbl-milesTotals
#| tbl-cap: Miles Total Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::select(miles) |>
dplyr::group_by(miles) |>
dplyr::summarize(n = dplyr::n()) |>
tabler( 
title = "Distance", 
footnote = gt::md("The recorded observations."),
location = n
)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-milesTotals
#| fig-cap: Miles Total Frequency
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::select(miles) |>
dplyr::group_by(miles) |>
dplyr::summarize(n = dplyr::n()) |>
plotter(
x_col = miles, 
y_col = n,
geomType = "column", 
title = "Distance", 
x_label = "Miles", 
y_label = "Trips") 

gplot +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}
::: panel-tabset
#### [Table]{.panel-tabset-label}
::: tableScroller
```{r}
#| label: tbl-milesCompare
#| tbl-cap: Miles Group Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::select(miles, member_casual) |>
dplyr::group_by(miles, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(miles, member_casual) |>
tabler(
title = "Distance Groups",
source_note = gt::md("**Source:** `db/freqCompare_miles.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "miles",
label_n = "n",
label_member = " "
)
```
:::

#### [Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-membershipMiles
#| fig-cap: Distance by membership.
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::select(miles, member_casual) |>
dplyr::group_by(miles, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(miles, member_casual) |>
plotter(
title = "Distance Groups",
x_label = "Miles",
y_label = "Trips",
x_col = miles, 
y_col = n, 
group_col = member_casual,
geomType = "column", 
isFaceted = TRUE,
is_colGroup = TRUE
)

gplot +
ggplot2::scale_x_discrete(guide = ggplot2::guide_axis(n.dodge = 1, angle = 45))
```
:::

#### [Chi-Square]{.panel-tabset-label}

#### [Density]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-distanceDensity
#| fig-cap: Densities of miles to membership.
#| fig-dpi: 150
#| tidy: true

gplot <- 
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(miles, member_casual) |>
dplyr::arrange(miles, member_casual) |>
dplyr::collect() |>
plotter(
title = "Distance Group Density",
x_label = "Miles",
x_col = miles, 
group_col = member_casual,
geomType = "column",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isDensity = TRUE,
is_colGroup = TRUE,
breaks = seq(0, 11, by = 1),
limits = c(0.1, 11)
)

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: modeldistanceQ
#| code-summary: Query ..._wq.db, process and create model R object for hour based on quartile range. 
#| tidy: true

model <- 
dplyr::tbl(dbconn, "db/distance_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```

```{r}
#| label: tbl-modeldistanceQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  
#| tidy: true

model |>
gtsummary::tbl_regression(
label = list(quartile = "Duration Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Duration & Membership"),
source_note = gt::md("**Source**: `db/duration_wq.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-distanceHistogram
#| fig-dpi: 150
#| tidy: true

qdf <-
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(miles) |>
dplyr::arrange(miles) |>
dplyr::collect()

quartiles <- quantile(qdf$miles, probs = c(0.25, 0.5, 0.75))

gplot <- qdf |>
plotter(
title = "Distance",
x_label = "Miles",
y_label = "Trips",
x_col = miles, 
geomType = "column", 
isHistogram = TRUE,
angle = 45,
color_col = "transparent",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
limits = c(0.1, 5),
breaks = seq(1, 5, by = 1),
quartiles = quartiles) 

gplot
```
:::

#### [Summary Stats]{.panel-tabset-label}

```{r}
#| label: tbl-distanceSummary
#| tidy: true

dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::mutate(miles = as.numeric(miles)) |>
dplyr::collect() |>
gtsummary::tbl_summary(
by = member_casual,
type = miles ~ "continuous2",
label = list(miles ~ "Distance (miles)"),
digits = list(
miles ~ c(2, 2)),
statistic = 
gtsummary::all_continuous() ~ c(
"{median} ({p25}, {p75})", 
"{mean} ({sd})", 
"{min}, {max}")
) |>
gtsummary::italicize_levels() |>
tabler(
title = gt::md("Summary Statistics: <br> Distance - Membership"),
source_note = gt::md("**Source**: `db/distance.db`"),
isBinary = TRUE
)
```

#### [AUC]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-rocDistance
#| fig-dpi: 150
#| tidy: true

# Generate ROC curve
roc_distance <- 
dplyr::tbl(dbconn, "db/distance.db") |>
dplyr::collect() |>
dplyr::mutate(miles = as.numeric(miles)) |>
pROC::roc(member_casual, miles, levels = c("casual", "member"))

# Find the area under the curve value
auc_distance <- round(pROC::auc(roc_distance), 4)

gplot <- roc_distance |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0("ROC Curve for Duration", " (AUC = ", auc_distance, ")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red")

# false positive rate = x-axis; true positive rate = y-axis
gplot
```
:::
:::
:::

## Speed

::: {.callout-important icon="false"}
<!-- -->
:::


::: {#offcanvas128 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Speed
:::
::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::
::: offcanvas-body
::: flex-code
```{r}
#| label: writeSpeed
#| code-summary: Write ... to the database.
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/speed.db"))) {
dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(mph, member_casual) |>
dplyr::collect() |>
dplyr::mutate(
mphR = round(mph, digits = 0)) |>
dplyr::arrange(mph, member_casual) |>
duckdb::dbWriteTable(
conn = dbconn,
name = "db/speed.db",
overwrite = TRUE)
}
```

```{r}
#| label: speedWeightedQuantiles
#| code-summary: Query ... .db, transform and write weighted quartile data to ... _wq.db. 
#| tidy: true

if (isFALSE(duckdb::dbExistsTable(dbconn, "db/speed_wq.db"))) {
transformData(
conn = dbconn,
path = "db/speed.db",
select_cols = c("mph", "member_casual"),
group_cols = c("mph", "member_casual"),
binary_col = "member_casual",
pred_col = "mph",
ntile_col = "quartile",
zero_val = "casual",
one_val = "member",
qtile_levels = c("Q1 (1.0 - 5.4]", "Q2 (5.4 - 7.0]", "Q3 (7.0 - 8.6]", "Q4 (8.6 - 20]"),
doQuantile = TRUE,
doWeights = TRUE
) |>
duckdb::dbWriteTable(conn = dbconn, name = "db/speed_wq.db", overwrite = TRUE)
}
```

::: {layout="[[1,2]]"}
```{r}
#| label: tbl-kableSpeed
#| tbl-cap: Speed
#| tidy: true

dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```

```{r}
#| label: tbl-kableSpeedWQ
#| tbl-cap: Speed with weighted quartile groups.
#| tidy: true

dplyr::tbl(dbconn, "db/speed_wq.db") |>
dplyr::collect() |>
head() |>
kableExtra::kable()
```
:::
:::
:::
:::
:::
::: {.d-flex .justify-content-center}
:::mb-5
::: {.btn .btn-outline-danger type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas128" aria-controls="offcanvas"}
Write, then preview the tables for this section
:::
:::
:::

::: panel-tabset
### [Overall Frequency Analysis]{.panel-tabset-label}
::: panel-tabset
#### [Table]{.panel-tabset-label}
::: tableScroller
```{r}
#| label: tbl-mphTotals
#| tbl-cap: Mph Total Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mphR) |>
dplyr::group_by(mphR) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mphR) |>
tabler(
title = "Speed",
note_list = list("miles per hour"),
location_list = list("mphR")
) |>
gt::cols_label(mphR = "Mph") |>
gt::cols_align(mphR, align = "left")
```
:::

#### [Plot]{.panel-tabset-label}
::: column-body-outset-right
```{r}
#| label: fig-mphTotals
#| fig-cap: Mph Total Frequency
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mphR) |>
dplyr::group_by(mphR) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mphR) |>
plotter(
x_col = mphR, 
y_col = n,
geomType = "column", 
title = "Speed", 
x_label = "Miles per Hour", 
y_label = "n")

gplot
```
:::
:::

### [Comparative Frequency Analysis]{.panel-tabset-label}
::: panel-tabset
#### [Table]{.panel-tabset-label}
::: tableScroller
```{r}
#| label: tbl-mphCompare
#| tbl-cap: Mph Group Frequency
#| tidy: true

dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mphR, member_casual) |>
dplyr::group_by(mphR, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mphR, member_casual) |>
dplyr::collect() |>
tabler(
title = "MPH Groups",
source_note = gt::md("**Source:** `db/speed.db`"),
footnote = "The recorded observations.",
location = n,
groupName = "mphR"
) |> 
gt::cols_label(n = "n", member_casual = " ") |>
gt::tab_stubhead("MPH")
```
:::

#### [Plot]{.panel-tabset-label}
::: column-body-outset-right
```{r}
#| label: fig-mphCompare
#| fig-cap: Mph Group Frequency
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mphR, member_casual) |>
dplyr::group_by(mphR, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mphR, member_casual) |>
dplyr::collect() |>
plotter(
title = "Speed Groups (Aggregated)",
x_label = "Miles per Hour",
y_label = "Trips",
x_col = mphR, 
y_col = n, 
color_col = member_casual,
geomType = "column",
is_colGroup = TRUE,
isFaceted = TRUE
)

gplot
```
:::

#### [Chi-Square]{.panel-tabset-label}

#### [Density]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-speedDensity
#| fig-cap: Density plot for speed by membership.
#| tidy: true
#| fig-dpi: 150

gplot <- 
dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mph, member_casual) |>
dplyr::group_by(mph, member_casual) |>
dplyr::summarize(n = dplyr::n()) |>
dplyr::arrange(mph, member_casual) |>
dplyr::collect() |>
plotter(
title = "Speed Group Density",
x_label = "MPH",
x_col = mph, 
group_col = member_casual,
geomType = "column",
angle = 45,
color_col = "black",
density_alpha = 0.75,
isDensity = TRUE,
is_colGroup = TRUE,
breaks = seq(1, 20, by = 1),
limits = c(1, 20)
)

gplot
```
:::

#### [Binary Logistic Regression]{.panel-tabset-label}

```{r}
#| label: modelspeedQ
#| code-summary: Query ..._wq.db, process and create model R object for hour based on quartile range. 
#| tidy: true

model <- 
dplyr::tbl(dbconn, "db/speed_wq.db") |>
dplyr::collect() |> 
glm(
formula = member_casual ~ quartile, 
family = binomial,
weights = n)
```

```{r}
#| label: tbl-modelspeedQ
#| code-summary: Pipe model object to tbl_regression(), then further adjust output with tabler().  
#| tidy: true

model |>
gtsummary::tbl_regression(
label = list(quartile = "Speed Ranges"), 
conf.int = FALSE, 
exponentiate = TRUE) |>
tabler(
title = gt::md("Binary Logistic Regression: <br> Speed & Membership"),
source_note = gt::md("**Source**: `db/speed_wq.db`"),
isBinary = TRUE)
```

#### [Histogram Plot]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-speedHistogram
#| tidy: true
#| fig-dpi: 150

qdf <-
dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::select(mph) |>
dplyr::arrange(mph) |>
dplyr::collect()

quartiles <- quantile(qdf$mph, probs = c(0.25, 0.5, 0.75))

gplot <- qdf |>
plotter(
title = "Estimated Average Trip Speed",
x_label = "MPH",
y_label = "Trips",
x_col = mph, 
geomType = "column", 
isHistogram = TRUE,
angle = 45,
color_col = "transparent",
vline_color = "lightyellow",
vline_size = 0.5,
low = "blue",
high = "red",
binwidth = function(x) 2 * IQR(x) / (length(x)^(1/3)),
breaks = seq(1, 20, by = 1),
limits = c(1, 20),
quartiles = quartiles) 

gplot
```
:::

#### [Summary Stats]{.panel-tabset-label}

#### [AUC]{.panel-tabset-label}

::: column-body-outset-right
```{r}
#| label: fig-rocSpeed
#| fig-dpi: 150
#| tidy: true

# Generate ROC curve
roc_speed <- 
dplyr::tbl(dbconn, "db/speed.db") |>
dplyr::collect() |>
pROC::roc(member_casual, mph, levels = c("casual", "member"))

# Find the area under the curve value
auc_speed <- round(pROC::auc(roc_speed), 4)

gplot <- roc_speed |>
plotter(
x_col = NULL, 
y_col = NULL, 
isROC = TRUE,
geomType = "ROC",
title = paste0("ROC Curve for Speed", " (AUC = ", auc_speed, ")"),
x_label = paste0("Specificity", "\n", "(False Positive Rate)"), 
y_label = paste0("Sensitivity", "\n", "(True Positive Rate)"),
roc_color = "red")

# false positive rate = x-axis; true positive rate = y-axis
gplot
```
:::
:::
:::

## Interpretation of EDA

::: p-1
After exploring the associations between the behaviors of annual members and casual riders, several correlations with predictive potential were identified. Chi-squared tests, [@summary], analyzed relationships between categorical variables like membership type, bicycle type, month, day, and hour. Binary logistic regression models, [@regression], examined correlations between the binary dependent variable (membership type) and continuous variables such as distance, duration, and speed. These insights empower stakeholders to make informed decisions to increase service utilization.

Annual members exhibit distinct usage patterns compared to casual riders. They use the service more consistently year-round, preferring manual "classic" bicycles. Annual members take more weekday trips, favoring shorter distances but traveling at faster speeds. These individuals likely have specific destinations in mind, using bicycles as a practical transportation mode akin to cars. Multiple factors likely motivate their choice, including cost savings, avoiding traffic congestion, environmental sustainability, and incorporating exercise. The picture of an annual member is someone with somewhere to be.

In contrast, casual riders tend to be more leisure-oriented, taking longer, slower rides predominantly during warmer months. These fair-weather riders may be visiting Chicago on vacation, opting for bicycles over rental cars as a sightseeing or recreational activity. Some casual users may be prospective annual members, weighing the service's value. The picture of a casual rider is someone who needs something to do.
:::

## Geographic Data

### Traffic Flow {#sec-epiflow}

::: p-1
@fig-epiflowNetwork presents an intriguing bird's-eye view of trip behaviors through an interactive *epiflows* graph. \]@moraga\] This R package used for creating this graph was re-purposed from its original intent for visualizing the spread of disease. This visualization employs a network of nodes (circles) connected by lines, where the thickness of the lines roughly corresponds to the volume of trips between the nodes, with thicker lines indicating a higher number of trips. The top 34 most frequently traveled stations are depicted in this visual network diagram.

The interactive nature of the epiflows allows users to click on individual nodes and lines to access more detailed information. Additionally, a drop-down window provides further exploration capabilities, enabling users to delve deeper into the data.

These stations represent the most active locations within the system. Fortunately, @sec-mapview explores a potential approach to gain insights into the typical high-traffic station locations and the underlying reasons behind their elevated activity levels.
:::

::: {#offcanvas13 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Creating an EpiFlow
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: createFlows dataframe
#| code-summary: First, creates the frequency of trips taken to and from pairs of stations. We are only going to look deeper into the top 50 most traveled pairs.
#| tidy: true

flowData <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(start_station_name, end_station_name) |>
dplyr::group_by(start_station_name, end_station_name) |>
dplyr::summarize(n = n()) |>
dplyr::ungroup() |>
dplyr::arrange(desc(n)) |>
dplyr::rename("from_station" = start_station_name, "to_station" = end_station_name) |>
dplyr::collect() |>
dplyr::slice_head(n = 50)
```

```{r}
#| label: location stats
#| code-summary: Second, we need statistics but also to combine the statistics for every unique station name. 
#| tidy: true

locationData <- dplyr::tbl(dbconn, tblPath_fltrd) |>
dplyr::select(start_station_name,
end_station_name,
started_at,
ended_at,
trip_time) |>
dplyr::group_by(start_station_name, end_station_name) |>
dplyr::mutate("trip_time" = round(trip_time, digits = 0)) |>
dplyr::summarize(
"trip_count" = dplyr::n(),
"first_date" = min(started_at),
"last_date" = max(ended_at),
) |>
dplyr::ungroup() |>
dplyr::rename("from_station" = start_station_name, "to_station" = end_station_name) |>
dplyr::arrange(desc(trip_count)) |>
dplyr::collect()

# Need to combine all names to single column and recalculate
# or retain other stats.
locationData_pivoted <- locationData |>
tidyr::pivot_longer(cols = 1:2, values_to = "allNames") |>
dplyr::group_by(allNames) |>
dplyr::summarize(
"trips_toAndfrom" = sum(trip_count),
first_date = min(first_date),
last_date = max(last_date),
) |>
dplyr::arrange(trips_toAndfrom)
```

```{r}
#| label: MakeEpiflows
#| code-summary: Third, creates epiflow objects, which take in a pair of dataframes and creates the flows between them.
#| tidy: true

# for all the pairs
ef_test <- epiflows::make_epiflows(flows = flowData,
locations = locationData_pivoted,
num_cases = "trips_toAndfrom")

```
:::
:::
:::

::: {#offcanvas14 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Tables
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: summaryFlowData
#| code-summary: First, just a quick view of the flow data table we made earlier.
#| title: Flow Data View
#| tidy: true

flowData
```

```{r}
#| label: pivotedLocations
#| code-summary: Second, another quick view, but for thethe location data we pivoted earlier.
#| title: Pivoted Location Data
#| tidy: true

locationData_pivoted |>
dplyr::arrange(desc(trips_toAndfrom))

```
:::
:::
:::

::: {.article style="color: Black"}
```{r}
#| label: fig-epiflowNetwork
#| fig-cap: EpiFlow Network
#| echo: false

epiflows::vis_epiflows(ef_test)
```
:::

::: {.d-flex .justify-content-center}
::: {.btn-group role="group" aria-label="third"}
::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas13" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="color: #00BFA5"></i>
```
:::

::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas14" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: #F4511E;"></i>
```
:::
:::
:::

### Checking the Map {#sec-mapview}

::: p-1
This section was made possible thanks to the latitude and longitude coordinates data provided alongside the stations names. Coming from the epiflow diagram, this should help make the data less abstract. The accordion below expands and collapses four *OpenStreet* maps found in the callout section below. These maps were split for viewing logistics. They contain from the epiflow in the section above. These maps are interactive, so the default views are zoom-able and movable. The transparent burst buttons enable snappy zooming-in of the station groups.
:::

::: {#offcanvas20 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::: offcanvas-header
::: {.h5 .offcanvas-title}
Code for Mapping
:::

::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::
:::

::: offcanvas-body
::: flex-code
```{r}
#| label: mapData
#| code-summary: "Processing 'flowData' created earlier to include geolocation data for mapview plots."
#| tidy: true

# All distinct stations in one column
names <- flowData |>
dplyr::select(from_station, to_station) |>
tidyr::pivot_longer(cols = 1:2,
names_to = NULL,
values_to = "station_names") |>
dplyr::distinct()


# The important geo-coordinates corresponding to station names
mapData <- dplyr::tbl(dbconn, tblPath_fltrd, check_from = FALSE) |>
dplyr::select(start_station_name,
start_lat,
start_lng,
end_station_name,
end_lat,
end_lng)

# Filter to include all observations that match the station names listed in 'names'. We need the geo-coordinates alongside the names.
mapData1 <- mapData |>
dplyr::collect() |>
# Filter, but through a vector of conditions.
dplyr::filter(start_station_name %in% names[[1]], end_station_name %in% names[[1]]) |>
dplyr::select(start_station_name:start_lng)


# Had to split 'mapData' into two and pivot into a single table.
mapData2 <- mapData |>
dplyr::collect() |>
dplyr::filter(start_station_name %in% names[[1]], end_station_name %in% names[[1]]) |>
dplyr::select(end_station_name:end_lng)

# Nice grouping
stations_groupMap <- dplyr::bind_rows(mapData1, mapData2) |>
dplyr::select(start_station_name, start_lat, start_lng) |>
dplyr::rename("station_names" = start_station_name,
"lat" = start_lat,
"lng" = start_lng) |>
dplyr::distinct() |>
dplyr::group_by(station_names)

# Setting seed for sampling
set.seed(113)

# Taking 10 random samples from each station_name group
sampled_stations <- stations_groupMap |>
dplyr::slice_sample(n = 10) |>
tidyr::drop_na()

```

```{r}
#| label: mapColors
#| code-summary: "Creates a map coloring palette excluding grays."
#| tidy: true

# All of the r-colors
allPalette <- colors()

# The grays are vast so we don't want those watering down the samples.
colorfulPal <- purrr::discard(allPalette, stringr::str_detect(allPalette, "gr(a|e)y"))

# When we sample the colors, 10 should be slightly more than needed.
n_colors <- 10
```

```{r}
#| label: mapViewer
#| code-summary: First, sourcing the script needed to generate the maps and creating the list of vectors used as input. These vectors are the slices of the top most traveled stations.
#| tidy: true

slicerVector <- list(c(1:9), c(10:18), c(19:27), c(28:34))
source("Scripts/mapViewer.R")
```

```{r}
#| file: "Scripts/mapViewer.R"
#| eval: false
#| code-summary: "The script used to generate the maps."
#| label: mapViewerScript

```
:::
:::
:::

::: {#accordionParent .accordion .mt-3 .mb-3}
::: accordion-item
::: {#headingOne .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne" style="background-color: #222"}
Benson Ave & Church St ... Ellis Ave & 60th St
:::
:::

::: {#collapseOne .accordion-collapse .collapse aria-labelledby="headingOne" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map1
#| fig-cap: "Benson Ave & Church St - Ellis Ave & 60th St"
#| tidy: true

set.seed(240)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[1]])
```
:::
:::
:::

::: accordion-item
::: {#headingTwo .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo" style="background-color: #222"}
Greenview Ave & Fullteron Ave ... Loomis Ave & Lexington St
:::
:::

::: {#collapseTwo .accordion-collapse .collapse aria-labelledby="headingTwo" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map2
#| echo: false
#| fig-cap: "Greenview Ave & Fullteron Ave - Loomis Ave & Lexington St"
#| tidy: true

set.seed(241)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[2]])
```
:::
:::
:::

::: accordion-item
::: {#headingThree .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree" style="background-color: #222"}
Michigan Ave & Oak St ... State St & 33rd St
:::
:::

::: {#collapseThree .accordion-collapse .collapse aria-labelledby="headingThree" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map3
#| echo: false
#| fig-cap: "Michigan Ave & Oak St - State St & 33rd St"
#| tidy: true

set.seed(242)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[3]])
```
:::
:::
:::

::: accordion-item
::: {#headingFour .accordion-header}
::: {.accordion-button .collapsed type="button" data-bs-toggle="collapse" data-bs-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour" style="background-color: #222"}
Street Dr & Grand Ave ... Woodlawn Ave & 55th St
:::
:::

::: {#collapseFour .accordion-collapse .collapse aria-labelledby="headingFour" data-bs-parent="#accordionParent"}
::: accordion-body
```{r}
#| label: fig-map4
#| fig-cap: "Street Dr & Grand Ave - Woodlawn Ave & 55th St"
#| tidy: true

set.seed(243)
randomColors <- sample(colorfulPal, n_colors)
mapViewer(slicerVector[[4]])
```
:::
:::
:::
:::

### Interpretation of the Geographic Data

::: p-1
For example, suppose the user selects *University Ave & 57th St* in the epiflow visualization. This intersection happens to be at the heart of the University of Chicago campus. The natural next question is: where does the traffic to and from this location typically flow? By selecting one of the other nodes highlighted with flows directing away from the previous node, the user can identify *Kimbark Ave and 53rd St*. As seen in the map view, this location is situated adjacent to the *Vue 53 Apartments* complex. By analyzing such connections between nodes, the user can gain insights into common routes and destinations originating from a particular point of interest, potentially revealing patterns related to student housing, campus facilities, or other points of interest in the vicinity.

The data suggests individual members utilize the service multiple times weekly. However, further analysis is needed to determine if a significantly larger volume of unique individuals are annual members. Verifying associations between specific locations and higher or lower traffic could be a next step. Preliminary observations indicate universities, shopping centers, major companies, and nearby apartment complexes tend to have the highest ridership volumes.

To improve membership, addressing factors deterring individuals from becoming annual members could be key. These may include a lack of stations within walking distance of residences or destinations, or concerns over electric bicycle battery life and charging station availability, potentially explaining their lower utilization compared to classic bikes. Offering trial periods could allow casual users to experience the service's reliability and convenience, encouraging conversion to annual memberships.
:::

## Updated Database Tables List

```{r}
#| label: tbl-dbList2
#| code-summary: "Revisiting the list of db tables, with many more tables added. All of these tables are stored within the data/data.db file."
#| tbl-cap: "Database Table List: Post-Exploratory Analysis"
#| tidy: true

dbList2 <- duckdb::dbListTables(dbconn) |>
as.data.frame() |>
tabler(
title = "Post-Exploratory Database Tables",
note_list = list(
gt::md("The tables contained in data.db, <br> at the end of the analysis.")
),
location_list = list("duckdb::dbListTables(dbconn)")
) |>
gt::cols_label("duckdb::dbListTables(dbconn)" = "Table Paths") |>
gt::tab_style(
gt::cell_text(align = "center", stretch = "semi-expanded"),
locations = list(gt::cells_column_labels(columns = gt::everything()))
)

dbList2
```

# Conclusion

::: p-1
These findings empower stakeholders with data-driven insights to increase service utilization and make informed decisions regarding resource allocation, marketing, and service enhancements.
:::

## Key Findings

::: p-1
-   Annual members exhibit consistent, practical usage patterns - frequent weekday trips, shorter distances at faster speeds, favoring "classic" bikes. Likely using the service for transportation, motivated by factors like cost, convenience, and exercise.

-   Casual riders demonstrate more leisurely behavior - longer, slower rides concentrated in warmer months, potentially for sightseeing/recreation purposes when visiting the city.

-   Correlations identified between membership type and variables like distance, duration, speed, month, day, hour, and bike type through statistical testing.
:::

## Recommendations:

::: p-1
-   Verify associations between specific locations (universities, shopping centers, businesses, residential areas) and higher/lower traffic to optimize service distribution.

-   Analyze the volume of unique individuals represented in each membership type to gauge potential for conversion from casual to annual.

-   Leverage insights into usage patterns and motivations to tailor marketing strategies, targeting prospective annual members among casual rider demographics.
:::

```{r}
#| eval: false
#| include: false

# If you need to drop any tables without deleting the entire database.
source("Scripts/duckDrops.R")
```
