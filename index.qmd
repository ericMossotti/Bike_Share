---
title: "Case study: Bike-sharing program in the chicago area"
author: "Eric Mossotti"
date: "05-01-2024"
bibliography: references.bib
repo: https://github.com/ericMossotti/Bike_Share
source: index.qmd
abstract-title: "Objective"
abstract: "Communicate data-driven insights to stakeholders."
description-meta: "Communicate data-driven insights to stakeholders."
code-links:
    - text: "Project Repo"
      href: repo
code-fold: true
code-copy: hover
code-overflow: wrap
code-tools: true
code-link: true
#toc: true
#toc_float: true
#smooth-scroll: true
fig-responsive: true
echo: true

margin-left: 10vw
margin-right: 5vw
margin-top: 5vh
margin-bottom: 5vh

#font: merriweather, futura
---

```{r, include = FALSE}

knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE)

```

::::::::::: flex-row-tainer
:::::::::: flex-col-tainer
::::::::: p
## Import and Project Design

Data source for this data analysis was obtained from Divvy Data. [@divvyda]

Thinking ahead with reproducibility in mind, should cover most use cases for tinkering and testing. I have found it helpful to reduce the need to re-download files and re-process all over again if all one needs to do is reconnect to the database that has already been written.

As a counterpart to the if-else design decision at the top of the project, I've condensed the initial download, import and cleaning steps inside of an R-script.

Choosing a persistent DuckDB database filesystem (as opposed to in-memory) was intentional as I wouldn't lose the progress I've made when tinkering over multiple days. It seems just as fast as the in-memory database but also seems to reduce RAM needed in tinkering. [@whyduck]
:::::::::

::::::::: {.btn-group role="group" aria-label="first"}

:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas1" aria-controls="offcanvas" .m-1}
```{=html}
<i class="bi bi-code-slash" style="font-size: .75em; color: cornflowerblue;"></i>
```
::::::::

:::::::: {#offcanvas1 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::::::: offcanvas-header
:::::: {#offcanvasLabel .h5 .offcanvas-title}
Hello
::::::

:::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
::::::
:::::::

::::::: {.offcanvas-body}
:::::: flex-code
```{r}
#| label: importOrConnect
#| code-summary: import or connect

if(exists("dbconn") == FALSE &&
   dir.exists("db") == FALSE) {
    # Script to keep this document less cluttered.
    source("import_clean_initial.R")
} else {
    # You will have to change original_nobs if you use            
    #  different data. It helps with tinkering when 
    #   you want to skip the import step.
    original_nobs <- as.integer(5719877)
    
    tblPath <- "db/data.db"
    
    dbconn <- DBI::dbConnect(
        duckdb::duckdb(),
        dbdir = tblPath,
        read_only = FALSE,
        check_from = FALSE
    )
}
```

```{r}
#| label: importProcessScript
#| code-summary: download, import, and process
#| file: "import_clean_initial.R"
#| eval: false 
```

```{r}
#| label: dbList
#| code-summary: create list of database tables

dbList <- duckdb::dbListTables(dbconn) |>
    data.frame() |>
    gt::gt()
```
::::::
:::::::
::::::::


:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas2" aria-controls="offcanvas" .m-1}
```{=html}
<i class="bi bi-table" style="color: red; font-size: .75em"></i>
```
::::::::

:::::::: {#offcanvas2 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::::::: offcanvas-header
:::::: {.h5 .offcanvas-title}
Hello
::::::

:::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
::::::
:::::::
::::::: {.offcanvas-body}
:::::: flex-code
```{r}
#| code-summary: view db tables
#| echo: false
dbList
```
::::::
:::::::
::::::::
:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#null" aria-controls="offcanvas" .disabled}
```{=html}
<i class="bi bi-pie-chart-fill" style="color: green; font-size: .75em"></i>
```
::::::::
:::::::::
::::::::::
:::::::::::

::::::::::: flex-row-tainer
:::::::::: flex-col-tainer
::::::::: p
## Hidden Duplicate Observations?

Now to go a little deeper, we can check for duplicates. It might not necessarily be the case that each observation (obs) is unique even if all the Rider IDs are, technically, unique. Of the other columns, it seems that the start_time, end_time, start_station, and end_station, if combined, could show if there are possibly hidden duplicated observations. We started with 5,719,877 observations (obs) for dates spanning January to December, 2023, then removed 1,388,170 incomplete obs.

I assumed that having the same times/dates and stations for two different ride IDs was a mistake. Although, I do not know how that error would happen, I could have assumed one person could check out multiple bikes at once. In that instance, each bike would be assigned a unique ride_id. That, however, has only happened 18 times over a year. Since it's only one copy every time, that also raises a red flag in my mind. I did not notice any other correlations with station_id/name, member_casual, or ride_type for those particular duplicated data.

By applying distinct() on dupeTable, we see the only distinct value, 'n', is 2. I conclude that, of the duplicates, each has a minimum and maximum of 1 extra copy. Number of rows in the dupeTable is 36. Because each duplicated observation has one duplicate, "n = 2", expected removed nobs is 18. The issue is that we need to get rid of not all 36 rows, but just one extra duplicate observation from each. This will result in the expected 18 obs.

The count of distinct n-values for the un-duplicated table was indeed 18. So now, it is time to run a count of how rows/observations are in the dataset. There is a difference, though, concerning the correct amount. The incorrect number of observations (nobs) was 4,331,707. The correct nobs after removing duplicated obs was 4,331,689. In short, 18 additional obs were removed.

We can now add the processed table to our database. Might be a good idea to verify the table is where it should be.
:::::::::
::::::::: {.btn-group role="group" aria-label="second"}
:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas3" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: .75em; color: cornflowerblue;"></i>
```
::::::::

:::::::: {#offcanvas3 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::::::: offcanvas-header
:::::: {.h5 .offcanvas-title}
Hello
::::::

:::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
::::::
:::::::

::::::: {.offcanvas-body}
:::::: flex-code
```{r}
#| label: duplicates_gt
#| code-summary: create gt of duplicates for illustration

# This is a separate table used to analyze the observations 
#  returned as not distinct (n > 1). 
#   This adds an extra column, labeled "n".
dupeTable <- dplyr::tbl(dbconn,
                        tblPath,
                        check_from = FALSE) |>
    dplyr::select(started_at:end_station_name) |>
    # Counts of unique rows added for column 'n'
    dplyr::add_count(started_at,
                     ended_at,
                     start_station_name,
                     end_station_name) |>
    # Only observations that have been duplicated 
    #  1 or more times are shown.
    dplyr::filter(n > 1) |>
    # We want to see all rows, 
    #  not just one row for each obs.
    dplyr::ungroup() |>
    dplyr::arrange(started_at) |>
    dplyr::collect()


gtDupes <- dupeTable |>
    dplyr::group_by(started_at) |>
    gt::gt(rowname_col = "row",
           groupname_col = "started_at",
           row_group_as_column = TRUE,
           caption = "Duplicates_Table1") |>
    gt::tab_style(
    style = list(
        gt::cell_text(weight = "bold",
                      align = "center"),
        gt::cell_borders(sides = c("bottom"))
    ),
    locations = gt::cells_column_labels(gt::everything())
    ) |>
    gt::tab_style(
    style = list(
        gt::cell_borders(sides = c("left", "right")),
        gt::cell_text(align = "center",
                      v_align = "middle")
    ),
    locations = gt::cells_body(gt::everything())
    ) |>
    gt::data_color(columns = start_station_name,
                   target_columns = gt::everything(),
                   method = "auto",
                   palette = "basetheme::brutal") |>
    gt::tab_source_note(gt::md("**Source**: Divvy Data")) |>
    gt::tab_header(title = "Duplicate Observations",
                   subtitle = "(by start date)") |>
    gt::tab_options(
        heading.title.font.weight = "bolder",
        heading.subtitle.font.weight = "lighter",
        table.layout = "auto"
        )
```

------------------------------------------------------------------------

```{r}
#| label: duplicateObs count
#| code-summary: create count of distinct duplicates and total obs

distinctCopiesCount <- dupeTable |>
    dplyr::distinct(n) |>
    as.integer() 

duplicateObs <- length(dupeTable[[1]])
```

------------------------------------------------------------------------

```{r}
#| label: undupedTable
#| code-summary: create table of the duplicated obs

# The issue is, we need to get rid of not all of these rows,
#  but just the extra duplicate observations. 

# If there were 2 rows of duplicates, 
#  we would want to end up with 1 row after 
#   removing the extras.
undupedTable <- dupeTable |>
    dplyr::distinct(started_at,
                     start_station_name,
                     ended_at,
                     end_station_name,
                     .keep_all = TRUE)
```

------------------------------------------------------------------------

```{r}
#| label: duplicated code
#| include: false
#| eval: false

distinctUndupedCounts <- undupedTable |>
    dplyr::select(started_at) |>
    dplyr::distinct() |>
    dplyr::count() |>
    as.integer()

```

------------------------------------------------------------------------

```{r}
#| label: incorrect distinct obs count
#| code-summary: count of incorrect obs

# Run an incorrect count on how many rows or observations 
#  there are in the dataset.
count_incorrectDists <- dplyr::tbl(dbconn,
                                   tblPath,
                                   check_from = FALSE) |>
    dplyr::distinct(dplyr::pick("ride_id")) |>
    dplyr::count(name = "Incorrect Distinct Observations") |>
    dplyr::collect() |>
    as.integer()

```

------------------------------------------------------------------------

```{r}
#| label: count_correctDists count
#| code-summary: count of correct obs

# For the correct count of obs
count_correctDists <- dplyr::tbl(dbconn,
                                 tblPath,
                                 check_from = FALSE) |>
    dplyr::distinct(
        dplyr::pick(
            "started_at",
            "start_station_name",
            "ended_at",
            "end_station_name"
        )
    ) |>
    dplyr::count() |>
    dplyr::collect() |>
    as.integer()

```

------------------------------------------------------------------------

```{r}
#| label: 'overwrite file with correct obs'
#| code-summary: writing dupeless db


dupelessPath <- "db/dupeless.db"
 
dplyr::tbl(dbconn,
           tblPath,
           check_from = FALSE) |>
    dplyr::select(ride_id:trip_time) |>
    dplyr::distinct(started_at,
                    start_station_name,
                    ended_at,
                    end_station_name,
                    .keep_all = TRUE) |>
    dplyr::arrange(started_at) |>
    dplyr::collect() |>
    duckdb::dbWriteTable(conn = dbconn,
                         name = dupelessPath,
                         overwrite = TRUE,
                         check_from = FALSE)
```

------------------------------------------------------------------------

```{r}
#| label: duplicateProcess
#| code-summary: summarizing obs removed so far

# To visualize a summary of what we just determined
#  regarding obs.
summaryProcessTable <- tidyr::tribble(
    ~ "Observations",
    ~ "Counts",
    "Original   ",
    original_nobs,
    "Processed   ",
    count_incorrectDists,
    "Duplicates   ",
    (count_incorrectDists - count_correctDists),
    "Total Corrected   ",
    count_correctDists
) |>
    gt::gt(rownames_to_stub = FALSE) |>
    gt::tab_header(title = "Tallying Observations") |>
    gt::tab_footnote(
        footnote = gt::md("Row counts throughout the cleaning steps."),
        locations = gt::cells_column_labels(columns = Counts)
    ) |>
    gt::tab_style(
        style = list(
            gt::cell_borders(sides = "bottom"),
            gt::cell_text(
                align = "left",
                stretch = "semi-expanded",
                whitespace = "break-spaces"
            )
        ),
        locations = gt::cells_body(gt::everything())
    ) |>
    gt::tab_style(
        style = list(gt::cell_borders(sides = c("bottom",
                                                "top"))),
        locations = gt::cells_column_labels(gt::everything())
    ) |>
    gt::tab_options(quarto.use_bootstrap = TRUE,
                    column_labels.font.weight = "bold")

```
::::::
:::::::
::::::::

:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas4" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: red; font-size: .75em"></i>
```
::::::::

::::::: {#offcanvas4 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
:::::: offcanvas-header
::::: {.h5 .offcanvas-title}
Hello
:::::

::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
:::::
::::::

:::::: {.offcanvas-body .align-text-center}
::::: flex-code
:::: panel-tabset
## Duplicates View

```{r}
#| label: gt table of duplicates view
#| code-summary: gt table of duplicates view
#| echo: false
#| title: Duplicates Table View
gtDupes
```

## Unduplicated View

```{r}
#| label: unduplicatedGT
#| code-summary: gt table of the now unduplicated obs
#| title: View of Un-duplicated Table
#| echo: false
undupedTable |>
    dplyr::collect() |>
    gt::gt()
```

## Verify Dupeless

```{r}
#| label: output_dupelessPath
#| echo: false
#| title: Verify Dupeless DB Path
dplyr::tbl(dbconn,
           dupelessPath) |>
    head() |>
    gt::gt()
```

## Summary of Processsing

```{r}
#| label: output_summaryProcessTable
#| title: Summary of Processing Table
#| echo: false
summaryProcessTable
```
::::
:::::
::::::
:::::::

:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#null" aria-controls="offcanvas" .disabled}
```{=html}
<i class="bi bi-pie-chart-fill" style="color: green; font-size: .75em"></i>
```
::::::::
:::::::::
::::::::::
:::::::::::

::::::::::: flex-row-tainer
:::::::::: flex-col-tainer

::::::::: p
## Outlier Filter

To ensure the conclusions are accurate, outliers should be filtered. Negative and very low trip times might skew trends. The underlying reason for very low trip times is somewhat of an unknown. Perhaps people often change their minds?

As in the first part, an if-else code-chunk design was chosen because it makes testing easier. It's not required but is nice-to-have. Removing the nonsensical outliers, on the other hand, is required. This code chunk accomplishes both, regardless if you are just testing and already have the filtered database table or if you still need to create it. A database filtering script was used to make the code chunk easier to follow. We then verify the table does exist now along with all other tables we previously created.

So this should have removed outliers from the dataset which don't really serve the scope of this analysis. Some could have also been erroneous data.
:::::::::
::::::::: {.btn-group role="group" aria-label="third"}
:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas33" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-code-slash" style="font-size: .75em; color: cornflowerblue;"></i>
```
::::::::
:::::::: {#offcanvas33 .offcanvas .offcanvas-start tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::::::: offcanvas-header
:::::: {.h5 .offcanvas-title}
Stepping Through the Code
::::::

:::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
::::::
:::::::

::::::: {.offcanvas-body}
:::::: flex-code
```{r}
#| label: filtering db
# So you don't have to re-dl or re-fltr    
#  after making further adjustments.
tblPath <- "db/data.db"
dupelessPath <- "db/dupeless.db"
tblPath_fltrd <- "db/data_fltrd.db"

if (exists("dbconn") == FALSE && dir.exists("db") == TRUE) {
    dbconn <- DBI::dbConnect(
        duckdb::duckdb(),
        dbdir = tblPath,
        read_only = FALSE,
        check_from = FALSE
    )
}

if (duckdb::dbExistsTable(dbconn,
                          "tblPath_fltrd") == FALSE) {
    source("filterDatabase.R")
    filterDatabase()
}
```
::::::
:::::::
::::::::

:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#offcanvas22" aria-controls="offcanvas"}
```{=html}
<i class="bi bi-table" style="color: red; font-size: .75em"></i>
```
::::::::

:::::::: {#offcanvas22 .offcanvas .offcanvas-end tabindex="-1" aria-labelledby="offcanvas" style="width: auto"}
::::::: offcanvas-header
:::::: {.h5 .offcanvas-title}
Stepping Through the Code
::::::

:::::: {.btn-close type="button" data-bs-dismiss="offcanvas" ariaLabel="Close"}
::::::
:::::::

::::::: {.offcanvas-body}
:::::: flex-code
```{r}
#| echo: false
# To verify the new filtered table exists.
duckdb::dbListTables(dbconn)
```
::::::
:::::::
::::::::
:::::::: {.btn .btn-secondary type="button" data-bs-toggle="offcanvas" data-bs-target="#null" aria-controls="offcanvas" .disabled}
```{=html}
<i class="bi bi-pie-chart-fill" style="color: green; font-size: .75em"></i>
```
::::::::
:::::::::
::::::::::
:::::::::::


```{r}
#| eval: false
#| include: false

# If you need to drop any tables
source("duckDrops.R")
```

------------------------------------------------------------------------

